[
  {
    "objectID": "3.html",
    "href": "3.html",
    "title": "Chapter 3: One-parameter models",
    "section": "",
    "text": "1998 General Social Survey: Females over age 65, \\(1 = \\text{happy}\\), \\(0 =\n\\text{unhappy}\\). \\(n = 129\\). So let the survey be 129 exchangeable random variables \\(Y_1, \\dots, Y_{129}\\).\nUnder our model, conditioned on some \\(\\theta\\), \\(Y_i\\) are i.i.d. binary random variables with probability \\(\\theta\\). So the joint probability is\n\\[\\begin{align}\np(y_1, \\dots, y_{129} \\mid \\theta) = \\theta^{\\sum_{i} y_i} (1 - \\theta)^{129 -\n\\sum_i y_i}\n\\end{align}\\]\nNow we need to specify our prior distribution\n\nImagine our prior is \\(\\theta \\sim \\text{Uniform}(0, 1)\\). What this means is \\(P(a \\leq \\theta \\leq b) = P(a + c \\leq \\theta \\leq b + c)\\) for all compatible \\(a, b, c\\). In other words, the probability of theta falling in an interval of a given width is constant, regardless of where the interval is.\nThen, notice\n\\[\\begin{align}\np(\\theta \\mid y_1, \\dots, y_{129}) &= \\frac{p(y_1, \\dots, y_{129} \\mid \\theta) p(\\theta)}{p(y_1, \\dots, y_{129})} \\\\\n&= \\frac{p(y_1, \\dots, y_{129} \\mid \\theta)}{p(y_1, \\dots, y_{129})} & (\\text{since $p(\\theta)$ is constant for all $\\theta$}) \\\\\n&\\propto p(y_1, \\dots, y_{129} \\mid \\theta)\n\\end{align}\\]\nso \\(p(\\theta \\mid Y)\\) and \\(p(y \\mid \\theta)\\) have the same shape (see MLE discussion in Chapter 1).\n\nSay the observed proportion is 118 happy out of 129 (91%). Our sampling model for some fixed \\(\\theta\\) is\n\\[\\begin{align}\np(y \\mid \\theta) = \\theta^{118} (1 - \\theta)^{11}\n\\end{align}\\]\nlinking this back to Bayes’ rule above, we have the posterior probability\n\\[\\begin{align}\np(\\theta \\mid y) = \\frac{\\theta^{118} (1 - \\theta)^{11}}{p(y)}\n\\end{align}\\]\nWe will often (WHEN would we not normalize?) want to be more precise than this and know about the scale of the posterior probability, not just the shape. This requires calculating \\(p(y) = p(y_1, \\dots, y_{129})\\):\n\\[\\begin{align}\n1 &= \\int_0^1 p(\\theta \\mid y) \\; d\\theta & (\\text{Law of total probability}) \\\\\n&= \\int_0^1 \\theta^{111} (1 - \\theta)^{11} / p(y) \\; d\\theta \\\\\n&= \\frac{1}{p(y)} \\int_0^1 \\theta^{118} (1 - \\theta)^{11} \\; d\\theta & (\\text{Note\n$p(y)$ is constant for fixed $y$})\\\\\n&= \\frac{1}{p(y)} \\frac{\\Gamma(119) \\Gamma(12)}{\\Gamma(131)} & (\\text{From calculus})\\\\\n\\end{align}\\]\nso \\(p(y) = \\frac{\\Gamma(119) \\Gamma(12)}{\\Gamma(131)} \\approx 2.89 \\times\n10^{-18}\\). Since our \\(y_i\\) are exchangeable, this holds true for any sequences of \\(y_i\\) with 118 ones and 11 zeros.\nSo, finally, the posterior probability is\n\\[\\begin{align}\np(\\theta \\mid y) &= \\frac{\\Gamma(131)}{\\Gamma(119) \\Gamma(12)} \\theta^{118} (1 -\n\\theta)^11 \\\\\n&= \\frac{\\Gamma(131)}{\\Gamma(119) \\Gamma(12)} \\theta^{119 - 1} (1 - \\theta)^{12 - 1} & (\\text{Beta parameterization})\\\\\n\\end{align}\\]\nwhich happens to be a beta distribution with parameters \\(a = 119\\) and \\(b = 12\\).\nIf \\(Y \\sim \\text{Beta}(a, b)\\), then\n\nPDF: \\(p(y) = \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} y^{a - 1} (1 - y)^{b - 1}\\)\n\n\\(\\mathbb{E}(Y) = \\frac{a}{a + b}\\)\n\\(\\text{Mode}(Y) = \\frac{a - 1}{a + b - 2}\\)\n\\(\\text{Var}(Y) = \\frac{ab}{(a + b)^2 (a + b + 1)}\\)\n\nIn our case, our posterior looks like:\n\n\n\n\n\n\n\n\n\nRecall for our binary data \\(Y_1, \\dots, Y_n\\) that\n\\[\\begin{align}\np(\\theta \\mid y) &= \\frac{p(y \\mid \\theta) p(\\theta)}{p(y)} \\\\\n&= \\frac{\\theta^{\\sum y_i} (1 - \\theta)^{n - \\sum y_i} p(\\theta)}{p(y)} & \\text{(Since i.i.d.)} \\\\\n\\end{align}\\]\nImportantly, the quantity \\(\\sum_{i = 1}^n Y_i\\) is the only statistic that is needed to calculate posterior probabilities of \\(\\theta\\). So it is a sufficient statistic for making inference about \\(\\theta\\). The statistic \\(Y = \\sum Y_i\\) has a binomial distribution with parameters \\((n, \\theta)\\). Then,\n\\[\\begin{align}\np(y \\mid \\theta) &= {n \\choose y} \\theta^y (1 - \\theta)^{n - y}\n\\end{align}\\]\n\nNote: I skip the general derivation of posterior probabilities for uniform prior here, since a uniform prior is also a \\(\\text{Beta}(a, b)\\).\n\nNow let’s calculate the posterior probability \\(p(\\theta \\mid y)\\) when \\(p(\\theta)\\) is not uniform; in particular, when our prior on \\(\\theta\\) is a Beta distribution (\\(\\theta \\sim \\text{Beta}(a,\nb)\\)):\n\\[\\begin{align}\np(\\theta \\mid y) &= \\frac{p(\\theta) p(y \\mid \\theta)}{p(y)} & \\\\\n&= \\frac{1}{p(y)} \\times \\underbrace{\\frac{\\Gamma(a + b)}{\\Gamma(a)\n\\Gamma(b)}\\theta^{a - 1}(1 - \\theta)^{b - 1}}_{\\text{PDF of $\\text{Beta}(a,\nb)$}} \\times \\underbrace{{n \\choose y} \\theta^y (1 - \\theta)^{n -\ny}}_{\\text{$p(y \\mid \\theta)$ above}} & \\\\\n&= c \\times \\theta^{a + y - 1} (1 - \\theta)^{b + n - y - 1} & \\text{(Combine $\\theta$s)} \\\n\\end{align}\\]\\end{align}\nwhere \\(c = f(n, y, a, b)\\) is just compressing the other stuff in the equation into a constant, since it doesn’t depend on \\(\\theta\\). Now, notice that the term with \\(\\Gamma\\)s in the above equation is the PDF of \\(\\theta \\sim \\text{Beta}(a, b)\\), which can also be expressed with a constant \\(c = f(a, b)\\): \\(p(\\theta) = c \\theta^{a - 1}(1\n- \\theta)^{b - 1}\\). Notice that this looks just like the equation above: thus, \\(p(\\theta)\\) and \\(p(\\theta \\mid y)\\) are both proportional to \\(\\theta^{a - 1} (1 -\n\\theta)^{b - 1}\\) by some constant \\(c\\).\nNow, since we know that as probability distributions, \\(\\int p(\\theta) = \\int\np(\\theta \\mid y) \\; d\\theta = 1\\), we also know that the functions share the same scale, which means that \\(p(\\theta \\mid y)\\) is actually a Beta PDF!\n\\[\n(\\theta \\mid y) \\sim \\text{Beta}(a + y, b + n - y).\n\\]\nWe therefore call Beta distributions conjugate priors for Binomial distributions.\n\n\nConjugacy. A class \\(\\mathcal{P}\\) of prior distributions for \\(\\theta\\) are conjugate priors of a sampling model \\(p(y \\mid \\theta)\\) if \\[ p(\\theta) \\in\n\\mathcal{P} \\implies p(\\theta \\mid y) \\in \\mathcal{P}.\\]\n\nConjugate priors are very convenient and making certain calculations easy, since there is some convenient closed form solution for the distribution of a model posterior given a model prior and observed data.\nNow, if you remember from Chatper 1, since the expectation of a Beta distribution is \\(\\frac{a}{a + b}\\),\n\\[\\begin{align}\n\\mathbb{E}(\\theta \\mid y) &= \\frac{a + y}{a + b + n} \\\\\n&= \\frac{a + b}{a + b + n} \\frac{a}{a + b} + \\frac{n}{a + b + n}\\frac{y}{n} \\\\\n\\end{align}\\]\nWhere \\(\\theta_0 = \\frac{a}{a + b}\\) can be seen as our “prior expectation”, \\(\\frac{y}{n}\\) is the sample mean, and \\(w = a + b\\) can be seen as the strength of belief in our prior. I leave the equation expressed above with the \\(a\\)s and \\(b\\)s expanded because another intuitive way of thinking about the problem is by thinking of \\(a\\) as the “prior number of 1s”, \\(b\\) as the “prior number of 0s”, and \\(a + b\\) as the “prior sample size”. If you play around with the equation above, seeing how the values change with various \\(a\\) and \\(b\\) prior choices, you’ll notice it has several nice properties that intuitively balance the expectation and strength of our prior with the amount of data we receive.\n\nAssume we’ve already seen data \\(y_1, \\dots y_n\\) and we want to predict value of the next observation \\(\\tilde{Y}\\). Intuitively we should predict \\(\\tilde{Y} = 1\\) with probability equal to the expectation of \\(\\theta\\) given our data (according to the Bayesian framework). These calculations confirm this:\n\\[\\begin{align}\np(\\tilde{Y} = 1 \\mid y) &= \\int p(\\tilde{Y} = 1, \\theta \\mid y) \\; d\\theta & \\text{(LTP)} \\\\\n&= \\int p(\\tilde{Y} = 1 \\mid \\theta, y) p(\\theta \\mid y) \\; d\\theta & \\text{(Chain rule)} \\\\\n&= \\int \\theta p(\\theta \\mid y) \\; d\\theta & \\text{(Since $\\tilde{Y}$ is binary)} \\\\\n&= \\mathbb{E}(\\theta \\mid y).\n\\end{align}\\]\nNote that in this case the posterior predictive distribution is very easy to predict and is (as it can only possibly be) a Bernoulli distribution with a certain probability \\(p\\). When posterior distributions become more complicated, however, (e.g. Poisson model), their posterior predictive distributions may require more complex calculations and may result in a different family of distributions. Still later, we will show how to simulate posterior predictive distributions with Monte Carlo sampling.\nAlso note that using the expectation instead of the mode is nice, for examples where we have a uniform \\(\\text{Beta}(1, 1)\\) prior and we observe \\(Y = 0\\). Then,\n\\[\\begin{align}\n\\mathbb{E}(\\theta \\mid Y = 0) &= \\frac{2}{2 + n}\\frac{1}{2} + \\frac{n}{2 +\nn}\\frac{y}{n} = \\frac{1}{2 + n}\\\\\n\\theta_{MAP} &= \\frac{y}{n} = 0 \\\\\n\\end{align}\\]\nAnd clearly the expectation is more sensible as a predictor of future \\(\\tilde{Y}\\). But \\(\\theta_{MAP}\\) is not as unreasonable when there is a non-uniform prior…\n\nSee this StackExchange question for a really interesting discussiona bout the difference between Bayesian and frequentist confidence intervals.\nBayesian confidence interval is an interval \\([l(y), u(y)]\\) with the following property:\n\\[\\begin{align}\nP(l(y) &lt; \\theta &lt; u(y) \\mid Y = y) = .95\n\\end{align}\\]\nIntuitively, a Bayesian confidence interval quantifies our uncertainty about the true value of the parameter we are estimating.\nFrequentist confidence interval is an interval \\([l(Y), u(Y)]\\) with the following property:\n\\[\\begin{align}\nP(l(Y) &lt; \\theta &lt; u(Y) \\mid theta) = .95\n\\end{align}\\]\nIntuitively, a Frequentist confidence interval quantifies our uncertainty about the measurement we have made of the parameter with a fixed true value.\nWhich interval is better is of course debated heavily.\nTo construct Bayesian confidence intervals, an easy way of doing so is to select quantiles of the posterior probability distribution such that the area in the interval under the curve is \\(1 - \\alpha\\), where \\(\\alpha\\) is the desired confidence level:\n\nShow R code# Uninformative prior, observe 10 variables with 2 1s\na = 1\nb = 1\nn = 10\ny = 2\n\nquantiles = data.frame(q = qbeta(c(0.025, 0.975), a + y, b + n - y))\n\ndf = data.frame(\n  theta = seq(0, 1, by = 0.001),\n  p = dbeta(seq(0, 1, by = 0.001), a + y, b + n - y)\n)\n\nggplot(df, aes(x = theta, y = p)) +\n  geom_line() +\n  geom_vline(data = quantiles, mapping = aes(xintercept = q))\n\n\n\n\n\n\n\nHowever, since some of the values for theta outside of the interval have higher density than values of theta inside the interval, another option is to force “symmetry” of heights by searching for the highest posterior density region, which can be intuitively found by drawing a horizontal line down the density until the region contained by the line is \\(1 - \\alpha\\)% of the entire curve. It’s not entirely clear to me how to calculate these analytically; computationally, using a discretized density, you can use a “trial and error” approach or a neat procedure detailed in Exercise 4.7 (c)."
  },
  {
    "objectID": "3.html#uniform-prior",
    "href": "3.html#uniform-prior",
    "title": "Chapter 3: One-parameter models",
    "section": "",
    "text": "Imagine our prior is \\(\\theta \\sim \\text{Uniform}(0, 1)\\). What this means is \\(P(a \\leq \\theta \\leq b) = P(a + c \\leq \\theta \\leq b + c)\\) for all compatible \\(a, b, c\\). In other words, the probability of theta falling in an interval of a given width is constant, regardless of where the interval is.\nThen, notice\n\\[\\begin{align}\np(\\theta \\mid y_1, \\dots, y_{129}) &= \\frac{p(y_1, \\dots, y_{129} \\mid \\theta) p(\\theta)}{p(y_1, \\dots, y_{129})} \\\\\n&= \\frac{p(y_1, \\dots, y_{129} \\mid \\theta)}{p(y_1, \\dots, y_{129})} & (\\text{since $p(\\theta)$ is constant for all $\\theta$}) \\\\\n&\\propto p(y_1, \\dots, y_{129} \\mid \\theta)\n\\end{align}\\]\nso \\(p(\\theta \\mid Y)\\) and \\(p(y \\mid \\theta)\\) have the same shape (see MLE discussion in Chapter 1)."
  },
  {
    "objectID": "3.html#data-and-posterior-distribution",
    "href": "3.html#data-and-posterior-distribution",
    "title": "Chapter 3: One-parameter models",
    "section": "",
    "text": "Say the observed proportion is 118 happy out of 129 (91%). Our sampling model for some fixed \\(\\theta\\) is\n\\[\\begin{align}\np(y \\mid \\theta) = \\theta^{118} (1 - \\theta)^{11}\n\\end{align}\\]\nlinking this back to Bayes’ rule above, we have the posterior probability\n\\[\\begin{align}\np(\\theta \\mid y) = \\frac{\\theta^{118} (1 - \\theta)^{11}}{p(y)}\n\\end{align}\\]\nWe will often (WHEN would we not normalize?) want to be more precise than this and know about the scale of the posterior probability, not just the shape. This requires calculating \\(p(y) = p(y_1, \\dots, y_{129})\\):\n\\[\\begin{align}\n1 &= \\int_0^1 p(\\theta \\mid y) \\; d\\theta & (\\text{Law of total probability}) \\\\\n&= \\int_0^1 \\theta^{111} (1 - \\theta)^{11} / p(y) \\; d\\theta \\\\\n&= \\frac{1}{p(y)} \\int_0^1 \\theta^{118} (1 - \\theta)^{11} \\; d\\theta & (\\text{Note\n$p(y)$ is constant for fixed $y$})\\\\\n&= \\frac{1}{p(y)} \\frac{\\Gamma(119) \\Gamma(12)}{\\Gamma(131)} & (\\text{From calculus})\\\\\n\\end{align}\\]\nso \\(p(y) = \\frac{\\Gamma(119) \\Gamma(12)}{\\Gamma(131)} \\approx 2.89 \\times\n10^{-18}\\). Since our \\(y_i\\) are exchangeable, this holds true for any sequences of \\(y_i\\) with 118 ones and 11 zeros.\nSo, finally, the posterior probability is\n\\[\\begin{align}\np(\\theta \\mid y) &= \\frac{\\Gamma(131)}{\\Gamma(119) \\Gamma(12)} \\theta^{118} (1 -\n\\theta)^11 \\\\\n&= \\frac{\\Gamma(131)}{\\Gamma(119) \\Gamma(12)} \\theta^{119 - 1} (1 - \\theta)^{12 - 1} & (\\text{Beta parameterization})\\\\\n\\end{align}\\]\nwhich happens to be a beta distribution with parameters \\(a = 119\\) and \\(b = 12\\).\nIf \\(Y \\sim \\text{Beta}(a, b)\\), then\n\nPDF: \\(p(y) = \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} y^{a - 1} (1 - y)^{b - 1}\\)\n\n\\(\\mathbb{E}(Y) = \\frac{a}{a + b}\\)\n\\(\\text{Mode}(Y) = \\frac{a - 1}{a + b - 2}\\)\n\\(\\text{Var}(Y) = \\frac{ab}{(a + b)^2 (a + b + 1)}\\)\n\nIn our case, our posterior looks like:"
  },
  {
    "objectID": "3.html#inference-for-exchangeable-binary-data-i.e.-more-generally",
    "href": "3.html#inference-for-exchangeable-binary-data-i.e.-more-generally",
    "title": "Chapter 3: One-parameter models",
    "section": "",
    "text": "Recall for our binary data \\(Y_1, \\dots, Y_n\\) that\n\\[\\begin{align}\np(\\theta \\mid y) &= \\frac{p(y \\mid \\theta) p(\\theta)}{p(y)} \\\\\n&= \\frac{\\theta^{\\sum y_i} (1 - \\theta)^{n - \\sum y_i} p(\\theta)}{p(y)} & \\text{(Since i.i.d.)} \\\\\n\\end{align}\\]\nImportantly, the quantity \\(\\sum_{i = 1}^n Y_i\\) is the only statistic that is needed to calculate posterior probabilities of \\(\\theta\\). So it is a sufficient statistic for making inference about \\(\\theta\\). The statistic \\(Y = \\sum Y_i\\) has a binomial distribution with parameters \\((n, \\theta)\\). Then,\n\\[\\begin{align}\np(y \\mid \\theta) &= {n \\choose y} \\theta^y (1 - \\theta)^{n - y}\n\\end{align}\\]\n\nNote: I skip the general derivation of posterior probabilities for uniform prior here, since a uniform prior is also a \\(\\text{Beta}(a, b)\\).\n\nNow let’s calculate the posterior probability \\(p(\\theta \\mid y)\\) when \\(p(\\theta)\\) is not uniform; in particular, when our prior on \\(\\theta\\) is a Beta distribution (\\(\\theta \\sim \\text{Beta}(a,\nb)\\)):\n\\[\\begin{align}\np(\\theta \\mid y) &= \\frac{p(\\theta) p(y \\mid \\theta)}{p(y)} & \\\\\n&= \\frac{1}{p(y)} \\times \\underbrace{\\frac{\\Gamma(a + b)}{\\Gamma(a)\n\\Gamma(b)}\\theta^{a - 1}(1 - \\theta)^{b - 1}}_{\\text{PDF of $\\text{Beta}(a,\nb)$}} \\times \\underbrace{{n \\choose y} \\theta^y (1 - \\theta)^{n -\ny}}_{\\text{$p(y \\mid \\theta)$ above}} & \\\\\n&= c \\times \\theta^{a + y - 1} (1 - \\theta)^{b + n - y - 1} & \\text{(Combine $\\theta$s)} \\\n\\end{align}\\]\\end{align}\nwhere \\(c = f(n, y, a, b)\\) is just compressing the other stuff in the equation into a constant, since it doesn’t depend on \\(\\theta\\). Now, notice that the term with \\(\\Gamma\\)s in the above equation is the PDF of \\(\\theta \\sim \\text{Beta}(a, b)\\), which can also be expressed with a constant \\(c = f(a, b)\\): \\(p(\\theta) = c \\theta^{a - 1}(1\n- \\theta)^{b - 1}\\). Notice that this looks just like the equation above: thus, \\(p(\\theta)\\) and \\(p(\\theta \\mid y)\\) are both proportional to \\(\\theta^{a - 1} (1 -\n\\theta)^{b - 1}\\) by some constant \\(c\\).\nNow, since we know that as probability distributions, \\(\\int p(\\theta) = \\int\np(\\theta \\mid y) \\; d\\theta = 1\\), we also know that the functions share the same scale, which means that \\(p(\\theta \\mid y)\\) is actually a Beta PDF!\n\\[\n(\\theta \\mid y) \\sim \\text{Beta}(a + y, b + n - y).\n\\]\nWe therefore call Beta distributions conjugate priors for Binomial distributions.\n\n\nConjugacy. A class \\(\\mathcal{P}\\) of prior distributions for \\(\\theta\\) are conjugate priors of a sampling model \\(p(y \\mid \\theta)\\) if \\[ p(\\theta) \\in\n\\mathcal{P} \\implies p(\\theta \\mid y) \\in \\mathcal{P}.\\]\n\nConjugate priors are very convenient and making certain calculations easy, since there is some convenient closed form solution for the distribution of a model posterior given a model prior and observed data.\nNow, if you remember from Chatper 1, since the expectation of a Beta distribution is \\(\\frac{a}{a + b}\\),\n\\[\\begin{align}\n\\mathbb{E}(\\theta \\mid y) &= \\frac{a + y}{a + b + n} \\\\\n&= \\frac{a + b}{a + b + n} \\frac{a}{a + b} + \\frac{n}{a + b + n}\\frac{y}{n} \\\\\n\\end{align}\\]\nWhere \\(\\theta_0 = \\frac{a}{a + b}\\) can be seen as our “prior expectation”, \\(\\frac{y}{n}\\) is the sample mean, and \\(w = a + b\\) can be seen as the strength of belief in our prior. I leave the equation expressed above with the \\(a\\)s and \\(b\\)s expanded because another intuitive way of thinking about the problem is by thinking of \\(a\\) as the “prior number of 1s”, \\(b\\) as the “prior number of 0s”, and \\(a + b\\) as the “prior sample size”. If you play around with the equation above, seeing how the values change with various \\(a\\) and \\(b\\) prior choices, you’ll notice it has several nice properties that intuitively balance the expectation and strength of our prior with the amount of data we receive.\n\nAssume we’ve already seen data \\(y_1, \\dots y_n\\) and we want to predict value of the next observation \\(\\tilde{Y}\\). Intuitively we should predict \\(\\tilde{Y} = 1\\) with probability equal to the expectation of \\(\\theta\\) given our data (according to the Bayesian framework). These calculations confirm this:\n\\[\\begin{align}\np(\\tilde{Y} = 1 \\mid y) &= \\int p(\\tilde{Y} = 1, \\theta \\mid y) \\; d\\theta & \\text{(LTP)} \\\\\n&= \\int p(\\tilde{Y} = 1 \\mid \\theta, y) p(\\theta \\mid y) \\; d\\theta & \\text{(Chain rule)} \\\\\n&= \\int \\theta p(\\theta \\mid y) \\; d\\theta & \\text{(Since $\\tilde{Y}$ is binary)} \\\\\n&= \\mathbb{E}(\\theta \\mid y).\n\\end{align}\\]\nNote that in this case the posterior predictive distribution is very easy to predict and is (as it can only possibly be) a Bernoulli distribution with a certain probability \\(p\\). When posterior distributions become more complicated, however, (e.g. Poisson model), their posterior predictive distributions may require more complex calculations and may result in a different family of distributions. Still later, we will show how to simulate posterior predictive distributions with Monte Carlo sampling.\nAlso note that using the expectation instead of the mode is nice, for examples where we have a uniform \\(\\text{Beta}(1, 1)\\) prior and we observe \\(Y = 0\\). Then,\n\\[\\begin{align}\n\\mathbb{E}(\\theta \\mid Y = 0) &= \\frac{2}{2 + n}\\frac{1}{2} + \\frac{n}{2 +\nn}\\frac{y}{n} = \\frac{1}{2 + n}\\\\\n\\theta_{MAP} &= \\frac{y}{n} = 0 \\\\\n\\end{align}\\]\nAnd clearly the expectation is more sensible as a predictor of future \\(\\tilde{Y}\\). But \\(\\theta_{MAP}\\) is not as unreasonable when there is a non-uniform prior…"
  },
  {
    "objectID": "3.html#confidence-regions",
    "href": "3.html#confidence-regions",
    "title": "Chapter 3: One-parameter models",
    "section": "",
    "text": "See this StackExchange question for a really interesting discussiona bout the difference between Bayesian and frequentist confidence intervals.\nBayesian confidence interval is an interval \\([l(y), u(y)]\\) with the following property:\n\\[\\begin{align}\nP(l(y) &lt; \\theta &lt; u(y) \\mid Y = y) = .95\n\\end{align}\\]\nIntuitively, a Bayesian confidence interval quantifies our uncertainty about the true value of the parameter we are estimating.\nFrequentist confidence interval is an interval \\([l(Y), u(Y)]\\) with the following property:\n\\[\\begin{align}\nP(l(Y) &lt; \\theta &lt; u(Y) \\mid theta) = .95\n\\end{align}\\]\nIntuitively, a Frequentist confidence interval quantifies our uncertainty about the measurement we have made of the parameter with a fixed true value.\nWhich interval is better is of course debated heavily.\nTo construct Bayesian confidence intervals, an easy way of doing so is to select quantiles of the posterior probability distribution such that the area in the interval under the curve is \\(1 - \\alpha\\), where \\(\\alpha\\) is the desired confidence level:\n\nShow R code# Uninformative prior, observe 10 variables with 2 1s\na = 1\nb = 1\nn = 10\ny = 2\n\nquantiles = data.frame(q = qbeta(c(0.025, 0.975), a + y, b + n - y))\n\ndf = data.frame(\n  theta = seq(0, 1, by = 0.001),\n  p = dbeta(seq(0, 1, by = 0.001), a + y, b + n - y)\n)\n\nggplot(df, aes(x = theta, y = p)) +\n  geom_line() +\n  geom_vline(data = quantiles, mapping = aes(xintercept = q))\n\n\n\n\n\n\n\nHowever, since some of the values for theta outside of the interval have higher density than values of theta inside the interval, another option is to force “symmetry” of heights by searching for the highest posterior density region, which can be intuitively found by drawing a horizontal line down the density until the region contained by the line is \\(1 - \\alpha\\)% of the entire curve. It’s not entirely clear to me how to calculate these analytically; computationally, using a discretized density, you can use a “trial and error” approach or a neat procedure detailed in Exercise 4.7 (c)."
  },
  {
    "objectID": "3.html#posterior-inference",
    "href": "3.html#posterior-inference",
    "title": "Chapter 3: One-parameter models",
    "section": "\n2.1 Posterior inference",
    "text": "2.1 Posterior inference\nJust like how \\(Y = \\sum Y_i\\) is a sufficient statistic for \\(n\\) independent Bernoulli trials, there exists a sufficient statistic for a sample of \\(n\\) i.i.d. Poisson variables. Notice\n\\[\\begin{align}\nP(Y_1 = y_1, \\dots, Y_n = y_n \\mid \\theta) &=\n\\prod_i p(y_i \\mid \\theta) \\\\\n&= \\prod_i \\frac{\\theta^{y_i} e^{-\\theta}}{y_i !} \\\\\n&= \\theta^{\\sum_i y_i} e^{-n \\theta} \\prod_i \\frac{1}{y_i !} & \\\\\n\\end{align}\\]\nWhen we compare two values of \\(\\theta\\),\n\\[\\begin{align}\n\\frac{p(\\theta_a \\mid y_1, \\dots, y_n)}{p(\\theta_b \\mid y_1, \\dots, y_n)} &= \\dots\n\\end{align}\\]\nnotice that the \\(\\prod_i 1 / y_i !\\) term is the same in that ratio, and thus cancels out. Then the \\(\\theta_{a, b}^{\\sum_i y_i}\\) terms are the only terms remaining in the fraction, and thus \\(\\sum_i y_i\\) is a sufficient statistic. This sufficient statistic is a little more interesting than the Bernoulli case - consider that it doesn’t matter what the individual values of \\(y_i\\) are (if one is very large, one is very small, or they all look the same) - inference on \\(\\theta\\) is possible with just the aggregate sum.\n\n2.1.1 Conjugate prior\nUsing Bayes’ rule and the sampling model above, we have\n\\[\\begin{align}\np(\\theta \\mid y) &= \\frac{p(\\theta)p(y \\mid \\theta)}{p(y)} \\\\\n&\\propto p(\\theta) p(y \\mid \\theta) \\\\\n&\\propto p(\\theta) \\times \\theta^{\\sum y_i} e^{-n\\theta} \\\\\n\\end{align}\\]\nWe are looking for some distribution of \\(p(\\theta)\\) that makes the posterior as calculated using the above the same distribution as \\(p(\\theta)\\) itself. That family of distributions is the Gamma family. If \\(\\theta \\sim \\text{Gamma}(a, b)\\), then\n\n\\(p(\\theta) = \\frac{b^a}{\\Gamma(a)}\\theta^{a - 1} e^{-b \\theta}\\)\n\\(\\mathbb{E}(\\theta) = a/b\\)\n\\(\\text{Var}(\\theta) = a/b^2\\)\n\nTo prove conjugacy, we have\n\\[\\begin{align}\np(\\theta \\mid y) &= \\frac{p(\\theta) p(y \\mid \\theta)}{p(y)} \\\\\n&= \\underbrace{\\left( \\frac{b^a}{\\Gamma(a)} \\theta^{a - 1} e^{-b \\theta}\n\\right)}_{p(\\theta)} \\underbrace{\\left( \\theta^{\\sum y_i} e^{-n \\theta} \\prod_i\n\\frac{1}{y_i !} \\right)}_{p(y \\mid \\theta)} \\left( \\frac{1}{p(y)} \\right) \\\\\n&= c \\times \\left( \\theta^{a - 1 + \\sum y_i} e^{-(b + n) \\theta} \\right)\n\\end{align}\\]\nWhere \\(c = f(y, a, b)\\) is throwing all of the stuff that doesn’t depend on \\(\\theta\\) into some normalizing constant such that \\(\\int p(\\theta \\mid y) \\; d\\theta = 1\\). Like the Binomial model, we recognize from the proportionality to \\(\\theta^{a - 1} e^{-b \\theta}\\) that the posterior distribution of \\(\\theta\\) is Gamma distributed. Specifically\n\\[\\begin{align}\n\\theta \\mid y_1, \\dots, y_n \\sim \\text{Gamma}(a + \\sum_i y_i, b + n)\n\\end{align}\\]\nand the expectation is\n\\[\\begin{align}\n\\mathbb{E}(\\theta \\mid y_1, \\dots, y_n) &= \\frac{a + \\sum y_i}{b + n} \\\\\n&= \\frac{b}{b + n} \\frac{a}{b} + \\frac{n}{b + n}\\frac{\\sum y_i}{n} \\\\\n\\end{align}\\]\n\n2.1.2 Posterior predictive distribution\n\\[\\begin{align}\np(\\tilde{y} \\mid y_1, \\dots, y_n) &= \\int_0^{\\infty} p(\\tilde{y} \\mid \\theta, y_1, \\dots, y_n) p(\\theta \\mid y_1, \\dots, y_n) \\; d\\theta & \\text{Marginalization} \\\\\n&= \\int_0^{\\infty} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y_1, \\dots, y_n) \\; d\\theta & \\text{Since $\\tilde{y}$ and $y_i$s c.i. given $\\theta$} \\\\\n&= \\int_0^{\\infty} \\left[ \\frac{\\theta^{\\tilde{y}} e^{-\\theta}}{\\tilde{y}!} \\right] \\times \\left[ \\frac{(b + n)^{a + \\sum y_i}}{\\Gamma(a + \\sum y_i)} \\theta^{a + \\sum y_i - 1} e^{-(b + n)\\theta} \\right] \\; d\\theta \\\\\n&= \\int_0^{\\infty} \\left[ \\frac{\\theta^{\\tilde{y} + a + \\sum y_i - 1} e^{-(b + n + 1)\\theta}}{\\tilde{y}!} \\right] \\times \\left[ \\frac{(b + n)^{a + \\sum y_i}}{\\Gamma(a + \\sum y_i)} \\right] \\; d\\theta & \\text{Combine $\\theta$s, $e$s} \\\\\n&= \\frac{(b + n)^{a + \\sum y_i}}{\\Gamma(\\tilde{y} + 1) \\Gamma(a + \\sum y_i)} \\int_0^{\\infty} \\theta^{\\tilde{y} + a + \\sum y_i - 1} e^{-(b + n + 1)\\theta} \\; d\\theta \\\\\n\\end{align}\\]\nNotice that the integrand is proportional to a Gamma density:\n\\[\\begin{align}\n& \\int_0^{\\infty} \\frac{b^a}{\\Gamma(a)} \\theta^{a - 1} e^{-b \\theta} \\; d\\theta = 1\\\\\n\\implies& \\int_0^{\\infty} \\theta^{a - 1} e^{-b\\theta} \\; d\\theta = \\frac{\\Gamma(a)}{b^a} \\\\\n\\end{align}\\]\nSo\n\\[\\begin{align}\np(\\tilde{y} \\mid y_1, \\dots, y_n) &= \\dots \\\\\n&= \\left( \\frac{(b + n)^{a + \\sum y_i}}{\\Gamma(\\tilde{y} + 1) \\Gamma(a + \\sum y_i)} \\right) \\left( \\frac{\\Gamma(\\tilde{y} + a + \\sum y_i)}{(b + n + 1)^{\\tilde{y} + a + \\sum y_i}} \\right) \\\\\n&= \\left( \\frac{\\Gamma(\\tilde{y} + a + \\sum y_i)}{\\Gamma(\\tilde{y} + 1) \\Gamma(a + \\sum y_i)} \\right) \\left( \\frac{(b + n)^{a + \\sum y_i}}{(b + n + 1)^{\\tilde{y} + a + \\sum y_i}} \\right) & \\text{Swapping numerators} \\\\\n&= \\left( \\frac{\\Gamma(\\tilde{y} + a + \\sum y_i)}{\\Gamma(\\tilde{y} + 1) \\Gamma(a + \\sum y_i)} \\right) \\left( \\frac{b + n}{b + n + 1} \\right)^{a + \\sum y_i} \\left( \\frac{1}{b + n + 1} \\right)^{\\tilde{y}} \\\\\n&= \\text{dnbinom}(\\tilde{y}, a + \\sum y_i, b + n) \\\\\n\\end{align}\\]\nThe negative binomial distribution here, whose parameters look just like the Gamma posterior on theta, can be thought of as a predictive Poisson distribution with increased variance owing to the increased uncertainty on the value of \\(\\theta\\). Notice\n\\[\\begin{align}\n\\mathbb{E}(\\tilde{Y} \\mid y_1, \\dots, y_n) &= \\frac{a + \\sum y_i}{b + n} = \\mathbb{E}(\\theta \\mid y_1, \\dots, y_n) \\\\\n\\text{Var}(\\tilde{Y} \\mid y_1, \\dots, y_n) &= \\frac{a + \\sum y_i}{b + n} \\frac{b\n+ n + 1}{b + n} = \\mathbb{E}(\\theta \\mid y_1, \\dots, y_n) \\times \\frac{b + n + 1}{b + n}\n\\\\\n\\end{align}\\]\nSo as \\(n\\) grows large, the variance on \\(\\tilde{Y}\\) approaches the variance of its expectation \\(\\mathbb{E}(\\tilde{Y})\\)."
  },
  {
    "objectID": "3.html#example-birth-rates",
    "href": "3.html#example-birth-rates",
    "title": "Chapter 3: One-parameter models",
    "section": "\n2.2 Example: Birth Rates",
    "text": "2.2 Example: Birth Rates\nIn the 1990s, did women with college degrees have different numbers of children than women without college degrees? We sample \\(n_1\\) women without college degrees, denoted \\(Y_{1,1}, \\dots, Y_{n_1, 1}\\), and \\(n_2\\) women with college degrees, \\(Y_{1, 2}, \\dots, Y_{n_2, 2}\\). For some parameter \\(\\theta\\) we can model the number of children for each woman as being i.i.d \\(\\text{Poisson}(\\theta_1)\\) and \\(\\text{Poisson}(\\theta_2)\\), respectively. We may be interested in conducting hypothesis tests to see whether or not these \\(\\theta\\) are different.\nRecall that, in this two samples, the sufficient statistic is simply the sum of all of the \\(Y_i\\). Say we observe\n\nNo college: \\(n_1 = 111\\), \\(\\sum Y_i = 217\\), \\(\\sum Y_i / n_1 = 1.95\\) (this is just useful for intuition)\nCollege: \\(n_2 = 44\\), \\(\\sum Y_i = 66\\), \\(\\sum Y_i / n_2 = 1.50\\)\n\n\nSay our prior on both \\(\\theta\\) is \\(\\text{Gamma(a = 2, 1)}\\), which is lightly centered on ~1. You can toy around with choices of different priors by changing a and b below:\n\nShow R codea = 2\nb = 1\nn1 = 111\nsy1 = 217\nn2 = 44\nsy2 = 66\ndf = data.frame(\n  theta = seq(0, 5, by = 0.01),\n  prior = dgamma(seq(0, 5, by = 0.01), a, b),\n  pos.theta1 = dgamma(seq(0, 5, by = 0.01), a + sy1, b + n1),\n  pos.theta2 = dgamma(seq(0, 5, by = 0.01), a + sy2, b + n2)\n)\ndf.long = melt(df, id.vars = 'theta', variable_name = 'dist')\nggplot(df.long, aes(x = theta, y = value, group = dist, color = dist)) +\n  geom_line() +\n  ylab('probability')\n\n\n\n\n\n\n\nNotice that we can calculate the probability that \\(\\theta_1 &gt; \\theta_2\\) by integrating over the joint density \\(p(\\theta_1, \\theta_2)\\) over the region where \\(\\theta_1 &gt; \\theta_2\\). This is calculated at the beginning of Chapter 4, and it is about 0.97."
  },
  {
    "objectID": "3.html#example-binomial-model",
    "href": "3.html#example-binomial-model",
    "title": "Chapter 3: One-parameter models",
    "section": "\n3.1 Example: Binomial model",
    "text": "3.1 Example: Binomial model\n\n3.1.1 Parameterization\nWe can obtain the representation from a single binary random variable (why?)\n\\[p(y \\mid \\theta) = \\theta^{y} (1 - \\theta)^{1 - y}\\]\nWe can express this as an exponential family model by reparameterizing by the log odds \\(\\phi = \\log \\frac{\\theta}{1 - \\theta}\\), so that \\(\\theta = \\frac{e^\\phi}{e^\\phi + 1}\\):\n\\[\\begin{align}\np(y \\mid \\phi) &= \\left( \\frac{e^\\phi}{e^\\phi + 1} \\right)^y \\left(\\frac{1}{e^\\phi + 1} \\right)^{1 - y} \\\\\n&= \\frac{e^{\\phi y}}{(e^\\phi + 1)^y} \\frac{1}{e^\\phi + 1} \\left( e^\\phi + 1\\right)^y \\\\\n&= e^{\\phi y} (1 + e^\\phi)^{-1} \\\\\n\\end{align}\\]\nHere,\n\n\\(h(y) = 1\\)\n\\(c(\\phi) = (1 + e^\\phi)^{-1}\\)\n\\(t(y) = y\\)\n\n(It’s intuitive that the sufficient statistic is \\(y\\))\n\n3.1.2 Prior\nThe conjugate prior on \\(\\phi\\) (discarding the constant \\(\\kappa\\)) is\n\\[\\begin{align}\np(\\phi \\mid n_0, t_0) &\\propto (1 + e^{\\phi})^{-n_0} e^{n_0 t_0 \\phi}\n\\end{align}\\]\nTo return to a density on \\(\\theta\\), let \\(\\theta = g(\\phi) = \\frac{e^\\phi}{e^\\phi\n+ 1}\\) and \\(\\phi = h(\\theta) = \\log \\frac{\\theta}{1 - \\theta}\\). Then, using the change of variables formula (Exercise 3.10),\n\\[\\begin{align}\np_{\\theta}(\\theta \\mid n_0, t_0) &= p_{\\phi}(h(\\theta) \\mid n_0, t_0) \\times \\left| \\frac{dh}{d\\theta} \\right| \\\\\n&\\propto \\left(1 + \\text{exp}\\left(\\log \\left(\\frac{\\theta}{1 - \\theta}\\right)\\right)\\right)^{-n_0} \\text{exp}\\left(n_0 t_0 \\log \\left(\\frac{\\theta}{1 - \\theta}\\right) \\right) \\times \\frac{1}{\\theta - \\theta^2} \\\\\n&\\propto \\left(1 + \\frac{\\theta}{1 - \\theta} \\right)^{-n_0} \\left(\\frac{\\theta}{1 - \\theta}\\right)^{n_0 t_0} \\times \\frac{1}{\\theta - \\theta^2} \\\\\n&\\propto \\left(\\frac{1}{1 - \\theta} \\right)^{-n_0} \\left(\\frac{\\theta}{1 - \\theta}\\right)^{n_0 t_0} \\times \\frac{1}{\\theta (1 - \\theta)} \\\\\n&\\propto (1 - \\theta)^{n_0} \\theta^{n_0 t_0} (1 - \\theta)^{-n_0 t_0} \\theta^{-1} (1 - \\theta)^{-1} \\\\\n&\\propto \\theta^{n_0 t_0 - 1} (1 - \\theta)^{n_0 - n_0t_0 - 1} \\\\\n&\\propto \\theta^{n_0 t_0 - 1} (1 - \\theta)^{n_0 (1 - t_0) - 1} \\\\\n&= \\text{dbeta}(\\theta, n_0 t_0, n_0 (1 - t_0))\n\\end{align}\\]\nSo the posterior is\n\\[\\begin{align}\np(\\theta \\mid y_1, \\dots, y_n) &= \\text{dbeta}\\left(\\theta,\\; (n_0 + n)\\left(n_0 t_0 + \\sum t(y_i) \\right),\\; (n_0 + n) \\left(1 - n_0 t_0 - \\sum t(y_i) \\right) \\right)\n\\end{align}\\]"
  },
  {
    "objectID": "3.html#example-poisson-model",
    "href": "3.html#example-poisson-model",
    "title": "Chapter 3: One-parameter models",
    "section": "\n3.2 Example: Poisson model",
    "text": "3.2 Example: Poisson model\n\n3.2.1 Parameterization\n\\[\\begin{align}\np(y \\mid \\theta) &= \\frac{1}{y!} \\theta^{y} e^{-\\theta} \\\\\n&= \\frac{1}{y!} e^{y \\log \\theta} \\text{exp}(-e^{\\log \\theta}) \\\\\n&= h(y) c(\\phi) e^{\\phi t(y)} \\\\\n\\end{align}\\]\nwhere\n\n\\(\\phi = \\log \\theta\\)\n\\(h(y) = \\frac{1}{y!}\\)\n\\(t(y) = y\\)\n\n\\(c(\\phi) = \\text{exp}(-e^\\phi)\\) (The book has a typo here).\n\n3.2.2 Prior\nThen the prior is \\(p(\\phi \\mid n_0, t_0) = \\text{exp}(n_0 e^{-\\phi}) e^{n_0 t_0\n\\phi}\\). For time, I will do change of variables to show how this induces a \\(\\text{Gamma}(n_0 t_0, n_0)\\) density on \\(\\theta\\)."
  },
  {
    "objectID": "3.html#section",
    "href": "3.html#section",
    "title": "Chapter 3: One-parameter models",
    "section": "\n4.1 3.1",
    "text": "4.1 3.1\n\n4.1.1 a\n\\[\\begin{align}\nP(Y_1 = y_1, \\dots, Y_{100} &= y_100 \\mid \\theta) &= \\theta^{\\sum y_i} (1 - \\theta)^{100 - \\sum y_i} \\\\\nP(\\sum Y_i = y \\mid \\theta) &= {100 \\choose y} \\theta^{y}(1 - \\theta)^{100 - y}\n\\end{align}\\]\n\n4.1.2 b\n\nShow R code# Hand-implementing this, but you can use dbinom easily\nmy_dbinom = function(y, n, theta) choose(n, y) * theta^y * (1 - theta)^(n - y)\ntheta.discrete = seq(0, 1, by = 0.1)\n\nY = 57\nN = 100\n\nps = sapply(theta.discrete, function(theta) my_dbinom(Y, N, theta))\n\ndf = data.frame(theta = theta.discrete, p = ps)\nprint(round(df, 3))\n#&gt;    theta     p\n#&gt; 1    0.0 0.000\n#&gt; 2    0.1 0.000\n#&gt; 3    0.2 0.000\n#&gt; 4    0.3 0.000\n#&gt; 5    0.4 0.000\n#&gt; 6    0.5 0.030\n#&gt; 7    0.6 0.067\n#&gt; 8    0.7 0.002\n#&gt; 9    0.8 0.000\n#&gt; 10   0.9 0.000\n#&gt; 11   1.0 0.000\n\nggplot(df, aes(x = theta, y = p)) +\n  geom_bar(stat = 'identity') +\n  scale_x_continuous(breaks = theta.discrete)\n\n\n\n\n\n\n\n\n4.1.3 c\nIf we have a uniform prior on beliefs of \\(\\theta \\in \\{0, 0.1, \\dots, 1.0\\}\\), then \\(P(\\theta = 0.0) = P(\\theta = 0.1) = \\dots = 1/11\\).\n\\[\\begin{align}\np(\\theta \\mid \\sum Y_i = 57) &= \\frac{p(\\sum Y_i = 57 \\mid \\theta)p(\\theta)}{p(\\sum Y_i = 57)} \\\\\n&= \\frac{p(\\sum Y_i = 57 \\mid \\theta)p(\\theta)}{\\sum_{\\theta'} p(\\sum Y_i = 57 \\mid \\theta') p(\\theta')}\n\\end{align}\\]\nNotice that \\(p(\\theta)\\) is constant for all \\(\\theta\\), so it can be pulled out of the sum at the bottom and cancelled with the numerator:\n\\[\\begin{align}\np(\\theta \\mid \\sum Y_i = 57)\n&= \\frac{p(\\sum Y_i = 57 \\mid \\theta)}{\\sum_{\\theta'} p(\\sum Y_i = 57 \\mid \\theta')} \\\\\n&\\propto p(\\sum Y_i = 57 \\mid \\theta)\n\\end{align}\\]\nsince the denominator is the constant\n\nShow R codedenom = sum(ps)\nprint(round(denom, 3))\n#&gt; [1] 0.099\n\n\nSo the posterior distribution has the same shape, but different scale.\n\nShow R codeposteriors = sapply(theta.discrete, function(theta) my_dbinom(Y, N, theta) / denom)\n\ndf = data.frame(theta = theta.discrete, p = posteriors)\nprint(round(df, 3))\n#&gt;    theta     p\n#&gt; 1    0.0 0.000\n#&gt; 2    0.1 0.000\n#&gt; 3    0.2 0.000\n#&gt; 4    0.3 0.000\n#&gt; 5    0.4 0.002\n#&gt; 6    0.5 0.304\n#&gt; 7    0.6 0.675\n#&gt; 8    0.7 0.019\n#&gt; 9    0.8 0.000\n#&gt; 10   0.9 0.000\n#&gt; 11   1.0 0.000\n\nggplot(df, aes(x = theta, y = p)) +\n  geom_bar(stat = 'identity') +\n  scale_x_continuous(breaks = theta.discrete)\n\n\n\n\n\n\n\nNotice the denominator calculation could have been ignored - we could simply normalize the proportional prior densities \\(p(\\sum Y_i = 57 \\mid \\theta)\\) to 1.\n\n4.1.4 d\nSince \\(p(\\theta) = 1\\), the density \\(p(\\theta) \\times P(\\sum Y_i = 57 \\mid\n\\theta) = P(\\sum Y_i = 57 \\mid \\theta)\\). From (a),\n\\[\nP(\\sum Y_i = 57 \\mid \\theta) = {100 \\choose 57} \\theta^{57} (1 - \\theta)^{43}\n\\]\nwhich is implemented in the my_dbinom function. So\n\nShow R codetheta.continuous = seq(0, 1, by = 0.001)\nqplot(theta.continuous, sapply(theta.continuous, function(theta) my_dbinom(Y, N, theta)),\n      geom = 'line')\n\n\n\n\n\n\n\n\n4.1.5 e\nTreat the uniform prior as a \\(\\text{Beta}(1, 1)\\) distribution. Then \\(\\left(\n\\theta \\mid \\sum Y_i = y \\right) \\sim \\text{Beta}(58, 44)\\).\n\nShow R codeqplot(theta.continuous, dbeta(theta.continuous, 58, 44), geom = 'line')\n\n\n\n\n\n\n\n\nis the posterior density before normalization by the constant \\(p(\\sum Y_i = 57) = 0.099\\). (e) is the posterior density fully, after normalization. Notice that (d) and (e) have the same shape, due to the lack of influence of \\(p(\\theta)\\) on posterior calculation."
  },
  {
    "objectID": "3.html#section-1",
    "href": "3.html#section-1",
    "title": "Chapter 3: One-parameter models",
    "section": "\n4.2 3.2",
    "text": "4.2 3.2\nFor consistency, I will rewrite these as done in Chapter 1, where \\(\\theta_0 = a\n/ (a + b)\\) is the initial guess of \\(\\theta\\) and \\(w = a + b\\) is the strength of that guess. Then,\n\nShow R code# What is the expected value of theta after observing result y, given a Beta\n# prior parameterized by theta0 and w?\nN = 100\nexp.posterior = function(w, theta0, y) {\n  (N / (w + N)) * (y / N) + (w / (w + N)) * theta0\n}\nTheta0 = rev(seq(0.0, 1, by = 0.1))\nW = seq(0, 32, by = 0.5)\n\ny = 57\nd = outer(Theta0, W, FUN = function(theta0, w) exp.posterior(w, theta0, 57))\nrownames(d) = Theta0\ncolnames(d) = W\n\ndf = melt(d)\ncolnames(df) = c('theta0', 'w', 'theta')\n\np = ggplot(df, aes(x = w, y = theta0, z = theta)) +\n  geom_contour(aes(colour = ..level..)) +\n  scale_x_continuous(breaks = c(1, 2, 8, 16, 32), labels = c(1, 2, 8, 16, 32)) +\n  scale_y_continuous(breaks = Theta0)\nlibrary(directlabels)\ndirect.label(p, method = 'bottom.pieces')\n\n\n\n\n\n\n\nOne can use this plot to determine whether or not they should believe that \\(\\theta &gt; 0.5\\) by quantifying their prior beliefs about the proportion with two factors: \\(\\theta_0\\), an initial estimate of the true proportion, and \\(w\\), the “sample size” of observed individuals that contributed to the initial estimate. Then, viewing the corresponding contour on this plot would give an estimate of the posterior proportion given these two variables. It is shown here that \\(\\theta &gt; 0.5\\) for most prior beliefs except for those with relatively low and very strong estimates about \\(\\theta_0\\)."
  },
  {
    "objectID": "3.html#section-2",
    "href": "3.html#section-2",
    "title": "Chapter 3: One-parameter models",
    "section": "\n4.3 3.3",
    "text": "4.3 3.3\n\n4.3.1 a\n\nShow R codeya = c(12, 9, 12, 14, 13, 13, 15, 8, 15, 6)\nyb = c(11, 11, 10, 9, 9, 8, 7, 10, 6, 8, 8, 9, 7)\n\n\nNotice that \\(\\sum y_a = 117, n_a = 10, \\sum y_b = 113, n_b = 13\\).\nIf\n\\[\\begin{align}\n\\theta_A &\\sim \\text{Gamma}(120, 10) \\\\\n\\theta_B &\\sim \\text{Gamma}(12, 1)\n\\end{align}\\]\nthen\n\\[\\begin{align}\n\\theta_A \\mid \\mathbf{y}_a &\\sim \\text{Gamma}(120 + 117, 10 + 10) = \\text{Gamma}(237, 20) \\\\\n\\theta_B \\mid \\mathbf{y}_b &\\sim \\text{Gamma}(12 + 113, 1 + 13) = \\text{Gamma}(125, 14) \\\\\n\\end{align}\\]\nSo\n\\[\\begin{align}\n\\mathbb{E}(\\theta_A) &=  237/20 = 11.85\\\\\n\\mathbb{E}(\\theta_A) &= 125/14 = 8.92\\\\\n\\text{Var}(\\theta_A) &= 237/400 = 0.593\\\\\n\\text{Var}(\\theta_B) &= 125/196 = 0.638\\\\\n\\end{align}\\]\n95% quantile-based confidence intervals can be solved by setting the CDF of the Gammas to \\(p\\), and solving for \\(\\theta\\). Alternatively,\n\nShow R codeqgamma(c(0.025, 0.975), 237, 20)\n#&gt; [1] 10.38924 13.40545\nqgamma(c(0.025, 0.975), 125, 14)\n#&gt; [1]  7.432064 10.560308\n\n\n\n4.3.2 b\n\nShow R codeya = c(12, 9, 12, 14, 13, 13, 15, 8, 15, 6)\nyb = c(11, 11, 10, 9, 9, 8, 7, 10, 6, 8, 8, 9, 7)\n\nn0 = 1:50\nexps = (12 * n0 + sum(yb)) / (n0 + length(yb))\nqplot(n0, exps, geom = c('point', 'smooth'))\n\n\n\n\n\n\n\nVery strong prior beliefs that the expected value of \\(\\theta \\approx 12\\) would be necessary, because \\(\\theta_{ML} = 8.69\\) which is quite low. According to the graph \\(n_0\\) values of close to 50 are required.\n\n4.3.3 c\nWe have existing knowledge about population A. Knowing that B is related, we have incorporated these beliefs into our prior on population B. However, nothing more than a weak prior expectation of B to be similar to A should be encoded in our analysis, since it is entirely possible that the parameter of B is quite different from A. So we should view the populations as independent."
  },
  {
    "objectID": "3.html#section-3",
    "href": "3.html#section-3",
    "title": "Chapter 3: One-parameter models",
    "section": "\n4.4 3.4",
    "text": "4.4 3.4\n\n4.4.1 a\nThis is fairly straightforward like 3.1, skipping\n\n4.4.2 b\nThis is fairly straightforward like 3.1, skipping\n\n4.4.3 c\n\nShow R codeprior = function(theta) {\n  (1/4) * (gamma(10) / (gamma(2) * gamma(8))) * \n    (3 * theta * (1 - theta)^7 + theta^7 * (1 - theta))\n}\nthetas = seq(0, 1, by = 0.005)\nqplot(thetas, prior(thetas), geom = 'line')\n\n\n\n\n\n\n\nSome kind of bimodal prior on rates of teen recidivism - for example, you believe that in some regions, teen recidivism is rather low, but there are some regions where teen recidivism is high.\n\n4.4.4 d\ni\n\\[\\begin{align}\np(\\theta) \\times p(y \\mid \\theta) &= \\frac{1}{4}\\frac{\\Gamma(10)}{\\Gamma(2) \\Gamma(8)} \\left[ 3\\theta (1 - \\theta)^7 + \\theta^7 (1 - \\theta) \\right] \\times \\left[ {43 \\choose 15} \\theta^{15} (1 - \\theta)^{28} \\right] \\\\\n&= \\frac{1}{4} \\frac{\\Gamma(44)}{\\Gamma(16) \\Gamma(29)} \\frac{\\Gamma(10)}{\\Gamma(2) \\Gamma(8)} \\left[3\\theta^{16} (1 - \\theta)^{35} + \\theta^{22} (1 - \\theta)^{29} \\right] \\\\\n\\end{align}\\]\nii\nThis is proportional to some mixture with unknown weights of a \\(\\text{Beta}(17,\n36)\\) and a \\(\\text{Beta}(23, 30)\\) which intuitively are the posterior densities in parts a and b.\niii\n\nShow R codeposterior = function(theta) {\n  prior(theta) * choose(43, 15) * theta^15 * (1 - theta)^28\n}\nqplot(thetas, posterior(thetas), geom = 'line')\n\n\n\n\n\n\nShow R codecat(\"Mode:\", thetas[which.max(posterior(thetas))], \"\\n\")\n#&gt; Mode: 0.315\n\n\nNotice that\n\\[\\begin{align}\n\\text{mode}(\\text{Beta}(17, 36)) &= (17 - 1) / (17 + 36 - 2) = 0.313 \\\\\n\\text{mode}(\\text{Beta}(23, 30)) &= (23 - 1) / (23 + 30 - 2) = 0.431\n\\end{align}\\]\nSo the mode is between these two modes, although closer to that of the \\(\\text{Beta}(17, 36)\\).\n\n4.4.5 e\nUnclear: general formula for any beta mixture with any weights and parameters? Or general formula for any observed result for this model, given then prior in c)?"
  },
  {
    "objectID": "3.html#section-4",
    "href": "3.html#section-4",
    "title": "Chapter 3: One-parameter models",
    "section": "\n4.5 3.5",
    "text": "4.5 3.5\n\n4.5.1 a\nFirst,\n\\[\\begin{align}\n\\tilde{p} &= \\sum_{k = 1}^K w_k p_k (\\theta \\mid n_{0, k}, t_{0, k}) \\\\\n&= \\sum_{k = 1}^K \\left( w_k \\kappa (n_{0, k}, t_{0, k}) c(\\phi)^{n_{0, k}} \\text{exp}(n_{0, k} t_{0, k} \\phi) \\right) \\\\\n\\end{align}\\]\nNow\n\\[\\begin{align}\np(\\phi \\mid y_1, \\dots, y_n) &\\propto p(\\phi) p(y_1, \\dots, y_n \\mid \\phi) \\\\\n\n&\\propto \\left[ \\sum_{k = 1}^K \\left( w_k \\kappa (n_{0, k}, t_{0, k}) c(\\phi)^{n_{0, k}} \\text{exp}(n_{0, k} t_{0, k} \\phi) \\right)  \\right] \\times \\left[ \\prod_{i = 1}^n h(y_i) c(\\phi) \\text{exp}(\\phi t(y_i)) \\right] \\\\\n&\\propto \\left[ \\sum_{k = 1}^K \\left( w_k \\kappa (n_{0, k}, t_{0, k}) c(\\phi)^{n_{0, k}} \\text{exp}(n_{0, k} t_{0, k} \\phi) \\right)  \\right] \\times \\left[ \\text{exp}\\left(\\phi \\sum_{i = 1}^n t(y_i)\\right) c(\\phi)^n \\prod_{i = 1}^n h(y_i) \\right] \\\\\n&\\propto \\left[ \\sum_{k = 1}^K \\left( w_k \\kappa (n_{0, k}, t_{0, k}) c(\\phi)^{n_{0, k}} \\text{exp}(n_{0, k} t_{0, k} \\phi) \\right)  \\right] \\times \\left[ \\text{exp}\\left(\\phi \\sum_{i = 1}^n t(y_i)\\right) c(\\phi)^n \\right] \\\\\n&\\propto \\sum_{k = 1}^K \\left( w_k \\kappa (n_{0, k}, t_{0, k}) c(\\phi)^{n_{0, k} + n} \\text{exp}\\left(\\phi \\times \\left[ n_{0, k} t_{0, k}+ \\sum_{i = 1}^n t(y_i) \\right] \\right) \\right) \\\\\n&\\propto \\sum_{k = 1}^K w_k p\\left(\\theta \\; \\middle| \\; n_0 + n, \\; n_0 t_0 + \\sum_{i = 1}^{n} t(y_i)\\right)\n\\end{align}\\]\nSo the posterior is another weighted mixture. However I don’t believe the weights of the relative components are preserved (neither are they in the Beta mixtures above).\n\n4.5.2 b\nNot specified whether we need to use the exponential family parameterization or the standard parameterization. I will use the standard parameterization.\nLet \\[\\begin{align}\n\\tilde{p} &= \\sum_{k = 1}^K w_k p_k (\\theta \\mid a_k, b_k) \\\\\n&= \\sum_{k = 1}^K \\left( w_k \\frac{b_k^{a_k}}{\\Gamma(a_k)} x^{a_k - 1} e^{-b_k x} \\right) \\\\\n\\end{align}\\]\nThen \\[\\begin{align}\np(\\theta \\mid y_1, \\dots, y_n) &\\propto p(\\theta) p(y_1, \\dots, y_n \\mid \\theta) \\\\\n&\\propto \\left[ \\sum_{k = 1}^K \\left( w_k \\frac{b_k^{a_k}}{\\Gamma(a_k)} \\theta^{a_k - 1} e^{-b_k \\theta} \\right) \\right] \\times \\left[ \\prod_{i = 1}^n \\frac{1}{y_i !} \\theta^{y_i} e^{-\\theta} \\right] \\\\\n&\\propto \\left[ \\sum_{k = 1}^K \\left( w_k \\frac{b_k^{a_k}}{\\Gamma(a_k)} \\theta^{a_k - 1} e^{-b_k \\theta} \\right) \\right] \\times \\left[ \\theta^{\\sum y_i} e^{-n\\theta} \\right] \\\\\n&\\propto \\sum_{k = 1}^K \\left( w_k \\frac{b_k^{a_k}}{\\Gamma(a_k)} \\theta^{a_k + \\sum y_i - 1} e^{-(b_k + n)\\theta} \\right) \\\\\n&\\propto \\sum_{k = 1}^K w_k p\\left(\\theta \\; \\middle| \\; a_k + \\sum y_i, \\; b_k + n \\right) \\\\\n\\end{align}\\]"
  },
  {
    "objectID": "3.html#section-5",
    "href": "3.html#section-5",
    "title": "Chapter 3: One-parameter models",
    "section": "\n4.6 3.9",
    "text": "4.6 3.9\n\n4.6.1 a\nWe take advantage of the fact that the Galenshore distribution can be viewed as an exponential model\n\\[\\begin{align}\np(y \\mid \\theta) &= \\frac{2}{\\Gamma(a)} \\theta^{2a} y^{2a - 1} e^{-\\theta^2 y^2} \\\\\n&= \\left( \\frac{2}{\\Gamma(a)} y^{2a - 1} \\right) \\times \\left(\\theta^{2a} \\right) \\times \\left( e^{-\\theta^2 y^2} \\right) \\\\\n&= \\left( \\frac{2}{\\Gamma(a)} y^{2a - 1} \\right) \\times \\left(\\theta^2 \\right)^a \\times \\left( e^{\\left(\\theta^2\\right) -y^2} \\right) \\\\\n&= h(y) c(\\phi) e^{\\phi t(y)}\n\\end{align}\\]\nWhere\n\n\\(h(y) = \\frac{2}{\\Gamma(a)} y^{2a - 1}\\)\n\\(c(\\phi) = \\phi^a\\)\n\\(t(y) = -(y^2)\\)\n\\(\\phi = \\theta^2\\)\n\nThen, the conjugate priors for the \\(\\phi\\) parameterization are given by\n\\[\\begin{align}\np(\\phi \\mid n_0, t_0) &= \\kappa (n_0, t_0) \\phi^{a n_0} \\text{exp}(n_0 t_0 \\phi) \\\\\n&\\propto \\phi^{a n_0} \\text{exp}(n_0 t_0 \\phi) \\\\\n\\end{align}\\]\nTo obtain the priors for \\(\\theta\\), let \\(\\theta = g(\\phi) = \\sqrt{\\phi}\\) and \\(\\phi = h(\\theta) = \\theta^2\\). Notice \\(dh/d\\theta = 2\\theta\\). By the change of variables formula,\n\\[\\begin{align}\np(\\theta \\mid n_0, t_0) &= p(h(\\theta) \\mid n_0, t_0) \\times \\left| \\frac{dh}{d\\theta} \\right| \\\\\n&\\propto \\kappa(n_0, t_0) \\theta^{2a n_0} \\text{exp}\\left( n_0 t_0 \\theta^2 \\right) \\times 2 \\theta \\\\\n&\\propto \\theta^{2a n_0 + 1} \\text{exp}\\left( n_0 t_0 \\theta^2 \\right) \\\\\n&\\propto \\text{dgalenshore}\\left(\\theta, \\underbrace{a n_0 + 1}_{a_{\\text{Galenshore}}}, \\underbrace{\\sqrt{-n_0 t_0}}_{\\theta_{\\text{Galenshore}}} \\right)\n\\end{align}\\]\nNotice this is true since \\(\\text{dgalenshore}(y, a, \\theta) \\propto y^{2a - 1}\ne^{- \\theta^2 y^2}\\) - the rest of the PDF is a constant that doesn’t depend on \\(y\\). Also notice that \\(\\sqrt{-n_0 t_0}\\) is defined since \\(n_0 &gt; 0\\) and \\(t_0\\) is the initial “guess” of \\(t(y) = - (y^2) &lt; 0\\), so \\(-n_0 t_0 &gt; 0\\).\n\nShow R codedgalenshore = function(y, a, theta) {\n  (2 / gamma(a)) * theta^(2 * a) * y^(2 * a - 1) * exp(-1 * (theta^2) * y^2)\n}\ny = seq(0.02, 5, by = 0.02)\ndf = rbind(\n  data.frame(y = y, density = dgalenshore(y, 1, 1), dist = 'alpha = 1, theta = 1'),\n  data.frame(y = y, density = dgalenshore(y, 1, 3), dist = 'alpha = 1, theta = 3'),\n  data.frame(y = y, density = dgalenshore(y, 3, 1), dist = 'alpha = 3, theta = 1'),\n  data.frame(y = y, density = dgalenshore(y, 4, 2), dist = 'alpha = 4, theta = 2')\n)\n\nggplot(df, aes(x = y, y = density, group = dist, color = dist)) +\n  geom_line()\n\n\n\n\n\n\n\n\n4.6.2 b\nSince this is an exponential family, the posterior of \\(\\phi\\) is given by \\(p(\\phi \\mid n_0 + n, n_0 t_0 + n\\bar{t}(\\mathbf{y}))\\). This means that\n\\[\\begin{align}\n\\theta \\mid y_1, \\dots, y_n &\\sim \\text{Galenshore}\\left(a (n_0 + n) + 1, \\sqrt{- (n_0 + n) (n_0 t_0 + n \\bar{t}(\\mathbf{y}))} \\right) \\\\\n\\end{align}\\]\n\n4.6.3 c\nBy taking advantage of the exponential family we already know \\(t(y) = -(y^2)\\) is our sufficient statistic. Specifically when comparing multiple \\(Y_1, \\dots, Y_n\\), we have \\(\\sum_{i = 1}^n\n- (y^2)\\) as our sufficient statistic.\nNote it was a technicality that I picked \\(t(y) = -(y^2)\\). I could have parameterized the exponential family such that \\(t(y) = y^2\\), and the negative is distributed in the other functions. Also notice that since \\(y^2 &gt; 0\\), the \\(t(y)\\)s provide the same information.\n\n4.6.4 d\nFrom the formula for the expectation of a Galenshore distribution, if we have \\[\\theta \\mid y_1, \\dots, y_n \\sim \\text{Galenshore}\\left(a (n_0 + n) + 1, \\sqrt{- (n_0 + n) (n_0 t_0 + n \\bar{t}(\\mathbf{y}))} \\right)\\]\nthen\n\\[\\begin{align}\n\\mathbb{E}(\\theta \\mid y_1, \\dots, y_n) = \\frac{\\Gamma\\left(\\frac{1}{2} a(n_0 + n) + 2 \\right)}{ \\sqrt{- (n_0 + n) (n_0 t_0 + n \\bar{t}(\\mathbf{y}))} \\Gamma\\left( a(n_0 + n) + 1 \\right)}\n\\end{align}\\]\n\n4.6.5 e\nThis one looks tedious…"
  },
  {
    "objectID": "3.html#section-6",
    "href": "3.html#section-6",
    "title": "Chapter 3: One-parameter models",
    "section": "\n4.7 3.10",
    "text": "4.7 3.10\nChange of variables\n\n4.7.1 a\nIf \\(\\psi = g(\\theta) = \\log \\frac{\\theta}{1 - \\theta}\\), then let \\(\\theta = h(\\psi) = \\frac{e^\\psi}{1 + e^\\psi}\\). Then, by the change of variables formula,\n\\[\\begin{align}\np_{\\psi}(\\psi) &= p_{\\theta}(h(\\psi)) \\times \\left| \\frac{dh}{d\\psi} \\right| \\\\\n&= \\left[ \\frac{\\Gamma(a + b)}{\\Gamma(a) \\Gamma(b)} \\left( \\frac{e^\\psi}{1 + e^\\psi}  \\right)^{a - 1} \\left( 1 - \\frac{e^\\psi}{1 + e^\\psi} \\right)^{b - 1} \\right] \\times \\frac{e^\\psi}{(e^\\psi + 1)^2} \\\\\n&= \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} \\left[ \\left( \\frac{e^\\psi}{1 + e^\\psi}  \\right)^{a - 1} \\left( \\frac{1}{1 + e^\\psi} \\right)^{b - 1} \\right] \\times \\frac{e^\\psi}{(e^\\psi + 1)^2} \\\\\n&= \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} \\left[ \\left( \\frac{e^\\psi}{1 + e^\\psi}  \\right)^a \\left( \\frac{1 + e^\\psi}{e^\\psi} \\right) \\left( \\frac{1}{1 + e^\\psi} \\right)^b \\left(\\frac{1 + e^\\psi}{1} \\right) \\right] \\times \\frac{e^\\psi}{(e^\\psi + 1)^2} \\\\\n&= \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} \\left[ \\left( \\frac{e^\\psi}{1 + e^\\psi}  \\right)^a \\left( \\frac{1}{1 + e^\\psi} \\right)^b \\frac{(e^\\psi + 1)^2}{e^\\psi} \\right] \\times \\frac{e^\\psi}{(e^\\psi + 1)^2} \\\\\n&= \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} \\left( \\frac{e^\\psi}{1 + e^\\psi}  \\right)^a \\left( \\frac{1}{1 + e^\\psi} \\right)^b\n\\end{align}\\]\n\nShow R codeh = function(psi) {\n  exp(psi) / (exp(psi) + 1)\n}\ndh = function(psi) {\n  exp(psi) / (exp(psi) + 1)^2\n}\ndpsi = function(psi, a, b) {\n  (gamma(a + b) / (gamma(a) * gamma(b))) * h(psi)^(a - 1) * (1 - h(psi))^(b - 1) * dh(psi)\n}\n\n# To verify this is a valid PDF - with various a and b, integral should be approximately 1\nintegrate(function(p) dpsi(p, 2, 2), -100, 100)\n#&gt; 1 with absolute error &lt; 9e-07\nintegrate(function(p) dpsi(p, 4, 8), -100, 100)\n#&gt; 1 with absolute error &lt; 1.2e-08\nintegrate(function(p) dpsi(p, 10, 1), -100, 100)\n#&gt; 1 with absolute error &lt; 5.6e-05\n\npsi = seq(-5, 5, by = 0.05)\ndensity = dpsi(psi, 1, 1)\n\nqplot(psi, density, geom = 'line')\n\n\n\n\n\n\n\nThis prior is also visualized via Monte-Carlo simulation in exercise 4.6. One perhaps counterintuitive result here is that for a Beta-Binomial model, an uninformative (uniform) prior on \\(\\theta\\) does result in an informative prior on the log-odds. This was apparently a “major criticism of Bayesian inference” led by R.A. Fisher. For more information about this (and an introduction into the Jeffreys’ prior exercises next up), see these lecture notes.\nPoint: it is impossible to have a totally diffuse prior on a random variable with infinite support such as the log-odds, though…\n\n4.7.2 b\nIf \\(\\psi = g(\\theta) = \\log \\theta\\), then let \\(\\theta = h(\\psi) = e^\\psi\\). Then, by the change of variables formula,\n\\[\\begin{align}\np_{\\psi}(\\psi) &= p_{\\theta}(h(\\psi)) \\times \\left| \\frac{dh}{d\\psi} \\right| \\\\\n&= \\left[ \\frac{b^a}{\\Gamma(a)} \\text{exp}\\left(\\psi (a - 1)\\right) \\text{exp}\\left( -b e^\\psi \\right)  \\right] \\times \\text{exp}\\left( \\psi \\right) \\\\\n&= \\frac{b^a}{\\Gamma(a)} \\text{exp}\\left(a\\psi - \\psi - b e^\\psi + \\psi \\right) \\\\\n&= \\frac{b^a}{\\Gamma(a)} \\text{exp}\\left(a\\psi - \\psi - b e^\\psi + \\psi \\right) \\\\\n&= \\frac{b^a}{\\Gamma(a)} \\text{exp}\\left(a\\psi - b e^\\psi \\right)\n\\end{align}\\]\n\nShow R codedpsi = function(psi, a, b) {\n  (b^a) / (gamma(a)) * exp(a * psi - b * exp(psi))\n}\n\n# To verify this is a valid PDF - with various a and b, integral should be approximately 1\nintegrate(function(p) dpsi(p, 2, 2), -100, 100)\n#&gt; 1 with absolute error &lt; 3.3e-06\nintegrate(function(p) dpsi(p, 4, 8), -100, 100)\n#&gt; 1 with absolute error &lt; 2.3e-05\nintegrate(function(p) dpsi(p, 10, 1), -100, 100)\n#&gt; 1 with absolute error &lt; 3.1e-05\n\npsi = seq(-10, 5, by = 0.05)\ndensity = dpsi(psi, 1, 1)\n\nqplot(psi, density, geom = 'line')"
  },
  {
    "objectID": "3.html#section-7",
    "href": "3.html#section-7",
    "title": "Chapter 3: One-parameter models",
    "section": "\n4.8 3.12",
    "text": "4.8 3.12\n\n4.8.1 a\nIf \\(Y\\) is Binomial, then \\(p(y \\mid \\theta) = {n \\choose y} \\theta^y (1 - \\theta)^{n - y}\\).\nSo \\(I(\\theta) = -\\mathbb{E}(\\partial^2 \\ell(y \\mid \\theta) / \\partial \\theta^2 )\\) where \\(\\ell(y \\mid \\theta) = \\log p(y \\mid \\theta)\\). Now,\n\\[\\begin{align}\n\\ell(y \\mid \\theta) &= \\log p(y \\mid \\theta) \\\\\n&= \\log \\left( {n \\choose y} \\theta^y (1 - \\theta)^{n - y} \\right) \\\\\n&= \\log \\left( {n \\choose y} \\right) + y \\log(\\theta) + (n - y) \\log(1 - \\theta) \\\\\n\\ell_\\theta(y \\mid \\theta) &= \\frac{y}{\\theta}- \\frac{n - y}{1 - \\theta} \\\\\n\\ell_{\\theta \\theta}(y \\mid \\theta) &= - \\frac{y}{\\theta^2} - \\frac{n - y}{(1 - \\theta)^2} \\\\\n\\end{align}\\]\nSo\n\\[\\begin{align}\nI(\\theta) &= -\\mathbb{E}\\left( -\\frac{y}{\\theta^2} - \\frac{n - y}{(1 - \\theta)^2} \\right) \\\\\n&= - \\left( -\\frac{1}{\\theta^2} \\mathbb{E}(y) - \\frac{1}{(1 - \\theta)^2} \\mathbb{E}(n - y) \\right) \\\\\n&= \\frac{n\\theta}{\\theta^2} + \\frac{n - n\\theta}{(1 - \\theta)^2} \\\\\n&= \\frac{n}{\\theta} + \\frac{n}{1 - \\theta} \\\\\n&= \\frac{n}{\\theta (1 - \\theta)}\n\\end{align}\\]\nSo Jeffreys’ prior distribution is\n\\[\\begin{align}\np_J(\\theta) &= c \\times \\sqrt{\\frac{n}{\\theta (1 - \\theta)}} \\\\\n\\end{align}\\]\nwhere \\[\nc = \\left( \\int_0^1 \\sqrt{\\frac{n}{\\theta(1 - \\theta)}} \\; d\\theta \\right)^{-1}.\n\\]\n\n4.8.2 b\n\\[\\begin{align}\n\\ell(y \\mid \\psi) &= \\log p(y \\mid \\psi) \\\\\n&= \\log \\left( {n \\choose y} e^{\\psi y} (1 + e^\\psi)^{-n} \\right) \\\\\n&= \\log {n \\choose y} + \\psi y - n \\log \\left(1 + e^\\psi \\right) \\\\\n\\ell_\\psi(y \\mid \\psi) &= y - \\frac{n e^\\psi}{e^\\psi + 1} \\\\\n\\ell_{\\psi \\psi}(y \\mid \\psi) &= - \\frac{n e^\\psi}{\\left( e^\\psi + 1 \\right)^2}\n\\end{align}\\]\nSo\n\\[\\begin{align}\nI(\\psi) &= -\\mathbb{E}\\left( - \\frac{n e^\\psi}{\\left( e^\\psi + 1 \\right)^2}\\right) \\\\\n&= \\frac{n e^\\psi}{\\left( e^\\psi + 1 \\right)^2} \\\\\n\\end{align}\\]\nThen Jeffreys prior is \\[\\begin{align}\np_J(\\psi) &\\propto \\sqrt{ \\frac{n e^\\psi}{\\left( e^\\psi + 1 \\right)^2} } \\\\\n&\\propto \\frac{\\sqrt{n e^\\psi}}{e^\\psi + 1}\n\\end{align}\\]\n\n4.8.3 c\nIf \\(\\psi = g(\\theta) = \\log \\frac{\\theta}{1 - \\theta}\\), then let \\(\\theta = h(\\psi) = \\frac{e^\\psi}{1 + e^\\psi}\\). Then, by the change of variables formula,\n\\[\\begin{align}\np_{\\psi}(\\psi) &\\propto p_{\\theta}(h(\\psi)) \\times \\left| \\frac{dh}{d\\psi} \\right| \\\\\n&\\propto \\sqrt{\\frac{n}{\\frac{e^\\psi}{1 + e^\\psi} \\left(1 - \\frac{e^\\psi}{1 + e^\\psi}\\right)}} \\times \\frac{e^\\psi}{(e^\\psi + 1)^2} \\\\\n&\\propto \\sqrt{\\frac{n(e^\\psi + 1)^2}{e^\\psi} } \\times \\frac{e^\\psi}{(e^\\psi + 1)^2} \\\\\n&\\propto \\frac{\\sqrt{n}(e^\\psi + 1)}{\\sqrt{e^\\psi}} \\times \\frac{e^\\psi}{(e^\\psi + 1)^2} \\\\\n&\\propto \\frac{\\sqrt{n}\\sqrt{e^\\psi}}{e^\\psi + 1} \\\\\n&\\propto p_J(\\psi).\n\\end{align}\\]\nIn this case, it has been demonstrated that Jeffreys’ prior is invariant under monotone transformation."
  },
  {
    "objectID": "3.html#section-8",
    "href": "3.html#section-8",
    "title": "Chapter 3: One-parameter models",
    "section": "\n4.9 3.13",
    "text": "4.9 3.13\nImproper Jeffreys’ prior\n\n4.9.1 a\nIf \\(Y \\sim \\text{Poisson}(\\theta)\\), \\(p(y) = \\frac{\\theta^y e^{-\\theta}}{y!}\\).\n\\[\\begin{align}\n\\ell(y \\mid \\theta) &= \\log p(y \\mid \\theta) \\\\\n&= \\log \\left( \\frac{\\theta^y e^{-\\theta}}{y!} \\right) \\\\\n&= \\log \\left( \\frac{1}{y!} \\right) + y \\log (\\theta) - \\theta \\\\\n\\ell_\\theta(y \\mid \\theta) &= \\frac{y}{\\theta} - 1\\\\\n\\ell_{\\theta \\theta}(y \\mid \\theta) &= -\\frac{y}{\\theta^2} \\\\\n\\end{align}\\]\nSo\n\\[\\begin{align}\nI(\\psi) &= -\\mathbb{E}\\left( - \\frac{y}{\\theta^2} \\right) \\\\\n&= \\frac{1}{\\theta^2} \\mathbb{E}(y) \\\\\n&= \\frac{\\theta}{\\theta^2} \\\\\n&= \\frac{1}{\\theta}\n\\end{align}\\]\nand Jeffreys’ prior is\n\\[\\begin{align}\np_J(\\theta) &= c \\times \\sqrt{\\frac{1}{\\theta}} \\\\\n&= c \\times \\frac{1}{\\sqrt{\\theta}}\n\\end{align}\\]\nNotice that, to be a proper probability distribution, it must be the case that\n\\[\\begin{align}\n\\int_0^{\\infty} c \\times \\frac{1}{\\sqrt{\\theta}} \\; d\\theta = c \\int_0^{\\infty} \\frac{1}{\\sqrt{\\theta}} \\; d\\theta = 1\n\\end{align}\\]\nHowever, this integral does not converge (\\(p\\)-test, \\(p = 1/2\\)), so there is no value of \\(c\\) such that this is a valid probability distribution. Thus (per the name of the exercise) this is an improper Jeffreys’ prior.\n\n4.9.2 b\nHowever, even if \\(p_J(\\theta)\\) is not a valid probability distribution, we can still imagine performing “inference” using this prior.\n\\[\\begin{align}\nf(\\theta, y) &= \\sqrt{I(\\theta)} \\times p(y \\mid \\theta) \\\\\n&= \\frac{1}{\\sqrt{\\theta}} \\times  \\frac{\\theta^y e^{-\\theta}}{y!} \\\\\n&= \\theta^{-1/2} \\times  \\frac{\\theta^y e^{-\\theta}}{\\Gamma(y + 1)} \\\\\n&= \\theta^{y - 1/2} e^{-\\theta} \\frac{1}{\\Gamma(y + 1)} \\\\\n\\end{align}\\]\nAs a function of \\(\\theta\\) only, this is proportional to \\[\\begin{align}\n\\dots &\\propto \\theta^{y - 1/2} e^{-\\theta} \\\\\n&\\propto \\text{dgamma}(\\theta, y + \\frac{1/2}, 1)\n\\end{align}\\]\nSince \\(\\Gamma(y + \\frac{1/2}, 1)\\), \\(y &gt;= 0\\) is a valid parameterization of a Gamma density, it follows that we can normalize \\(f(\\theta, y)\\) such that it represents a valid posterior density for \\(\\theta\\). If we actually calculate \\(f(\\theta, y) / \\int f(\\theta, y) \\; d\\theta\\) (which I won’t do here), we will get such a Gamma density.\nNotes: the prior in a) can be thought of as an improper \\(\\text{Gamma}(1/2, 0)\\). Since improper Jeffreys’ priors are not real probability densities, their usage is controversial for some. (Who?)"
  },
  {
    "objectID": "irm.html",
    "href": "irm.html",
    "title": "Final Lecture: Infinite Relational Model",
    "section": "",
    "text": "What happens when you want to cluster your data, but the number of clusters is unknown? While some approaches involve fitting several models with a varying number of clusters to your data and comparing model fit statistics, the Bayesian approach is to specify a model which is allowed to dynamically grow the number of clusters as the complexity of the data warrants.\nThe Infinite Relational Model is the prototypical example of such a model.\n\nKemp et al. (2006). Learning Systems of Concepts with an Infinite Relational Model\n\nFor this last project, I coded up a simple version of Charles Kemp’s Infinite Relational Model (IRM) in irm.R to co-cluster rows and columns of a simple 2-dimensional binary relation.\n\n\nShow R codesource('irm.R')\n\n\n\nAs a sanity check, we use the toy matrix in the original paper:\n\nShow R codeR = rbind(\n  c(0, 0, 1, 0, 1, 0, 0, 1, 0),\n  c(0, 0, 0, 0, 0, 0, 1, 0, 1),\n  c(0, 0, 1, 0, 0, 0, 1, 0, 1),\n  c(0, 1, 1, 0, 0, 0, 0, 1, 1),\n  c(0, 0, 0, 0, 0, 0, 1, 0, 1),\n  c(0, 1, 1, 0, 1, 0, 0, 1, 0),\n  c(1, 0, 0, 0, 0, 1, 0, 0, 0),\n  c(0, 0, 0, 0, 0, 1, 1, 0, 1),\n  c(1, 0, 0, 1, 0, 1, 0, 0, 0)\n)\nplot.R(R)\n\n\n\n\n\n\n\n\nShow R codeZ = irm(R, sweeps = 1000)\ntop.n(Z)\n#&gt; 122121323 122121324 122123424 122321424 122323424 122223424 123121424 122123425 \n#&gt;       883        31        27        17         9         6         6         5 \n#&gt; 123121425 122121343 \n#&gt;         5         3\nplot.R(R, mode.irm(Z))\n\n\n\n\n\n\n\nThis successfully finds the clusters of rows and columns that correspond to the original paper."
  },
  {
    "objectID": "irm.html#demo",
    "href": "irm.html#demo",
    "title": "Final Lecture: Infinite Relational Model",
    "section": "",
    "text": "Show R codesource('irm.R')\n\n\n\nAs a sanity check, we use the toy matrix in the original paper:\n\nShow R codeR = rbind(\n  c(0, 0, 1, 0, 1, 0, 0, 1, 0),\n  c(0, 0, 0, 0, 0, 0, 1, 0, 1),\n  c(0, 0, 1, 0, 0, 0, 1, 0, 1),\n  c(0, 1, 1, 0, 0, 0, 0, 1, 1),\n  c(0, 0, 0, 0, 0, 0, 1, 0, 1),\n  c(0, 1, 1, 0, 1, 0, 0, 1, 0),\n  c(1, 0, 0, 0, 0, 1, 0, 0, 0),\n  c(0, 0, 0, 0, 0, 1, 1, 0, 1),\n  c(1, 0, 0, 1, 0, 1, 0, 0, 0)\n)\nplot.R(R)\n\n\n\n\n\n\n\n\nShow R codeZ = irm(R, sweeps = 1000)\ntop.n(Z)\n#&gt; 122121323 122121324 122123424 122321424 122323424 122223424 123121424 122123425 \n#&gt;       883        31        27        17         9         6         6         5 \n#&gt; 123121425 122121343 \n#&gt;         5         3\nplot.R(R, mode.irm(Z))\n\n\n\n\n\n\n\nThis successfully finds the clusters of rows and columns that correspond to the original paper."
  },
  {
    "objectID": "6.html",
    "href": "6.html",
    "title": "Chapter 6: Posterior approximation with the Gibbs sampler",
    "section": "",
    "text": "In Chapter 5, we performed two-parameter inference by decomposing the prior \\(p(\\theta, \\sigma^2) = p(\\theta \\mid \\sigma^2) p(\\sigma^2)\\). So our prior distribution on \\(\\theta\\) relates to the variance \\(\\sigma^2\\):\n\\[\n\\theta \\mid \\sigma^2 \\sim \\mathcal{N}(\\mu_0, \\sigma^2 / \\kappa_0)\n\\]\nHowever, consider that we may want to decouple the priors of the two parameters. This allows flexibility with specification of the prior (initial estimate and confidence) of either parameter.\nConsider the midge wing example: we picked a prior on \\(\\theta\\) that was centered around 1.9 (our prior expectation) but with most of its mass above 0, since wing lengths cannot be above 0. We can’t freely do this from what we know in section 5 (i.e. setting \\(\\tau_0^2 = \\sigma^2 / \\kappa_0\\)). Alternatively, we can set \\(\\tau_0^2\\) to be whatever we want, but then there is no longer a known form of the joint posterior\n\\[\np(\\theta, \\sigma^2 \\mid y_1, \\dots, y_n) \\propto p(\\theta, \\sigma^2) \\times p(y_1, \\dots, y_n \\mid \\theta, \\sigma^2)\n\\]\nthat can easily be sampled from. However, as it turns out, the full conditionals \\(p(\\theta \\mid \\sigma^2, y_1, \\dots, y_n)\\) and \\(p(\\sigma^2 \\mid \\theta, y_1,\n\\dots, y_n)\\) are easy to specify, as when evaluating the formulas, we can simply disregard the other fixed parameter as a constant, leading to known posterior distributions. A technicue called Gibbs sampling allows us to take advantage of this by constructing a sampler that approximates the (unknown) joint distribution by sampling iteratively from the (known) full conditional distributions."
  },
  {
    "objectID": "6.html#section",
    "href": "6.html#section",
    "title": "Chapter 6: Posterior approximation with the Gibbs sampler",
    "section": "\n7.1 6.1",
    "text": "7.1 6.1\n\n7.1.1 a\n\\[\n\\begin{align}\n\\text{Cov}(\\theta_A, \\theta_B) &= \\mathbb{E}\\left[\\theta_A \\theta_B\\right] - \\mathbb{E}[\\theta_A]\\mathbb{E}[\\theta_B] \\\\\n&= \\mathbb{E}[\\theta^2\\gamma] - \\mathbb{E}[\\theta] \\mathbb{E}[\\theta\\gamma] \\\\\n&= \\mathbb{E}\\left[\\theta^2\\right] \\mathbb{E}\\left[ \\gamma \\right] - \\mathbb{E}[\\theta]\\mathbb{E}[\\theta]\\mathbb{E}[\\gamma] & \\theta \\perp \\gamma \\\\\n&= \\mathbb{E}\\left[\\theta^2\\right] \\mathbb{E}\\left[ \\gamma \\right] - \\mathbb{E}[\\theta]^2\\mathbb{E}[\\gamma] \\\\\n&= \\left(\\mathbb{E}[\\theta^2] - \\mathbb{E}[\\theta]^2 \\right) \\mathbb{E}[\\gamma] \\\\\n&= \\text{Var}(\\theta) \\mathbb{E}[\\gamma] \\\\\n&\\neq 0\n\\end{align}\n\\]\nSince \\(\\text{Cov}(\\theta_A, \\theta_B) \\neq 0\\), \\(\\theta_A\\) and \\(\\theta_B\\) are dependent.\nThis prior is justified if we have reason to believe that \\(\\theta_B\\) is some product of \\(\\theta_A\\) plus random Gamma-distributed noise.\n\n7.1.2 b\nFirst the joint posterior distribution\n\\[\n\\begin{align}\np(\\theta, \\gamma \\mid \\boldsymbol{y}_A, \\boldsymbol{y}_B)\n&\\propto p(\\theta, \\gamma) \\times p(\\boldsymbol{y}_A, \\boldsymbol{y}_B \\mid \\theta, \\gamma) \\\\\n&= p(\\theta) \\times p(\\gamma) \\times p(\\boldsymbol{y}_A \\mid \\theta) \\times p(\\boldsymbol{y}_B \\mid \\theta, \\gamma) & \\boldsymbol{y}_A \\perp \\gamma \\\\\n&\\propto \\left(\\theta^{a_\\theta - 1}e^{-b_\\theta \\theta}\\right) \\times \\left(\\gamma^{a_\\gamma - 1}e^{-b_\\gamma \\gamma} \\right) \\times  \\left(\\prod_{i=1}^{n_{A}} \\theta^{y_{A_i}} e^{-\\theta} \\right) \\times \\left(\\prod_{i=1}^{n_{B}} (\\gamma \\theta)^{y_{B_i}} e^{-\\gamma \\theta} \\right) \\\\\n&= \\left(\\theta^{a_\\theta - 1}e^{-b_\\theta \\theta}\\right) \\times \\left(\\gamma^{a_\\gamma - 1}e^{-b_\\gamma \\gamma} \\right) \\times  \\left( \\theta^{\\sum_{i = 1}^{n_A} y_{A_i}} e^{-n_A \\theta} \\right) \\times \\left( (\\gamma \\theta)^{\\sum_{i=1}^{n_B} y_{B_i}} e^{- n_B \\gamma \\theta} \\right) \\\\\n&= \\left(\\theta^{a_\\theta - 1}e^{-b_\\theta \\theta}\\right) \\times \\left(\\gamma^{a_\\gamma - 1}e^{-b_\\gamma \\gamma} \\right) \\times  \\left( \\theta^{n_A \\bar{y}_A} e^{-n_A \\theta} \\right) \\times \\left( (\\gamma \\theta)^{n_B \\bar{y}_B} e^{- n_B \\gamma \\theta} \\right) \\\\\n\\end{align}\n\\]\nSo\n\\[\n\\begin{align}\np(\\theta, \\mid \\boldsymbol{y}_A, \\boldsymbol{y}_B, \\gamma)\n&\\propto \\left(\\theta^{a_\\theta - 1}e^{-b_\\theta \\theta}\\right) \\times \\left(\\gamma^{a_\\gamma - 1}e^{-b_\\gamma \\gamma} \\right) \\times  \\left( \\theta^{n_A \\bar{y}_A} e^{-n_A \\theta} \\right) \\times \\left( (\\gamma \\theta)^{n_B \\bar{y}_B} e^{- n_B \\gamma \\theta} \\right) \\\\\n&\\propto \\left(\\theta^{a_\\theta - 1}e^{-b_\\theta \\theta}\\right) \\times \\left( \\theta^{n_A \\bar{y}_A} e^{-n_A \\theta} \\right) \\times \\left( (\\gamma \\theta)^{n_B \\bar{y}_B} e^{- n_B \\gamma \\theta} \\right) \\\\\n&\\propto \\theta^{a_\\theta + n_A \\bar{y}_A + n_B \\bar{y}_B - 1} \\exp \\left( - (b_\\theta + n_A + n_B \\gamma ) \\theta \\right) \\\\\n&\\propto \\text{dgamma}\\left(a_\\theta + n_A \\bar{y}_A + n_B \\bar{y}_B, b_\\theta + n_A + n_B \\gamma \\right)\n\\end{align}\n\\]\n\n7.1.3 c\n\\[\n\\begin{align}\np(\\gamma, \\mid \\boldsymbol{y}_A, \\boldsymbol{y}_B, \\theta)\n&\\propto \\left(\\theta^{a_\\theta - 1}e^{-b_\\theta \\theta}\\right) \\times \\left(\\gamma^{a_\\gamma - 1}e^{-b_\\gamma \\gamma} \\right) \\times  \\left( \\theta^{n_A \\bar{y}_A} e^{-n_A \\theta} \\right) \\times \\left( (\\gamma \\theta)^{n_B \\bar{y}_B} e^{- n_B \\gamma \\theta} \\right) \\\\\n&\\propto \\left(\\gamma^{a_\\gamma - 1}e^{-b_\\gamma \\gamma} \\right) \\times \\left( (\\gamma \\theta)^{n_B \\bar{y}_B} e^{- n_B \\gamma \\theta} \\right) \\\\\n&\\propto \\left(\\gamma^{a_\\gamma - 1}e^{-b_\\gamma \\gamma} \\right) \\times \\left( \\gamma^{n_B \\bar{y}_B} e^{- n_B \\gamma \\theta} \\right) \\\\\n&\\propto \\gamma^{a_\\gamma + n_B \\bar{y}_B - 1} \\exp\\left( -(b_\\gamma + n_B \\theta) \\gamma \\right) \\\\\n&\\propto \\text{dgamma}\\left(a_\\gamma + n_B\\bar{y}_B, b_\\gamma + n_B \\theta \\right)\n\\end{align}\n\\]\n\n7.1.4 d\n\nShow R codeY_a &lt;- scan('Exercises/menchild30bach.dat')\nY_b &lt;- scan('Exercises/menchild30nobach.dat')\nn_a = length(Y_a)\nn_b = length(Y_b)\nybar_a = mean(Y_a)\nybar_b = mean(Y_b)\n\na_theta = 2\nb_theta = 1\n\nS = 5000\n\nab_gamma = c(8, 16, 32, 64, 128)\n\ntheta_diff = sapply(ab_gamma, function(abg) {\n  a_gamma = b_gamma = abg\n\n  THETA = numeric(S)\n  GAMMA = numeric(S)\n\n  # Starting values\n  theta = ybar_a\n  gamma = ybar_a / ybar_b  # Relative rate \\theta_B / \\theta_A\n\n  for (s in 1:S) {\n    # Sample theta \\text{dgamma}\\left(a_\\theta + n_A \\bar{y}_A + n_B \\bar{y}_B, b_\\theta + n_A + n_B \\gamma \\right)\n    theta = rgamma(\n      1,\n      a_theta + n_a * ybar_a + n_b * ybar_b,\n      b_theta + n_a + n_b * gamma\n    )\n\n    # Sample gamma from \\text{dgamma}\\left(a_\\gamma + n_B\\bar{y}_B, b_\\gamma + n_B \\theta \\right)\n    gamma = rgamma(\n      1,\n      a_gamma + n_b * ybar_b,\n      b_gamma + n_b * theta\n    )\n\n    THETA[s] = theta\n    GAMMA[s] = gamma\n  }\n\n  # Reconstruct \\theta_A, \\theta_B\n  THETA_A = THETA\n  THETA_B = THETA * GAMMA\n\n  mean(THETA_B - THETA_A)\n})\n\nggplot(data.frame(ab_gamma = ab_gamma, theta_diff = theta_diff), aes(x = ab_gamma, y = theta_diff)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\nSince \\(a_\\gamma\\) and \\(b_\\gamma\\) are equal, the gamma distribution is centered around 1 and the magnitude represents the strength of our belief that \\(\\gamma\\) (the proportion \\(\\theta_B / \\theta_A\\)) is 1. As expected, as our belief in that increases, the mean posterior difference between \\(\\theta_B\\) and \\(\\theta_A\\) decreases."
  },
  {
    "objectID": "6.html#section-1",
    "href": "6.html#section-1",
    "title": "Chapter 6: Posterior approximation with the Gibbs sampler",
    "section": "\n7.2 6.2",
    "text": "7.2 6.2\n\nShow R codeglucose &lt;- scan('Exercises/glucose.dat')\n\n\n\n7.2.1 a\n\nShow R codeqplot(glucose, geom = 'histogram')\n\n\n\n\n\n\n\nAppears to be skewed right significantly.\n\n7.2.2 b\nThe likelihood is\n\\[\n\\begin{align}\np(\\boldsymbol{y} \\mid \\boldsymbol{x}, p, \\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2) &=\n\\prod_{i = 1}^n p(y_i \\mid x_i, p, \\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2) \\\\\n&= \\prod_{i = 1}^n \\text{dnorm}(y_i, \\theta_1, \\sigma^2_1)^{x_i} \\text{dnorm}(y_i, \\theta_2, \\sigma^2_2)^{1 - x_i} \\\\\n\\end{align}\n\\]\n\\(\\boldsymbol{x}\\)\nFirst observe the probability that a single \\(X_i = 1\\):\n\\[\n\\begin{align}\nP(X_i = 1 \\mid y_i, p, \\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2) &= \\frac{P(X_i = 1 \\mid p, \\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2) \\times p(y_i \\mid X_i = 1, p, \\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2)}{P(y_i \\mid p, \\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2)} \\\\\n&=\n\\frac{P(X_i = 1 \\mid p) \\times p(y_i \\mid X_i = 1, \\theta_1, \\sigma^2_1)}{P(X_i = 1 \\mid p) \\times p(y_i \\mid X_i = 1, \\theta_1, \\sigma^2_1) + P(X_i = 0 \\mid p) \\times p(y_i \\mid X_i = 0, \\theta_2, \\sigma^2_2)} \\\\\n&= \\frac{p \\times \\text{dnorm}(y_i, \\theta_1, \\sigma^2_1)}{p \\times \\text{dnorm}(y_i, \\theta_1, \\sigma^2_1) + (1 - p) \\times \\text{dnorm}(y_i, \\theta_2, \\sigma^2_2)}\n\\end{align}\n\\]\nSince this is similar for \\(P(X_i = 0)\\), we know\n\\[\nx_i \\sim \\text{Bernoulli}\\left(\\frac{p \\times \\text{dnorm}(y_i, \\theta_1, \\sigma^2_1)}{p \\times \\text{dnorm}(y_i, \\theta_1, \\sigma^2_1) + (1 - p) \\times \\text{dnorm}(y_i, \\theta_2, \\sigma^2_2)}\\right)\n\\]\n\\(p\\)\nFor this and later calculations, let \\(n_1 = \\sum x_i\\) (i.e. number of 1s in \\(\\boldsymbol{x}\\)) and \\(n_2 = n - n_1\\) (i.e. number of 0s).\n\\[\n\\begin{align}\np(p \\mid \\boldsymbol{x}, \\boldsymbol{y}, \\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2) &\\propto p(p) \\times p(\\boldsymbol{x}, \\boldsymbol{y}, \\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2 \\mid p) \\\\\n&\\propto p(p) \\times p(\\boldsymbol{x} \\mid p) p(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2) p(\\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2) \\\\\n&\\propto p(p) \\times p(\\boldsymbol{x} \\mid p) \\\\\n&\\propto \\text{dbeta}(p, a, b) \\times \\text{dbinom}(n_1, n, p) \\\\\n&\\propto p^{a - 1} (1 - p)^{b - 1} \\times p^{n_1} (1 - p)^{n_2} \\\\\n&= p^{a + n_1 - 1}(1 - p)^{b + n_2 - 1} \\\\\n&= \\text{dbeta}(p, a + n_1, b + n_2)\n\\end{align}\n\\]\n\\(\\theta_1\\)\nLet \\(\\boldsymbol{y}_1 = \\{y_i \\in \\boldsymbol{y} \\; : \\; x_i = 1 \\}\\) and \\(\\boldsymbol{y}_2 = \\{y_i \\in \\boldsymbol{y} \\; : \\; x_i = 0 \\}\\)\n\\[\n\\begin{align}\np(\\theta_1 \\mid \\boldsymbol{x}, \\boldsymbol{y}, p, \\theta_2, \\sigma^2_1, \\sigma^2_2) &\\propto p(\\theta_1 \\mid \\boldsymbol{x}, p, \\theta_2, \\sigma^2_1, \\sigma^2_2) \\times p(\\boldsymbol{y} \\mid \\boldsymbol{x}, p, \\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2) \\\\\n&\\propto p(\\theta_1) \\times \\prod_{i=1}^n \\left( \\text{dnorm}(y_i, \\theta_1, \\sigma^2_1)^{x_i} \\text{dnorm}(y_i, \\theta_2, \\sigma^2_2)^{1 - x_i} \\right) \\\\\n&\\propto \\text{dnorm}(\\theta_1, \\mu_0, \\tau^2_0) \\times \\prod_{i = 1}^n \\text{dnorm}(y_i, \\theta_1, \\sigma^2_1)^{x_i} \\\\\n&\\propto \\text{dnorm}(\\theta_1, \\mu_0, \\tau^2_0) \\times \\prod_{y \\in \\boldsymbol{y}_1} \\text{dnorm}(y, \\theta_1, \\sigma^2_1) \\\\\n&\\propto \\exp \\left(- \\frac{1}{2 \\tau^2_0} (\\theta_1 - \\mu_0)^2 \\right) \\times \\prod_{y \\in \\boldsymbol{y}_1} \\exp\\left( -\\frac{1}{2\\sigma^2_1} (y - \\theta_1)^2\\right) \\\\\n&\\propto \\exp \\left(- \\frac{1}{2 \\tau^2_0} (\\theta_1 - \\mu_0)^2 \\right) \\times \\exp\\left(-\\frac{1}{2\\sigma^2_1} \\sum_{y \\in \\boldsymbol{y}_1} (y - \\theta_1)^2 \\right) \\\\\n&\\propto \\text{calculations from 5.2...} \\\\\n&\\propto \\mathcal{N}(\\tau^2_{n , 1}, \\mu_{n, 1})\n\\end{align}\n\\]\nwhere\n\\[\n\\begin{align}\n\\tau^2_{n, 1} &= \\frac{1}{\\frac{1}{\\tau^2_0} + \\frac{n_1}{\\sigma^2_1}} \\\\\n\\mu_{n, 1} &= \\frac{\\frac{1}{\\tau^2_0}\\mu_0 + \\frac{n_1}{\\sigma^2_1} \\bar{y}_{\\cdot, 1}}{\\frac{1}{\\tau^2_0} + \\frac{n_1}{\\sigma^2_1}}\n\\end{align}\n\\]\n\\(\\theta_2\\)\n\\(\\theta_2 \\mid \\dots \\sim \\mathcal{N}(\\mu_{n, 2}, \\tau^2_{n, 2})\\) like \\(\\theta_1\\) but with the subscripts switched from 1 to 2.\n\\(\\sigma^2_1\\)\nAs probably expected, this will look like inference for a standard normal model, except using only the data in group 1.\n\\[\n\\begin{align}\np(\\sigma^2_1 \\mid \\boldsymbol{x}, \\boldsymbol{y}, p, \\theta_1, \\theta_2, \\sigma^2_2) &\\propto p(\\sigma^2_1 \\mid \\boldsymbol{x}, p, \\theta_1, \\theta_2, \\sigma^2_2) \\times p(\\boldsymbol{y} \\mid \\boldsymbol{x}, p, \\theta_1, \\theta_2, \\sigma^2_1, \\sigma^2_2) \\\\\n&\\propto p(\\sigma^2_1) \\times \\prod_{i=1}^n \\left( \\text{dnorm}(y_i, \\theta_1, \\sigma^2_1)^{x_i} \\text{dnorm}(y_i, \\theta_2, \\sigma^2_2)^{1 - x_i} \\right) \\\\\n&\\propto \\text{inverse-gamma}(\\sigma^2_1, \\nu_0, \\sigma^2_0 \\nu_0 / 2) \\times \\prod_{y \\in \\boldsymbol{y}_1} \\text{dnorm}(y, \\theta_1, \\sigma^2_1) \\\\\n&\\propto \\exp \\left((\\sigma_1^2)^{-(\\nu_0 / 2) - 1} \\exp\\left( -\\frac{1}{\\sigma^2_1} \\sigma^2_0 \\nu_0 / 2 \\right) \\right) \\times (\\sigma_1^2)^{-n / 2} \\exp\\left(-\\frac{1}{2\\sigma^2_1} \\sum_{y \\in \\boldsymbol{y}_1} (y - \\theta_1)^2 \\right) \\\\\n&\\propto \\text{calculations from 6.3...} \\\\\n&\\propto \\text{inverse-gamma}(\\nu_{n, 1} / 2, \\sigma^2_{n, 1}(\\theta_1) \\nu_{n, 1} / 2)\n\\end{align}\n\\]\nwhere\n\\[\n\\begin{align}\n\\nu_{n, 1} &= \\nu_0 + n_1 \\\\\n\\sigma^2_{n, 1}(\\theta_1) &= \\frac{1}{\\nu_{n, 1}} \\left[\\nu_0 \\sigma^2_0 + n_1 s^2_{n, 1}(\\theta_1) \\right]\n\\end{align}\n\\]\n\\(\\sigma^2_2\\)\nSame as above, but with subscripts switched.\n\n7.2.3 c\n\nShow R codeY = glucose\nn = length(Y)\n\n# Priors\na = b = 1\nmu0 = 120\nt20 = 200\ns20 = 1000\nnu0 = 10\n\nS = 10000\n\n# Values we'd like to store. Don't care about xs, p, sigmas\nTHETA1 = numeric(S)\nTHETA2 = numeric(S)\nYPRED = numeric(S) # Posterior predictive\n\n# Starting values\np = 0.5\ntheta1 = theta2 = mean(Y)\ns21 = s22 = var(Y)\n\n# Gibbs sampling\nfor (s in 1:S) {\n  # Sample X\n  # We calculate dnorm for each y so p1 and p2 are vectors\n  p1 = p * dnorm(Y, theta1, sqrt(s21))\n  p2 = (1 - p) * dnorm(Y, theta2, sqrt(s22))\n  bernoulli_p = p1 / (p1 + p2)\n  X = rbinom(n, 1, bernoulli_p)\n  \n  # With X sample, calcuate group-specific summary statistics\n  n1 = sum(X)\n  n2 = n - n1\n  y1 = Y[X == 1]\n  y2 = Y[X == 0]\n  ybar1 = mean(y1)\n  ybar2 = mean(y2)\n  yvar1 = var(y1)\n  yvar2 = var(y2)\n  \n  # Sample p\n  p = rbeta(1, a + n1, b + n2)\n  \n  # Sample thetas\n  t2n1 = 1 / (1 / t20 + n1 / s21)\n  mun1 = (mu0 / t20 + n1 * ybar1 / s21) / (1 / t20 + n1 / s21)\n  theta1 = rnorm(1, mun1, sqrt(t2n1))\n  \n  t2n2 = 1 / (1 / t20 + n2 / s22)\n  mun2 = (mu0 / t20 + n2 * ybar2 / s22) / (1 / t20 + n2 / s22)\n  theta2 = rnorm(1, mun2, sqrt(t2n2))\n\n  # Sample sigma^2s\n  nun1 = nu0 + n1\n  s2n1 = (nu0 * s20 + (n1 - 1) * yvar1 + n1 * (ybar1 - theta1)^2) / nun1\n  s21 = 1 / rgamma(1, nun1 / 2, s2n1 * nun1 / 2)\n\n  nun2 = nu0 + n2\n  s2n2 = (nu0 * s20 + (n2 - 1) * yvar2 + n2 * (ybar2 - theta2)^2) / nun2\n  s22 = 1 / rgamma(1, nun2 / 2, s2n2 * nun2 / 2)\n  \n  # Sample posterior predictive\n  xpred = runif(1) &lt; p\n  ypred = ifelse(xpred, rnorm(1, theta1, sqrt(s21)), rnorm(1, theta2, sqrt(s22)))\n  \n  # Store values\n  THETA1[s] = theta1\n  THETA2[s] = theta2\n  YPRED[s] = ypred\n}\n\n\n\nShow R codeTHETAMIN = pmin(THETA1, THETA2)\nTHETAMAX = pmax(THETA1, THETA2)\n\nlibrary(coda)\n\nacf(THETAMIN)\n\n\n\n\n\n\nShow R codeeffectiveSize(THETAMIN)\n#&gt;     var1 \n#&gt; 534.7286\n\nacf(THETAMAX)\n\n\n\n\n\n\nShow R codeeffectiveSize(THETAMAX)\n#&gt;     var1 \n#&gt; 227.5474\n\n\nThese samples are actually highly autocorrelated, hence the minimum effective sample sizes. But I’m not sure (?) the purpose of calculating the autocorrelation of the minimum and maximum \\(\\theta\\)?\n\n7.2.4 d\n\nShow R codeYCOMP = rbind(data.frame(y = YPRED, dataset = 'predictive'), data.frame(y = Y, dataset = 'original'))\nggplot(YCOMP, aes(x = y, fill = dataset)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\nBased on the very close correspondence with the densities of the original and posterior predictive dataset, it seems like this mixture model fits very well."
  },
  {
    "objectID": "5.html",
    "href": "5.html",
    "title": "Chapter 5: The Normal Model",
    "section": "",
    "text": "A normal variable \\(Y\\) with mean \\(\\theta\\) and variance \\(\\sigma^2\\) (and thus standard deviation \\(\\sigma\\)) we denote\n\\[Y \\sim \\mathcal{N}(\\theta, \\sigma^2)\\]\nand \\(Y\\) has PDF\n\\[\np(y) = \\frac{1}{\\sqrt{2\\pi\\sigma}} \\text{exp}\\left(-\\frac{1}{2} \\frac{(y - \\theta)^2}{\\sigma^2}\\right)\n\\]\nDue to the central limit theorem, the normal model is used all the time to model sample averages or values known to be the additive result of several random variables.\n\nIt’s useful to remember the percentage of values lying within 1, 2, or 3 standard deviations of the mean when constructing priors: 68, 95, and 99.7%, respectively."
  },
  {
    "objectID": "5.html#combining-information",
    "href": "5.html#combining-information",
    "title": "Chapter 5: The Normal Model",
    "section": "\n2.1 Combining information",
    "text": "2.1 Combining information\nNotice in the posterior parameters the frequency of inverse variances i.e. \\(\\frac{1}{\\tau_0^2}, \\frac{n}{\\sigma^2}\\). This hints at the importance of using precision to understand and parameterize our normal prior and posterior distributions. Specifically, it is much more concise to express the above parameters in terms of variance. Specifically, if we let \\(\\tilde{\\tau_n^2} = 1 /\n\\tau_n^2\\), i.e. the posterior precision, and similar tildes for the over variables,\n\\[\\tilde{\\tau_n^2} = \\tilde{\\tau_0^2} + n\\tilde{\\sigma^2}\\]\nSo intuitively, our posterior precision is a combination of our prior belief in the precision of the true population mean of the data, plus the (assumed known) precision, where a larger sample size \\(n\\) increases this precision.\nUsing precision, the fact that \\(\\mu_n\\) is a weighted average of prior and sample information becomes more clear. Notice\n\\[\\begin{align}\n\\mu_n &= \\frac{\\frac{1}{\\tau_0^2}}{ \\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2} } \\mu_0 +\n\\frac{\\frac{n}{\\sigma^2}}{ \\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2} } \\bar{y} \\\\\n&= \\frac{\\tilde{\\tau_0^2}}{\\tilde{\\tau_0^2} + n\\tilde{\\sigma^2}} \\mu_0 + \\frac{n\\tilde{\\sigma^2}}{\\tilde{\\tau_0^2} + n\\tilde{\\sigma^2}} \\bar{y}\n\\end{align}\\]\nSo the posterior mean is a weighted average of the prior expectation of the mean \\(\\mu_0\\) weighted by the precision of that mean \\(\\tilde{\\tau_0^2}\\), and the observed sample mean \\(\\bar{y}\\) weighted by our sample size \\(n\\) and the (assumed known) precision \\(\\tilde{\\sigma^2}\\).\nHow do we select \\(\\tau_0^2\\)? One intuitive way to think about it (as we have done with one-parameter models) is by treating our prior parameters for \\(\\theta\\) as derived from \\(\\kappa_0\\) prior “observations” from the same (or similar) population that we are sampling from. Then \\(\\mu_0\\) is the average of these prior observations, and let \\(\\tau_0^2 = \\sigma^2 / \\kappa_0\\) be the variance of the mean of these prior observations. Then the posterior mean simplifies quite nicely to:\n\\[\\begin{align}\n\\mu_n &= \\frac{\\kappa_0}{\\kappa_0 + n}\\mu_0 + \\frac{n}{\\kappa_0 + n}\\bar{y} \\\\\n&= \\frac{\\kappa_0}{\\kappa_n}\\mu_0 + \\frac{n}{\\kappa_n}\\bar{y} & \\text{Let $\\kappa_n = \\kappa_0 + n$} \\\\\n\\end{align}\\]\nwhich is just a weighted average of \\(\\mu_0\\) and \\(\\bar{y}\\) given the number of prior “observations” \\(\\kappa_0\\) and the sample size \\(n\\). We will take advantage of this when jointly estimating the mean and variance for the normal model. The idea is to first estimate the variance, then assume that variance \\(\\sigma^2\\) is known such that \\(\\tau_0^2 = \\sigma^2 / \\kappa_0\\) can be estimated."
  },
  {
    "objectID": "5.html#prediction",
    "href": "5.html#prediction",
    "title": "Chapter 5: The Normal Model",
    "section": "\n2.2 Prediction",
    "text": "2.2 Prediction\nTo obtain the posterior predictive distribution, instead of doing complex integration, we can use a trick.\n\\(\\tilde{Y}\\) is normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2\\). This is equivalent to saying\n\\[\\tilde{Y} = \\theta + \\tilde{\\epsilon}\\]\nwhere \\(\\theta \\sim \\mathcal{N}(\\mu_n, \\tau_n^2\\), \\(\\tilde{\\epsilon} \\sim\n\\mathcal{N}(0, \\sigma^2)\\). So adding these normal distributions together gives\n\\[\\tilde{Y} \\mid \\sigma^2, y_1, \\dots, y_n \\sim \\mathcal{N}(\\mu_n, \\tau_n^2 + \\sigma^2)\\]"
  },
  {
    "objectID": "5.html#example-midge-wing-data",
    "href": "5.html#example-midge-wing-data",
    "title": "Chapter 5: The Normal Model",
    "section": "\n2.3 Example: Midge wing data",
    "text": "2.3 Example: Midge wing data\nThe wing lengths of 9 members of a species of “midge” are measured. We are interested in estimates of the mean wing length and variance. Prior information from other populations suggests that wing lengths are typically around 1.9mm, so our initial estimate \\(\\mu_0 = 1.9\\). One way of assigning a prior estimate of the variance of the mean \\(\\tau_0^2\\) is to pick the spread of the prior such that all of its mass is above 0, since wing lengths can’t be negative. So we select \\(\\tau_0\\) such that 2 standard deviations from 1.9 &gt; 0: \\(\\tau_0 = 0.95\\).\nOur data are:\n\nShow R codey = c(1.64, 1.70, 1.72, 1.74, 1.82, 1.82, 1.82, 1.90, 2.08)\nmean(y)\n#&gt; [1] 1.804444\nvar(y)\n#&gt; [1] 0.01687778\n\n\nSince we are assuming for now that \\(\\sigma^2\\) is known, let’s use \\(s^2 = \\sigma^2\\).\nNow calculating \\(\\mu_n, \\tau_n^2\\) is simply done by plugging in the relevant formulas:\n\\[\\begin{align}\n\\mu_n &= \\frac{1.11 (1.9) + \\frac{9}{0.017} 1.804}{1.11 + \\frac{9}{0.017}} = 1.805 \\\\\n\\tau_n^2 &= \\frac{1}{1.11 + \\frac{9}{0.017}} = 0.002\n\\end{align}\\]\n\nShow R codeqnorm(c(0.025, 0.975), 1.805, sqrt(0.002))\n#&gt; [1] 1.717348 1.892652"
  },
  {
    "objectID": "5.html#posterior-inference",
    "href": "5.html#posterior-inference",
    "title": "Chapter 5: The Normal Model",
    "section": "\n3.1 Posterior inference",
    "text": "3.1 Posterior inference\nNow we have fully specified (1) our prior distributions:\n\\[\\begin{align}\n1 / \\sigma^2 &\\sim \\text{Gamma}(\\nu_0 / 2, \\sigma^2_0 \\nu_0 / 2) \\\\\n\\theta \\mid \\sigma^2 &\\sim \\mathcal{N}(\\mu_0, \\sigma^2 / \\kappa_0), \\\\\n\\end{align}\\]\nand (2) our sampling model:\n\\[\nY_1, \\dots, Y_n \\mid \\theta, \\sigma^2 \\sim \\text{ i.i.d. } \\mathcal{N}(\\theta,\n\\sigma^2)\n\\]\nNow we wish to calculate \\(p(\\theta, \\sigma^2 \\mid y_1, \\dots, y_n)\\) which we can decompose to a product of marginal and conditional probabilities, just like the prior:\n\\[\np(\\theta, \\sigma^2 \\mid y_1, \\dots, y_n) =  p(\\theta \\mid \\sigma^2, y_1, \\dots, y_n) p(\\sigma^2 \\mid y_1, \\dots, y_n)\n\\]\nThis is convenient because we already know \\(p(\\theta \\mid \\sigma^2, y_1, \\dots, y_n)\\) from the one-parameter case:\n\\[\\begin{align}\n\\theta \\mid \\sigma^2, y_1, \\dots y_n \\sim \\mathcal{N}(\\mu_n, \\tau_n^2)\n\\end{align}\\]\nwhere\n\\[\\begin{align}\n\\mu_n &= \\frac{ \\frac{1}{\\tau_0^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y} }{ \\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2} } \\\\\n&= \\frac{ \\frac{\\kappa_0}{\\sigma^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y} }{ \\frac{\\kappa_0}{\\sigma^2} + \\frac{n}{\\sigma^2} } & \\text{Sub $\\tau_0^2 = \\sigma^2 / \\kappa_0$} \\\\\n&= \\frac{ \\kappa_0 \\mu_0 + n \\bar{y} } { \\kappa_0 + n } & \\text{$\\sigma^2$s cancel} \\\\\n\\end{align}\\]\nand\n\\[\\begin{align}\n\\tau_n^2 &= \\frac{1}{\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}} \\\\\n&= \\frac{1}{\\frac{\\kappa_0}{\\sigma^2} + \\frac{n}{\\sigma^2}} & \\text{Sub $\\tau_0^2 = \\sigma^2 / \\kappa_0$} \\\\\n&= \\frac{\\sigma^2}{\\kappa_0 + n}.\n\\end{align}\\]\nIf we let \\(\\kappa_n = \\kappa_0 + n\\) (remember we will interpret \\(\\kappa_0\\) as a prior sample size, and \\(n\\) as this sample size), then we have\n\\[\\begin{align}\n\\theta \\mid \\sigma^2, y_1, \\dots y_n \\sim \\mathcal{N}(\\mu_n, \\sigma^2 / \\kappa_n)\n\\end{align}\\]\nWhere like before, \\(\\mu_n\\) is a weighted average of \\(\\mu_0\\) and \\(\\bar{y}\\) dependent on the “prior” sample size \\(\\kappa_0\\) and the sample size \\(n\\), and \\(\\sigma^2 / \\kappa_n\\) is the sampling variance of the sample mean given known variance \\(\\sigma^2\\) and our “sample size” \\(\\kappa_n\\).\nRecall our posterior distribution decomposition:\n\\[\np(\\theta, \\sigma^2 \\mid y_1, \\dots, y_n) =  p(\\theta \\mid \\sigma^2, y_1, \\dots, y_n) p(\\sigma^2 \\mid y_1, \\dots, y_n)\n\\]\nOnce we calculate the second component, the posterior distribution of \\(\\sigma^2\\), we will have fully specified the joint posterior distribution.\n\\[\\begin{align}\np(\\sigma^2 \\mid y_1, \\dots, y_n) &\\propto p(\\sigma^2) p(y_1, \\dots, y_n \\mid \\sigma^2) \\\\\n&= p(\\sigma^2) \\int p(y_1, \\dots, y_n \\mid \\theta, \\sigma^2) p(\\theta \\mid \\sigma^2) \\; d\\theta \\\\\n&= \\text{dinverse-gamma}(\\sigma^2, \\nu_0 / 2, \\sigma_0^2 \\nu_0 / 2) \\times \\\\ &\\quad \\int \\left[ \\left( \\prod_{i = 1}^{n} p(y_i \\mid \\theta, \\sigma^2) \\right) \\times \\text{dnorm}(\\theta, \\mu_0, \\sigma^2 / \\kappa_0)  \\right] \\; d\\theta \\\\\n\\end{align}\\]\nThis integral is left as an exercise (Exercise 5.3). The result is that\n\\[\\begin{align}\n\\sigma^2 \\mid y_1, \\dots, y_n & \\sim \\text{Inverse-Gamma}(\\nu_n / 2, \\sigma_n^2 \\nu_n / 2) \\\\\n1 / \\sigma^2 \\mid y_1, \\dots, y_n &\\sim \\text{Gamma}(\\nu_n / 2, \\sigma_n^2 \\nu_n / 2)\n\\end{align}\\]\nwhere\n\n\n\\(\\nu_n = \\nu_0 + n\\), like \\(\\kappa_n\\)\n\n\\(\\sigma_n^2 = \\frac{1}{\\nu_n} \\left[ \\nu_0 \\sigma_0^2 + (n - 1)s^2 + \\frac{\\kappa_0 n}{\\kappa_n} (\\bar{y} - \\mu_0)^2 \\right]\\)\n\n\\(\\nu_n\\) is fairly intuitive, it acts as a sample size which is the “prior sample size” of the variance plus the sample size \\(n\\). \\(\\sigma_n^2\\) is a bit harder to understand. There are three terms here. The first, \\(\\nu_0 \\sigma_0^2\\), can be thought of as a prior sum of squared observations from the sample mean (\\(\\nu_0\\) prior samples with variance \\(\\sigma_0^2\\)). Similarly, \\((n - 1)s^2\\), where \\(s^2 =\n\\sum_{i = 1}^n (y_i - \\bar{y})^2 / (n - 1)\\), is literally the sum of squared (actually observed) observations from the sample mean. Lastly, the third term increases the posterior variance if the observed sample mean \\((\\bar{y})\\) is far away from the expected prior mean \\(\\mu_0\\), since this would suggest higher variance. All three “sum of squares-ish” terms are combined, then divided by the total number of “observations” \\(\\nu_n = n + \\nu_0\\), as commonly done to estimate variance from a sample."
  },
  {
    "objectID": "5.html#summary-of-posterior-inference",
    "href": "5.html#summary-of-posterior-inference",
    "title": "Chapter 5: The Normal Model",
    "section": "\n3.2 Summary of posterior inference",
    "text": "3.2 Summary of posterior inference\nThis is a lot to handle, since there are a lot of moving parts. In sum, for inference with the normal model, there are four prior parameters to specify:\n\n\n\\(\\sigma_0^2\\), an initial estimate for the variance;\n\n\\(\\nu_0\\), a “prior sample size” from which the initial estimate of the variance is observed;\n\n\\(\\mu_0\\), an initial estimate for the population mean;\n\n\\(\\kappa_0\\), a “prior sample size” from which the initial estimate of the mean is observed\n\nThen we have\n\n\\(1 / \\sigma^2 \\sim \\text{Gamma}(\\nu_0 / 2, \\sigma^2_0 \\nu_0 / 2)\\)\n\n\\(\\implies \\mathbb{E}(\\sigma^2) = \\sigma^2_0 \\frac{\\nu_0 / 2}{\\nu_0 / 2 - 1}\\) (use expectation of inverse gamma)\n\\(\\theta \\mid \\sigma^2 \\sim \\mathcal{N}(\\mu_0, \\sigma^2 / \\kappa_0)\\)\n\\(\\implies \\mathbb{E}(\\theta) = \\mu_0\\)\n\nThe updated parameters are\n\n\\(\\nu_n = \\nu_0 + n\\)\n\\(\\sigma_n^2 = \\frac{1}{\\nu_n} \\left[ \\nu_0 \\sigma_0^2 + (n - 1)s^2 + \\frac{\\kappa_0 n}{\\kappa_n} (\\bar{y} - \\mu_0)^2 \\right]\\)\n\\(\\mu_n = \\frac{\\kappa_0 \\mu_0 + n\\bar{y}}{\\kappa_n}\\)\n\\(\\kappa_n = \\kappa_0 + n\\)\n\nSo that the posterior is finally\n\n\\(1 / \\sigma^2 \\mid y_1, \\dots, y_n \\sim \\text{Gamma}(\\nu_n / 2, \\sigma^2_n \\nu_n / 2)\\)\nWhere \\(\\mathbb{E}(\\sigma^2 \\mid y_1, \\dots, y_n) = \\frac{\\sigma^2_n \\nu_n}{2 (\\nu_n / 2 - 1)}\\) (using the expectation of the inverse gamma)\n\\(\\theta \\mid \\sigma^2, y_1, \\dots, y_n \\sim \\mathcal{N}(\\mu_n, \\sigma^2 / \\kappa_n)\\)\nWhere \\(\\mathbb{E}(\\theta \\mid y_1, \\dots, y_n, \\sigma^2) = \\mu_n = \\frac{\\kappa_0 \\mu_0 + n \\bar{y}}{\\kappa_n}\\)\n\n\nNote how the prior sample sizes for the variance and the mean are decoupled because they update differently. However, it’s common to set \\(\\nu_0 =\n\\kappa_0\\)."
  },
  {
    "objectID": "5.html#example",
    "href": "5.html#example",
    "title": "Chapter 5: The Normal Model",
    "section": "\n3.3 Example",
    "text": "3.3 Example\nBack to midge wing length, although this time, we are leaving our estimate of the variance of the population free as well.\nFrom other populations, say that we weakly believe that our prior estimates of the population mean and variance are \\(\\mu_0 = 1.9\\) and \\(\\sigma_0^2 = 0.01\\), respectively. Since this is a weak belief we will pick \\(\\kappa_0 = \\nu_0 = 1\\). Now our prior distributions are\n\n\\(1 / \\sigma^2 \\sim \\text{Gamma}(0.5, 0.005)\\)\n\\(\\theta \\mid \\sigma^2 \\sim \\mathcal{N}(1.9, \\sigma^2 / \\kappa_0)\\)\n\nRecall that our data are\n\nShow R codey = c(1.64, 1.70, 1.72, 1.74, 1.82, 1.82, 1.82, 1.90, 2.08)\nn = length(y)\nybar = mean(y)\ns2 = var(y)\n\n\nNow we calculate the parameters of the posterior distributions\n\n\\(\\kappa_n = \\kappa_0 + n = 1 + 9 = 10\\)\n\\(\\nu_n = \\nu_0 + n = 1 + 9 =10\\)\n\\(\\mu_n = \\frac{\\kappa_0 \\mu_0 + n\\bar{y}}{\\kappa_n} = \\frac{1.9 + 9(1.804)}{10} = 1.814\\)\n\\[\\begin{align}\n\\sigma_n^2 &= \\frac{1}{\\nu_n} \\left[ \\nu_0 \\sigma_0^2 + (n - 1)s^2 + \\frac{\\kappa_0 n}{\\kappa_n} (\\bar{y} - \\mu_0)^2 \\right] \\\\\n&= \\frac{1}{10} \\left[ 0.01 + 8(0.168) + \\frac{9}{10} (1.804 - 1.9)^2 \\right] \\\\\n&= \\frac{1}{10} \\left[ 0.01 + 0.135 + 0.008 \\right] \\\\\n&= 0.015\n\\end{align}\\]\n\nSo our joint posterior distribution is\n\\[\\begin{align}\n1 / \\sigma^2 \\mid y_1, \\dots, y_n &\\sim \\text{Gamma}(10/2 = 5, 10(0.015 / 2) = 0.075) \\\\\n\\theta \\mid \\sigma^2, y_1, \\dots, y_n &\\sim \\mathcal{N}(1.814, \\sigma^2 / 10)\n\\end{align}\\]\nNow we can plot the posterior distribution for various values of \\(\\theta\\) and \\(\\sigma^2\\).\n\nShow R code# Prior\nmu0 = 1.9\nkappa0 = 1\ns20 = 0.01\nnu0 = 1\n\nkappan = kappa0 + n\nnun = nu0 + n\nmun = (kappa0 * mu0 + n * ybar) / kappan\ns2n = (1 / nun) * (nu0 * s20 + (n - 1) * s2 + (kappa0 * n / kappan) * (ybar - mu0)^2)\n\nTheta = seq(1.6, 2.0, by = 0.005)\nSigma2 = seq(0, 0.04, by = 0.0001)\n\nlibrary(invgamma)\npost.func = function(theta, sigma2) {\n  dnorm(theta, mun, sqrt(sigma2 / kappan)) * dinvgamma(sigma2, nun / 2, s2n * nun / 2)\n}\n\nd = outer(Theta, Sigma2, post.func)\nrownames(d) = Theta\ncolnames(d) = Sigma2\n\ndf = melt(d)\ncolnames(df) = c('theta', 'sigma2', 'density')\n\nggplot(df, aes(x = theta, y = sigma2, z = density)) +\n  geom_contour(aes(color = ..level..)) +\n  guides(color = FALSE)"
  },
  {
    "objectID": "5.html#monte-carlo-sampling",
    "href": "5.html#monte-carlo-sampling",
    "title": "Chapter 5: The Normal Model",
    "section": "\n3.4 Monte carlo sampling",
    "text": "3.4 Monte carlo sampling\nWe can simulate values from the posterior by first sampling \\(\\sigma^{2(n)}\\) from its inverse gamma distribution, and \\(\\theta^{(n)}\\) from its normal distribution conditioned on \\(\\sigma^{2(n)}\\). Then \\(\\{\\theta^{(n)}, \\sigma^{2(n)}\\}\\) represent samples from the joint distribution \\(p(\\theta, \\sigma^2 \\mid y_1, \\dots, y_n)\\), and either set of values by themselves represents samples from the full marginal distribution. This is intuitive for \\(\\sigma^{2(n)}\\) but less so for \\(\\theta^{(n)}\\). The key is to notice that, although \\(\\theta^{(n)}\\) is sampled conditioned on \\(\\sigma^{2(n)}\\), multiple \\(\\theta^{(n)}\\) samples are conditioned on multiple different \\(\\sigma^{2(n)}\\)s, so the \\(\\theta^{(n)}\\) do indeed represent samples from the marginal distribution.\n\nShow R codes2.mc = rinvgamma(10000, nun / 2, s2n * nun / 2)\ntheta.mc = rnorm(10000, mun, sqrt(s2.mc / kappan)) # Accepts a vector of parameters\nmean(theta.mc)\n#&gt; [1] 1.813665\nquantile(theta.mc, c(0.025, 0.975))\n#&gt;     2.5%    97.5% \n#&gt; 1.725932 1.899375\n\n\n\nShow R codeggplot(data.frame(sigma2 = s2.mc, theta = theta.mc)) +\n  geom_point(aes(x = theta, y = sigma2), alpha = 0.1)"
  },
  {
    "objectID": "5.html#improper-priors",
    "href": "5.html#improper-priors",
    "title": "Chapter 5: The Normal Model",
    "section": "\n3.5 Improper priors",
    "text": "3.5 Improper priors\nWhat if we want to use no prior information? See what happens to our posterior distribution \\(\\kappa_0, \\nu_0 \\rightarrow 0\\). Using the formula above,\n\n\\(\\sigma_n^2 \\rightarrow \\frac{n - 1}{n}s^2\\)\n\n\\(\\mu_n \\rightarrow \\bar{y}\\).\n\nThen, the “posterior” (plugging in \\(\\kappa_0 = \\nu_0 = 0\\) and the posterior parameters \\(\\sigma_n^2, \\mu_n\\) and simplifying) would be\n\\[\\begin{align}\n1 / \\sigma^2 \\mid y_1, \\dots, y_n &\\sim \\text{Gamma}(\\frac{n}{2}, \\frac{1}{n} \\frac{n}{2}\\sum (y_i - y)^2)$ \\\\\n\\theta \\mid \\sigma^2, y_1, \\dots, y_n &\\sim \\mathcal{N}(\\bar{y}, \\frac{\\sigma^2}{n})\n\\end{align}\\]\n\n\n\n\nWith “significant algebra”, you can show that inference this way results in\n\\[\\frac{\\theta - \\bar{y}}{s / \\sqrt{n}} \\mid y_1, \\dots, y_n \\sim t_{n - 1}\\]\ni.e. a \\(t\\) distribution with \\(n - 1\\) degrees of freedom. This is similar to the sampling distribution of \\(t\\) statistic:\n\\[\\frac{\\bar{Y} - \\theta}{s / \\sqrt{n}} \\mid \\theta \\sim t_{n - 1}\\]\nbut like the Bayesian vs Frequentist confidence intervals discussion in Chapter 3, they are philosophically different. The first describes uncertainty about the true mean conditional on the data, while the second describes uncertainty about the observed sample mean given the true population mean."
  },
  {
    "objectID": "5.html#section",
    "href": "5.html#section",
    "title": "Chapter 5: The Normal Model",
    "section": "\n7.1 5.1",
    "text": "7.1 5.1\n\nShow R codeschool1 = scan('Exercises/school1.dat')\nschool2 = scan('Exercises/school2.dat')\nschool3 = scan('Exercises/school3.dat')\n\n\n\n7.1.1 a\n\nShow R codemu0 = 5\ns20 = 4\nk0 = 1\nnu0 = 2\n\nparams = lapply(list(school1, school2, school3), function(sdata) {\n  # Statistics of data\n  n = length(sdata)\n  ybar = mean(sdata)\n  s2 = var(sdata)\n  \n  # Compute posterior values, mun, s2n, kappan, nun\n  kn = k0 + n\n  nun = nu0 + n\n  mun = (k0 * mu0 + n * ybar) / kn\n  s2n = (1 / nun) * (nu0 * s20 + (n - 1) * s2 + ((k0 * n) / kn) * (ybar - mu0)^2)\n  \n  c('mun' = mun, 's2n' = s2n, 'kn' = kn, 'nun' = nun)\n})\n\nparams.df = as.data.frame(rbind(params[[1]], params[[2]], params[[3]]))\nrownames(params.df) = c('school1', 'school2', 'school3')\n\n\n\nShow R code# 5000 monte carlo samples. Need to estimate \\sigma^2 before \\theta.\n# I can easily do means and confidence intervals of the \\sigma^2, but for\n# brevity, I will output only \\theta\nschool1.s2.mc = 1 / rgamma(5000, params.df[1, ]$nun / 2, params.df[1, ]$s2n * params.df[1, ]$nun / 2)\nschool1.theta.mc = rnorm(5000, params.df[1, ]$mun, sqrt(school1.s2.mc / params.df[1, ]$kn))\nquantile(school1.theta.mc, probs = c(0.025, 0.5, 0.975))\n#&gt;      2.5%       50%     97.5% \n#&gt;  7.817611  9.310191 10.882127\n\nschool2.s2.mc = 1 / rgamma(5000, params.df[2, ]$nun / 2, params.df[2, ]$s2n * params.df[2, ]$nun / 2)\nschool2.theta.mc = rnorm(5000, params.df[2, ]$mun, sqrt(school2.s2.mc / params.df[2, ]$kn))\nquantile(school2.theta.mc, probs = c(0.025, 0.5, 0.975))\n#&gt;     2.5%      50%    97.5% \n#&gt; 5.156598 6.966805 8.773847\n\nschool3.s2.mc = 1 / rgamma(5000, params.df[3, ]$nun / 3, params.df[3, ]$s2n * params.df[3, ]$nun / 2)\nschool3.theta.mc = rnorm(5000, params.df[3, ]$mun, sqrt(school3.s2.mc / params.df[3, ]$kn))\nquantile(school3.theta.mc, probs = c(0.025, 0.5, 0.975))\n#&gt;     2.5%      50%    97.5% \n#&gt; 5.753531 7.798181 9.868711\n\n\n\n7.1.2 b\n\nShow R codelibrary(combinat)\nschool.theta.mc = list(school1.theta.mc, school2.theta.mc, school3.theta.mc)\nperms = permn(1:3)\ntheta.lt.probs = lapply(perms, function(perm) {\n  # This is a vector e.g. c(1, 3, 2)\n  mean(school.theta.mc[[perm[1]]] &lt; school.theta.mc[[perm[2]]] &\n         school.theta.mc[[perm[2]]] &lt; school.theta.mc[[perm[3]]])\n})\nnames(theta.lt.probs) = sapply(perms, function(v) paste(v, collapse =' &lt; '))\ntheta.lt.probs.stacked = stack(theta.lt.probs)[, c(2, 1)] # Reverse stack order\nkable(theta.lt.probs.stacked, col.names = c('inequality', 'prob'))\n\n\n\ninequality\nprob\n\n\n\n1 &lt; 2 &lt; 3\n0.0062\n\n\n1 &lt; 3 &lt; 2\n0.0028\n\n\n3 &lt; 1 &lt; 2\n0.0156\n\n\n3 &lt; 2 &lt; 1\n0.2514\n\n\n2 &lt; 3 &lt; 1\n0.6118\n\n\n2 &lt; 1 &lt; 3\n0.1122\n\n\n\n\n\n\n7.1.3 c\n\nShow R codeschool.s2.mc = list(school1.s2.mc, school2.s2.mc, school3.s2.mc)\nschool.y.mc = lapply(1:3, function(i) {\n  this.s2 = school.s2.mc[[i]]\n  this.theta = school.theta.mc[[i]]\n  rnorm(5000, this.theta, sqrt(this.s2))\n})\ny.lt.probs = lapply(perms, function(perm) {\n  # This is a vector e.g. c(1, 3, 2)\n  mean(school.y.mc[[perm[1]]] &lt; school.y.mc[[perm[2]]] &\n         school.y.mc[[perm[2]]] &lt; school.y.mc[[perm[3]]])\n})\nnames(y.lt.probs) = sapply(perms, function(v) paste(v, collapse =' &lt; '))\ny.lt.probs.stacked = stack(y.lt.probs)[, c(2, 1)] # Reverse stack order\nkable(y.lt.probs.stacked, col.names = c('inequality', 'prob'))\n\n\n\ninequality\nprob\n\n\n\n1 &lt; 2 &lt; 3\n0.1124\n\n\n1 &lt; 3 &lt; 2\n0.0994\n\n\n3 &lt; 1 &lt; 2\n0.1360\n\n\n3 &lt; 2 &lt; 1\n0.2038\n\n\n2 &lt; 3 &lt; 1\n0.2476\n\n\n2 &lt; 1 &lt; 3\n0.2008\n\n\n\n\n\n\n7.1.4 d\n\nShow R codetheta1.big.prob = mean(school.theta.mc[[1]] &gt; school.theta.mc[[2]] & school.theta.mc[[1]] &gt; school.theta.mc[[3]])\nprint(theta1.big.prob)\n#&gt; [1] 0.8632\ny1.big.prob = mean(school.y.mc[[1]] &gt; school.y.mc[[2]] & school.y.mc[[1]] &gt; school.y.mc[[3]])\nprint(y1.big.prob)\n#&gt; [1] 0.4514"
  },
  {
    "objectID": "5.html#section-1",
    "href": "5.html#section-1",
    "title": "Chapter 5: The Normal Model",
    "section": "\n7.2 5.2",
    "text": "7.2 5.2\n\nShow R codemu0 = 75\ns20 = 100\n\nn.a = n.b = 16\nybar.a = 75.2\ns2.a = 7.3^2\nybar.b = 77.5\ns2.b = 8.1^2\n\nk0nu0 = c(1, 2, 4, 8, 16, 32)\n\nprob = sapply(k0nu0, function(p) {\n  # p is the common parameter for k0 and nu0\n  \n  # Calculate posterior parameters\n  kn.a = p + n.a\n  nun.a = p + n.a\n  mun.a = (p * mu0 + n.a * ybar.a) / kn.a\n  s2n.a = (1 / nun.a) * (p * s20 + (n.a - 1) * s2.a + ((p * n.a) / kn.a) * (ybar.a - mu0)^2)\n  \n  s2.a.mc = 1 / rgamma(10000, nun.a / 2, s2n.a * nun.a / 2)\n  theta.a.mc = rnorm(10000, mun.a, sqrt(s2.a.mc/kn.a))\n  \n  kn.b = p + n.b\n  nun.b = p + n.b\n  mun.b = (p * mu0 + n.b * ybar.b) / kn.b\n  s2n.b = (1 / nun.b) * (p * s20 + (n.b - 1) * s2.b + ((p * n.b) / kn.b) * (ybar.b - mu0)^2)\n  \n  s2.b.mc = 1 / rgamma(10000, nun.b / 2, s2n.b * nun.b / 2)\n  theta.b.mc = rnorm(10000, mun.b, sqrt(s2.b.mc/kn.b))\n  \n  mean(theta.a.mc &lt; theta.b.mc)\n})\n\nqplot(k0nu0, prob, geom = c('line', 'point'))\n\n\n\n\n\n\n\nIn general, there is weak evidence that \\(\\theta_A &lt; \\theta_B\\). Depending on the strength of a person’s confidence in the prior, as quantified by a “prior sample size” \\(\\nu_0 = \\kappa_0\\), the posterior probability starts at ~0.58 and declines as strength increases. However, it takes a very strong prior belief for the probability to dip below 0.50."
  },
  {
    "objectID": "5.html#section-2",
    "href": "5.html#section-2",
    "title": "Chapter 5: The Normal Model",
    "section": "\n7.3 5.3",
    "text": "7.3 5.3\nI’ll derive \\(p(\\sigma^2 \\mid y_1, \\dots, y_n)\\):\n\\[\\begin{align}\np(\\sigma^2 \\mid y_1, \\dots, y_n) &\\propto p(\\sigma^2)p(y_1, \\dots, y_n \\mid \\sigma^2) \\\\\n&= p(\\sigma^2) \\times \\int p(y_1, \\dots, y_n \\mid \\theta, \\sigma^2) p(\\theta \\mid \\sigma^2) \\; d\\theta \\\\\n&= \\text{dinvgamma}(\\sigma^2, \\nu_0 / 2, \\nu_0 \\sigma_0^2 / 2) \\int \\left[ \\prod_{i=1}^n \\text{dnorm}(y_i, \\theta, \\sigma^2) \\right] \\times \\text{dnorm}(\\theta, \\mu_0, \\sigma^2 / \\kappa_0)\\; d\\theta \\\\\n&= \\text{dinvgamma}(\\sigma^2, \\nu_0 / 2, \\nu_0 \\sigma_0^2 / 2) \\; \\times \\\\ &\\quad \\int (2\\pi\n\\sigma^2)^{-n/2} \\text{exp}\\left( -\\frac{1}{2} \\sum \\frac{(y_i -\n\\theta)^2}{\\sigma^2} \\right) \\times \\frac{1}{\\sqrt{2\\pi\\sigma^2 / \\kappa_0}}\n\\text{exp}\\left(-\\frac{1}{2} \\frac{(\\theta - \\mu_0)^2}{\\sigma^2 / \\kappa_0}\\right) \\; d\\theta \\\\\n&\\propto \\text{dinvgamma}(\\sigma^2, \\nu_0 / 2, \\nu_0 \\sigma_0^2 / 2) \\; \\times \\\\ &\\quad \\sigma^{2(-(n + 1)/2)} \\int \\text{exp}\\left( -\\frac{1}{2} \\sum \\frac{(y_i -\n\\theta)^2}{\\sigma^2} \\right) \\times\n\\text{exp}\\left(-\\frac{1}{2} \\frac{(\\theta - \\mu_0)^2}{\\sigma^2 / \\kappa_0}\\right) \\; d\\theta \\\\\n&\\propto \\dots\n\\end{align}\\]\nThis is apparently non-trivial, and requires expanding the quadratic terms in the \\(\\text{exp}\\) terms. I’ll skip this for now."
  },
  {
    "objectID": "5.html#section-3",
    "href": "5.html#section-3",
    "title": "Chapter 5: The Normal Model",
    "section": "\n7.4 5.4",
    "text": "7.4 5.4\n\n7.4.1 a\nThe log-likelihood function \\(\\ell\\) is\n\\[\\begin{align}\n\\ell(Y \\mid \\theta, \\sigma^2) &= \\log \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\text{exp}\\left(-\\frac{1}{2}\\sum_{i=1}^n \\frac{(y_i - \\theta)^2}{\\sigma^2} \\right) \\right] \\\\\n&= -\\frac{n}{2} \\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\theta)^2 \\\\\n&= -\\frac{n}{2} \\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n y_i^2 -2\\theta y_i + \\theta^2 \\\\\n&= -\\frac{n}{2} \\log(2\\pi) - \\frac{n}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\left(  \\sum y_i^2 - 2\\theta \\sum y_i + n \\theta^2 \\right)\n\\end{align}\\]\nThe first derivatives are\n\\[\\begin{align}\n\\ell_\\theta(Y \\mid \\theta, \\sigma) &= \\frac{\\sum y_i - n\\theta}{\\sigma^2} \\\\\n\\ell_{\\sigma^2}(Y \\mid \\theta, \\sigma) &= -\\frac{n}{2\\sigma^2} + \\frac{\\sum y_i^2}{2(\\sigma^2)^2} - \\frac{2\\theta \\sum y_i}{2(\\sigma^2)^2} + \\frac{n\\theta^2}{2(\\sigma^2)^2} \\\\\n\\end{align}\\]\nSo the \\(2 \\times 2\\) matrix \\(I(\\theta, \\sigma^2)\\) is (expectations wrt \\(Y\\))\n\\[\\begin{align}\nI(\\theta, \\sigma^2) &=\n\\begin{bmatrix}\n-\\mathbb{E}\\left( \\ell_{\\theta\\theta}(Y \\mid \\theta, \\sigma) \\right) & -\\mathbb{E}\\left( \\ell_{\\theta\\sigma^2}(Y \\mid \\theta, \\sigma) \\right) \\\\\n-\\mathbb{E}\\left( \\ell_{\\sigma^2\\theta}(Y \\mid \\theta, \\sigma) \\right) & -\\mathbb{E}\\left( \\ell_{\\sigma^2\\sigma^2}(Y \\mid \\theta, \\sigma) \\right)\\\\\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n-\\mathbb{E}\\left( -\\frac{n}{\\sigma^2} \\right) &\n-\\mathbb{E}\\left( -\\frac{\\sum y_i - n\\theta}{(\\sigma^2)^2}\\right) \\\\\n-\\mathbb{E}\\left( -\\frac{\\sum y_i - n\\theta}{(\\sigma^2)^2}\\right) &\n-\\mathbb{E}\\left( \\frac{n}{2(\\sigma^2)^2} - \\frac{\\sum y_i^2 - 2\\theta\\sum y_i + n\\theta^2}{(\\sigma^2)^3}\\right) \\\\\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n\\frac{n}{\\sigma^2} &\n-\\left( -\\frac{n\\theta - n\\theta}{(\\sigma^2)^2} \\right) \\\\\n-\\left( -\\frac{n\\theta - n\\theta}{(\\sigma^2)^2} \\right) &\n-\\frac{n}{2(\\sigma^2)^2} + \\frac{\\mathbb{E}(\\sum y_i^2 - 2\\theta\\sum y_i + n\\theta^2)}{(\\sigma^2)^3} \\\\\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n\\frac{n}{\\sigma^2} &\n0 \\\\\n0 &\n\\frac{n}{2(\\sigma^2)^2} \\\\\n\\end{bmatrix}\n\\end{align}\\]\nThe last one is derived as follows:\n\\[\\begin{align}\n-\\frac{n}{2(\\sigma^2)^2} + \\frac{\\mathbb{E}(\\sum y_i^2 - 2\\theta\\sum y_i + n\\theta^2)}{(\\sigma^2)^3} &= -\\frac{n}{2(\\sigma^2)^2} + \\frac{n(\\theta^2 + \\sigma^2) - 2\\theta(n\\theta) + n\\theta^2}{(\\sigma^2)^3} \\\\\n&= -\\frac{n}{2(\\sigma^2)^2} + \\frac{n\\sigma^2}{(\\sigma^2)^3} \\\\\n&= -\\frac{n}{2(\\sigma^2)^2} + \\frac{2n}{2(\\sigma^2)^2} \\\\\n&= \\frac{n}{2(\\sigma^2)^2}\n\\end{align}\\]\nSo Jeffrey’s prior is\n\\[\\begin{align}\np_J(\\theta, \\sigma^2) &\\propto \\sqrt{|I(\\theta, \\sigma^2)|} \\\\\n&= \\sqrt{\\frac{n^2}{2(\\sigma^2)^3}} \\\\\n&\\propto \\sqrt{\\frac{n^2}{2}} \\sqrt{\\frac{1}{(\\sigma^2)^3}} \\\\\n&\\propto (\\sigma^2)^{-3/2}.\n\\end{align}\\]\n\n7.4.2 b\n\\[\\begin{align}\np_J(\\theta, \\sigma^2 \\mid \\mathbf{y}) &\\propto p_J(\\theta, \\sigma^2) p(\\mathbf{y} \\mid \\theta, \\sigma^2) \\\\\n&\\propto (\\sigma^2)^{-3/2} \\times (\\sigma^2)^{-n/2} \\text{exp}\\left(-\\frac{1}{2\\sigma^2} \\sum_{i = 1}^n (y_i - \\theta)^2 \\right) \\\\\n&= (\\sigma^2)^{-(3 + n)/2} \\text{exp}\\left(-\\frac{1}{2\\sigma^2} \\sum_{i = 1}^n (y_i - \\theta)^2 \\right)\n\\end{align}\\]\nYes, since there is some normalizing constant that results in the integral over \\(p_J\\) being equal to 1.\nAfter some poking around, this is a normal-inverse-chi-squared distribution."
  },
  {
    "objectID": "10.html",
    "href": "10.html",
    "title": "Chapter 10: Nonconjugate priors and Metropolis-Hastings algorithms",
    "section": "",
    "text": "Poisson + logistic. No conjugate priors."
  },
  {
    "objectID": "10.html#combining-metropolis-and-gibbs-algorithms",
    "href": "10.html#combining-metropolis-and-gibbs-algorithms",
    "title": "Chapter 10: Nonconjugate priors and Metropolis-Hastings algorithms",
    "section": "\n2.1 Combining Metropolis and Gibbs algorithms",
    "text": "2.1 Combining Metropolis and Gibbs algorithms\nSince proposal distributions for different parameters can all be different - could use Gibbs for some parameters (where Gibbs is just a special case of Metropolis-Hastings)\n\n2.1.1 A regression model with correlated errors\nHere I explore the idea of running multiple independent MCMC chains, then combining the data (which is theoretically OK). In icecore_parallel.R I take the MH algorithm for analyzing the icecore data and distribute it across multiple cores with parallel::mclapply. That file creates icecore_mcmc which is analyzed here.\n\nShow R codeif (!file.exists('./icecore_mcmc')) {\n  stop(\"Run icecore_parallel.R first to get MCMC data\")\n}\nload('./icecore_mcmc')\n# Should have \"outs\" now\n# TODO: put colnames in icecore_parallel\ncolnames(outs) = c('b1', 'b2', 's2', 'phi')\nplot(density(outs[seq(1, 80000), 'phi']))\n\n\n\n\n\n\nShow R codeplot(density(outs[seq(1, 80000, by = 25), 'phi']))\n\n\n\n\n\n\nShow R code\nouts.df = data.frame(outs)\nouts.df$iteration = 1:nrow(outs.df)\n\nmessage(nrow(outs.df), \" samples in ./icecore_mcmc\")\n\nggplot(outs.df, aes(x = iteration, y = phi)) +\n  geom_line()\n\n\n\n\n\n\nShow R code\neffectiveSize(outs.df$phi)\n#&gt;     var1 \n#&gt; 1084.922"
  },
  {
    "objectID": "10.html#section",
    "href": "10.html#section",
    "title": "Chapter 10: Nonconjugate priors and Metropolis-Hastings algorithms",
    "section": "\n3.1 10.2",
    "text": "3.1 10.2\n\nShow R codemsparrownest = read.table('Exercises/msparrownest.dat')\n\n\nFor convenience let \\(\\theta_i = P(Y_i = 1 \\mid \\alpha, \\beta, x_i)\\). Now we solve for \\(\\theta_i\\) in our model\n\\[\n\\begin{align}\n& \\log\\left(\\frac{\\theta_i}{1 - \\theta_i}\\right) = \\alpha + \\beta x_i \\\\\n\\implies& \\frac{\\theta_i}{1 - \\theta_i} = \\exp(\\alpha + \\beta x_i) \\\\\n\\implies& \\theta_i = \\exp(\\alpha + \\beta x_i) - \\theta_i \\exp(\\alpha + \\beta x_i) \\\\\n\\implies& \\theta_i = \\frac{\\exp(a + \\beta x_i)}{1 + \\exp(\\alpha + \\beta x_i)}\n\\end{align}\n\\]\nSo we know \\(Y_i \\sim \\text{Bernoulli}\\left(p_i\\right)\\) where \\(p_i = \\frac{\\exp(a + \\beta x_i)}{1 + \\exp(a + \\beta x_i)}\\) and thus\n\\[\np(y_i \\mid \\alpha, \\beta, x_i) = p_i^{y_i}(1 - p_i)^{1 - y_i}\n\\]\n\n3.1.1 a\nLet \\(z_i = \\exp(\\alpha + \\beta x_i)\\) for simplicity.\n\\[\n\\begin{align}\np(\\boldsymbol{y} \\mid \\alpha, \\beta, x_i) &= \\prod_{i = 1}^n p(y_i \\mid \\alpha, \\beta, x_i) \\\\\n&= \\prod_{i = 1}^n p_i^{y_i} (1 - p_i)^{1 - y_i} \\\\\n&= \\prod_{i = 1}^n \\left(\\frac{z_i}{1 + z_i} \\right)^{y_i} \\left(1 - \\frac{z_i}{1 + z_i} \\right)^{1 - y_i} \\\\\n&= \\prod_{i = 1}^n \\left(\\frac{z_i}{1 + z_i} \\right)^{y_i} \\left(\\frac{1 + z_i}{1 + z_i} - \\frac{z_i}{1 + z_i} \\right)^{1 - y_i} \\\\\n&= \\prod_{i = 1}^n \\left(\\frac{z_i}{1 + z_i} \\right)^{y_i} \\left(\\frac{1}{1 + z_i}\\right)^{1 - y_i} \\\\\n&= \\prod_{i = 1}^n \\frac{z_i^{y_i}}{(1 + z_i)^{y_i}} \\frac{1}{(1 + z_i)^{1 - y_i}} \\\\\n&= \\prod_{i = 1}^n \\frac{z_i^{y_i}}{1 + z_i} \\\\\n&= \\prod_{i = 1}^n \\frac{\\exp(y_i (\\alpha + \\beta x_i))}{1 + \\exp(\\alpha + \\beta x_i)} \\\\\n\\end{align}\n\\]\nand I don’t think that can be simplified further.\n\n3.1.2 b\nIt’s helpful (I think) to think about this in terms of the log-odds i.e. \\(\\text{log-odds}(\\theta_i) = a + \\beta x_i\\). If we have an uniformative prior where we by default assume no interaction between wingspan \\(x_i\\) and nesting, then we should center our prior for \\(\\beta\\) around 0. If we also want to be uninformative about our prior proportion of nesting birds regardless of wingspan, then we should center our prior for \\(\\alpha\\) around 0 as well, our prior expectation regardless of \\(x_i\\) is \\(\\text{log-odds}(\\theta_i) = 0 + 0 x_i = 0\\) (so not favoring nesting or not).\nThe question is what to use for a prior distribution and how diffuse to make our priors. We would like priors for \\(\\alpha\\) and \\(\\beta\\) to be symmetric, so normal distributions for both make sense. And we want our prior to be uninformative, so we should set the variance of these normals high.\nIf \\(\\alpha\\) is always 0, then as \\(x\\) moves from 10 to 15, we want our possible values of \\(\\beta\\) to allow for a change in the log-odds ratio from approximately 0 to 1. Notice the log-odds ratio of some sufficiently small number e.g. 1e-5 is -11.5129155 which is roughly 10. Since \\(x\\) at a minimum is 10, it makes sense to have most of our prior on \\(\\beta\\) in the range \\([-10 / 10, 10 / 10] = [-1, 1]\\), so I’ll set the standard deviation of the \\(\\beta\\) prior to 0.5 and the variance to 0.25.\nSimilarly I’ll let the standard deviation of our \\(\\alpha\\) prior to be 5 and the variance 25, so that, if \\(\\beta = 0\\), the most of the \\(\\alpha\\) prior falls in the log-odds interval \\([-10, 10]\\).\nSo\n\\[\n\\begin{align}\n\\alpha &\\sim \\mathcal{N}(0, 25) \\\\\n\\beta &\\sim \\mathcal{N}(0, 0.25) \\\\\n\\end{align}\n\\]\n\n3.1.3 c\n\nShow R codelibrary(MASS)\ninv = solve\n# In this sampling scheme, when we sample, we keep the values together\n# ($\\theta$). But when I store the values, I split them (ALPHA, BETA).\nS = 10000\nburnin = 5000\ny = msparrownest[, 1]\nn = length(y)\n# Use linear regression format, where column 1 is 1 (for alpha) and column 2 is\n# the wingspan\nx = cbind(rep(1, n), msparrownest[, 2])\n\n# Start with X^T X but increase until acceptance ratio between 30% - 50%\nvar.prop = 7 * inv(t(x) %*% x)\n\n# Prior parameters\npmn.theta = c(0, 0)\npsd.theta = sqrt(c(25, 0.25))\n\n# Where to store values\nALPHA = numeric(S + burnin)\nBETA = numeric(S + burnin)\n# Acceptances\nacs = 0\n\n# Initial estimates\ntheta = c(0, 0)\n\n# For calculating likelihood ratio\nlog.p.y = function(x, y, theta) {\n  exp_term = exp(x %*% theta)\n  p = exp_term / (1 + exp_term)\n  sum(dbinom(y, 1, p, log = TRUE))\n}\n\np.theta = function(theta) {\n  sum(dnorm(theta, pmn.theta, psd.theta, log = TRUE))\n}\n\nfor (s in 1:(S + burnin)) {\n  theta.star = mvrnorm(1, theta, var.prop)\n\n  lhr = log.p.y(x, y, theta.star) +\n    p.theta(theta.star) -\n    log.p.y(x, y, theta) -\n    p.theta(theta)\n\n  if (log(runif(1)) &lt; lhr) {\n    theta = theta.star\n    if (s &gt; burnin) {\n      acs = acs + 1\n    }\n  }\n  ALPHA[s] = theta[1]\n  BETA[s] = theta[2]\n}\nALPHA = ALPHA[burnin:length(ALPHA)]\nBETA = BETA[burnin:length(BETA)]\n\nmessage(\"Acceptance ratio: \", acs / S) # Good to go\nc(effectiveSize(ALPHA), effectiveSize(BETA))\n#&gt;     var1     var1 \n#&gt; 1569.255 1549.445\n\n\n\n3.1.4 d\n\nShow R codealpha_prior = data.frame(\n  val = seq(-10, 10, length.out = 1000),\n  density = dnorm(seq(-10, 10, length.out = 1000), 0, 5),\n  var = 'alpha',\n  dist = 'prior'\n)\nbeta_prior = data.frame(\n  val = seq(-1, 1, length.out = 1000),\n  density = dnorm(seq(-1, 1, length.out = 1000), 0, 0.5),\n  var = 'beta',\n  dist = 'prior'\n)\nprior_df = rbind(alpha_prior, beta_prior)\nalpha_post = data.frame(\n  val = ALPHA,\n  var = 'alpha',\n  dist = 'posterior'\n)\nbeta_post = data.frame(\n  val = BETA,\n  var = 'beta',\n  dist = 'posterior'\n)\npost_df = rbind(alpha_post, beta_post)\n\nggplot(prior_df, aes(x = val, y = density, color = dist)) +\n  geom_line() +\n  geom_density(data = post_df, mapping = aes(x = val, y = ..density..)) +\n  facet_wrap(~ var, scales = 'free')\n\n\n\n\n\n\n\n\n3.1.5 e\nUsing the samples of \\(\\alpha\\) and \\(\\beta\\), simply compute a distribution on \\(f_{\\alpha\\beta}(x)\\). We can then construct confidence intervals around this distribution. However, we need to do this for many \\(x\\) values:\n\nShow R codex_seq = seq(10, 15, length = 100)\nquantiles = sapply(x_seq, function(x) {\n  exp_term = exp(ALPHA + BETA * x)\n  fab = exp_term / (1 + exp_term)\n  quantile(fab, probs = c(0.025, 0.5, 0.975))\n})\n\nfab_df = data.frame(\n  wingspan = x_seq,\n  ymin = quantiles[1, ],\n  fpred = quantiles[2, ],\n  ymax = quantiles[3, ]\n)\n\nggplot(fab_df, aes(x = wingspan, y = fpred, ymin = ymin, ymax = ymax)) +\n  geom_line() +\n  geom_ribbon(fill = 'grey', alpha = 0.5)\n\n\n\n\n\n\n\nThis is the logistic regressions’ approximate probability of nesting based on wingspan, although the confidence intervals are quite wide."
  },
  {
    "objectID": "FCBS_FILES.html",
    "href": "FCBS_FILES.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "FCBS_FILES.html#directory-structure",
    "href": "FCBS_FILES.html#directory-structure",
    "title": "",
    "section": "1.1 Directory Structure",
    "text": "1.1 Directory Structure\n\n1.1.1 Exercises/\nContains data files used in the book’s exercises (33 files total): - .dat files with datasets for end-of-chapter exercises - Examples: school1.dat through school8.dat, bluecrab.dat, orangecrab.dat, swim.dat, etc.\n\n\n1.1.2 Inline/\nContains data files and R code used for inline examples in the book (23 files total): - Data files referenced in chapter examples - Short R scripts for specific chapters (chapter7.R through chapter11.R) - Various data formats (plain text, R data dumps) - Special datasets like vostok.icecore.co2.dat for ice core analysis\n\n\n1.1.3 Misc/\nContains miscellaneous book-related materials (3 files total): - bookcover.jpg - Cover image of the book - econjournal_review.pdf - Review from an economics journal - errata.txt - List of known errors in the book\n\n\n1.1.4 Replication/\nContains R code and data for replicating all figures in the book (106 files total): - chapter1.R through chapter12.R - Complete R code for each chapter - fig*_*.pdf - PDF versions of all figures from the book - .RData files - Preprocessed datasets used in examples - Helper functions: hdr2d.r, rlreg.R, regression_gprior.R, backselect.R"
  },
  {
    "objectID": "FCBS_FILES.html#usage",
    "href": "FCBS_FILES.html#usage",
    "title": "",
    "section": "1.2 Usage",
    "text": "1.2 Usage\nThese files are now available locally in the repository and can be referenced directly instead of downloading from the web. For example:\n# Old way (requires internet):\nschool1 = scan('https://www2.stat.duke.edu/~pdh10/FCBS/Exercises/school1.dat')\n\n# New way (local files):\nschool1 = scan('Exercises/school1.dat')"
  },
  {
    "objectID": "FCBS_FILES.html#original-source",
    "href": "FCBS_FILES.html#original-source",
    "title": "",
    "section": "1.3 Original Source",
    "text": "1.3 Original Source\nAll files were downloaded from: https://www2.stat.duke.edu/~pdh10/FCBS/\nBook: Hoff, Peter D. (2009). A First Course in Bayesian Statistical Methods. Springer."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hoff Bayesian Statistics",
    "section": "",
    "text": "These are (fully reproducible!) R Markdown lecture notes for Peter D. Hoff, “A First Course in Bayesian Statistical Methods”, completed as part of a 1-semester independent study course. Only Chapters 1-8 are complete right now.\nEach note includes summaries of chapter sections, with math and explanations modified to better fit my understanding and the occasional link to external resources. I also reproduce many figures in the book in a ggplot/tidyverse style, and tackle some of the exercises at the end of each chapter (correctness not guaranteed).\nIf you find an error or would like to improve the notes, please let me know/submit a PR!"
  },
  {
    "objectID": "index.html#chapters",
    "href": "index.html#chapters",
    "title": "Hoff Bayesian Statistics",
    "section": "1 Chapters",
    "text": "1 Chapters\n\nChapter 1: Introduction and examples\nChapter 2: Belief, probability, and exchangeability\nChapter 3: One-parameter models\nChapter 4: Monte Carlo approximation\nChapter 5: The Normal Model\nChapter 6: Posterior approximation with the Gibbs sampler\nChapter 7: The multivariate normal model\nChapter 8: Group comparisons and hierarchical modeling\nChapter 9: Linear regression\nChapter 10: Nonconjugate priors and Metropolis-Hastings algorithms"
  },
  {
    "objectID": "index.html#final-project",
    "href": "index.html#final-project",
    "title": "Hoff Bayesian Statistics",
    "section": "2 Final Project",
    "text": "2 Final Project\nAs a small final project, I also implemented R code for the basic binary relation version of the Infinite Relational Model, described in Kemp et al. (2006), “Learning Systems of Concepts with an Infinite Relational Model”.\n\nInfinite Relational Model"
  },
  {
    "objectID": "8.html",
    "href": "8.html",
    "title": "Chapter 8: Group comparisons and hierarchical modeling",
    "section": "",
    "text": "A common task in data analysis is to compare summary statistics for two or more groups. In this chapter we cover the Bayesian approach to doing this."
  },
  {
    "objectID": "8.html#prior-and-posterior-distributions",
    "href": "8.html#prior-and-posterior-distributions",
    "title": "Chapter 8: Group comparisons and hierarchical modeling",
    "section": "\n1.1 Prior and posterior distributions",
    "text": "1.1 Prior and posterior distributions\n\n1.1.1 Prior\nThe joint prior for all three parameters of our model \\(\\mu, \\delta, \\sigma^2\\) is unsurprising. We treat the parameters as independent, so \\(p(\\mu, \\delta, \\sigma^2) = p(\\mu) p(\\delta) p(\\sigma^2)\\) where\n\n\\(\\mu \\sim \\mathcal{N}(\\mu_0, \\gamma_0^2)\\)\n\\(\\delta \\sim \\mathcal{N}(\\delta_0, \\tau_0^2)\\)\n\\(\\sigma^2 \\sim \\text{inverse-gamma}(\\nu_0 / 2, \\sigma_0^2 \\nu_0 / 2)\\)\n\nNotice that we specify prior distributions for the common mean and variance, but we also express an estimate (and certainty of the estimate) for the difference between the group means \\(\\delta\\).\n\n1.1.2 Posterior\nThen the full conditional distributions of the parameters are\n\n\n\\(\\mu \\mid \\boldsymbol{y}_1, \\boldsymbol{y}_2, \\delta, \\sigma^2 \\sim \\mathcal{N}(\\mu_n, \\gamma_n^2)\\)\n\n\\(\\mu_n = \\gamma_n^2 \\times \\left[ \\mu_0 / \\gamma_0^2 + \\sum_{i = 1}^{n_1} (y_{i, 1} - \\delta) / \\sigma^2 + \\sum_{i = 1}^{n_2}(y_{i, 2} + \\delta) / \\sigma^2 \\right]\\)\n\\(\\gamma_n^2 = \\left[ 1/\\gamma_0^2 + (n_1 + n_2) / \\sigma^2  \\right]^{-1}\\)\n\n\n\n\\(\\delta \\mid \\boldsymbol{y}_1, \\boldsymbol{y}_2, \\mu, \\sigma^2 \\sim \\mathcal{N}(\\delta_n, \\tau_n^2)\\)\n\n\\(\\delta_n = \\tau_n^2 \\times \\left[ \\delta_0 / \\tau_0^2 + \\sum_{i = 1}^{n_1} (y_{i, 1} - \\mu) / \\sigma^2 - \\sum_{i = 1}^{n_2} (y_{i, 2} - \\mu) / \\sigma^2 \\right]\\)\n\\(\\tau_n^2 = \\left[ 1 / \\tau_0^2 + (n_1 + n_2) / \\sigma^2 \\right]^{-1}\\)\n\n\n\n\\(\\sigma^2 \\mid \\boldsymbol{y}_1, \\boldsymbol{y}_2, \\mu, \\delta \\sim \\text{inverse-gamma}(\\nu_n / 2, \\sigma_n^2 \\nu_n / 2)\\)\n\n\\(\\nu_n = \\nu_0 + n_1 + n_2\\)\n\\(\\nu_n \\sigma_n^2 = \\nu_0 \\sigma_0^2 + \\sum_{i = 1}^{n_1} (y_{i, 1} - \\left[\\mu + \\delta \\right])^2 + \\sum_{i = 1}^{n_2} (y_{i, 2} - \\left[ \\mu - \\delta \\right])^2\\)"
  },
  {
    "objectID": "8.html#analysis-of-the-math-score-data",
    "href": "8.html#analysis-of-the-math-score-data",
    "title": "Chapter 8: Group comparisons and hierarchical modeling",
    "section": "\n1.2 Analysis of the math score data",
    "text": "1.2 Analysis of the math score data\n\nShow R codesource('Replication/chapter8.R')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow R codey1 = y.school1\ny2 = y.school2\nn1 = length(y1)\nn2 = length(y2)\n\n# Priors\nmu0 = 50\ng20 = 625\ndel0 = 0\nt20 = 625\ns20 = 100\nnu0 = 1\n\n# starting values based on ML estimates\nmu = (mean(y1) + mean(y2)) / 2\ndel = (mean(y1) - mean(y2)) / 2\n\n# Gibbs sampler\nS = 5000\nMU = rep(0, S)\nDEL = rep(0, S)\nS2 = rep(0, S)\nY12 = matrix(0, nrow = S, ncol = 2)\n\nset.seed(1)\nfor (s in 1:S)  {\n\n  # Sample s2 according to p.128 eq 3\n  s2 = 1 / rgamma(1, (nu0 + n1 + n2) / 2,\n                  (nu0 * s20 + sum((y1 - mu - del)^2) + sum((y2 - mu + del)^2)) / 2)\n\n  # Sample mu according to p.128 eq 1\n  var.mu = 1 / (1 / g20 + (n1 + n2) / s2)\n  mean.mu = var.mu * (mu0/g20 + sum(y1 - del) / s2 + sum(y2 + del) / s2)\n  mu = rnorm(1, mean.mu, sqrt(var.mu))\n\n  # Sample del according to p.128 eq 2\n  var.del = 1 / (1 / t20 + (n1 + n2) / s2 )\n  mean.del = var.del * (del0 / t20 + sum(y1 - mu) / s2 - sum(y2 - mu) / s2)\n  del = rnorm(1, mean.del, sqrt(var.del))\n\n  # Store params\n  MU[s] = mu\n  DEL[s] = del\n  S2[s] = s2\n  # Sample from posterior\n  Y12[s, ] = rnorm(2, mu + c(1, -1) * del, sqrt(s2))\n}                 \n\nggplot(data.frame(mu = MU)) +\n  geom_density(aes(x = mu))\n\n\n\n\n\n\n\nNow we can directly estimate the probability that \\(\\delta &gt; 0\\):\n\nShow R codemean(DEL &gt; 0)\n#&gt; [1] 0.95\n\n\nas well as the probability that an individual from school 1 is higher than school 2, which due to variance is a bit lower:\n\nShow R codemean(Y12[, 1] &gt; Y12[, 2])\n#&gt; [1] 0.6232"
  },
  {
    "objectID": "8.html#exchangeability-and-hierarchical-models",
    "href": "8.html#exchangeability-and-hierarchical-models",
    "title": "Chapter 8: Group comparisons and hierarchical modeling",
    "section": "\n2.1 Exchangeability and hierarchical models",
    "text": "2.1 Exchangeability and hierarchical models\nUsing de Finetti’s theorem and assuming exchangability, we knew previously that for a single group, we can treat the data within the group as being conditionally i.i.d. given a parameter, which we call the within-group sampling variability:\n\\[\n\\{Y_{1, j}, \\dots, Y_{n_{j}, j} \\mid \\phi_j\\} \\sim \\text{i.i.d.}\\; p(y \\mid \\phi_j)\n\\]\nFurther, if we have many groups with parameters \\(\\phi_j\\) that we assume are sampled from a population of groups we can again use de Finetti’s theorem to treat the group means \\(\\phi_j\\) as conditionally i.i.d. given another parameter, which we call the between-group sampling variability:\n\\[\n\\{\\phi_{1}, \\dots, \\phi_{m} \\mid \\psi\\} \\sim \\text{i.i.d.} \\; p(\\phi \\mid \\psi)\n\\]\nThen we simply need a prior distribution on the parameter for the group parameters (a “hyperparameter”) \\(\\psi\\):\n\\[\n\\psi \\sim p(\\psi)\n\\]\nNote that we can extend this hierarchy arbitrarily."
  },
  {
    "objectID": "8.html#posterior-inference",
    "href": "8.html#posterior-inference",
    "title": "Chapter 8: Group comparisons and hierarchical modeling",
    "section": "\n3.1 Posterior inference",
    "text": "3.1 Posterior inference\n\n3.1.1 Intuition\nWe have samples from \\(m\\) groups \\(\\{\\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_m\\}\\). Our task is to sample from the posterior distribution\n\\[\np(\\theta_1, \\dots, \\theta_m, \\mu, \\tau^2, \\sigma^2 \\mid \\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_m)\n\\]\nfor which we’ll use a Gibbs sampler. We need to find the full conditionals for all unknown quantities above, which seems intimidating. In the Chapter 6 notes (“a shortcut for thinking about full conditionals”), however, I mention that obtaining the full conditional for a single parameter is fairly straightforward by simply writing the entire joint posterior but then treating the other parameters as constants that can be discarded via proportionality.\nTo obtain the full joint posterior we will take use key independence assumptions between the parameters of our model. For example, given a group-specific mean \\(\\theta_j\\), the corresponding random variables \\(Y_{i, j}\\) depend only on \\((\\theta_j, \\sigma^2)\\) and not on \\(\\mu\\) or \\(\\tau^2\\) (this is implied in Figure 8.3).\n\\[\\begin{align}\n& p(\\theta_1, \\dots, \\theta_m, \\mu, \\tau^2, \\sigma^2 \\mid \\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_m) \\\\\n\\quad&\\propto p(\\mu, \\tau^2, \\sigma^2, \\mu, \\tau^2, \\sigma^2) \\times p(\\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_m \\mid \\theta_1, \\dots, \\theta_m, \\mu, \\tau^2, \\sigma^2) & \\text{Bayes' rule} \\\\\n&= p(\\mu, \\tau^2, \\sigma^2) \\times p(\\theta_1, \\dots, \\theta_m \\mid \\mu, \\tau^2, \\sigma^2) \\times p(\\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_m \\mid \\theta_1, \\dots, \\theta_m, \\mu, \\tau^2, \\sigma^2) & \\text{Chain rule} \\\\\n&= p(\\mu) p(\\tau^2) p(\\sigma^2) \\times p(\\theta_1, \\dots, \\theta_m \\mid \\mu, \\tau^2) \\times p(\\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_m \\mid \\theta_1, \\dots, \\theta_m, \\sigma^2) & \\text{Indep.} \\\\\n&= p(\\mu) p(\\tau^2) p(\\sigma^2) \\times \\left[ \\prod_{j = 1}^m p(\\theta_j \\mid \\mu, \\tau^2) \\right] \\times \\left[ \\prod_{j = 1}^m p(\\boldsymbol{y}_j \\mid \\theta_j, \\sigma^2) \\right] & \\text{de Finetti} \\\\\n&= p(\\mu) p(\\tau^2) p(\\sigma^2) \\times \\left[ \\prod_{j = 1}^m p(\\theta_j \\mid \\mu, \\tau^2) \\right] \\times \\left[ \\prod_{j = 1}^m \\left( \\prod_{i = 1}^{n_j} p(y_{i, j} \\mid \\theta_j, \\sigma^2) \\right) \\right] & \\text{de Finetti 2x} \\\\\n\\end{align}\\]\nNow to evaluate a full conditional, for example that for \\(\\mu\\), we take the full posterior and discard all terms that don’t depend on \\(\\mu\\):\n\\[p(\\mu \\mid \\theta_1, \\dots, \\theta_m, \\tau^2, \\sigma^2, \\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_m) \\propto p(\\mu) \\prod_{j=1}^m p(\\theta_j \\mid \\mu, \\tau^2)\\]\nwhich in this case looks exactly like a standard one-sample Normal posterior from Chapter 6, so we borrow that result and replace the relevant variables from our priors. We can do this similarly for the other parameters.\n\n3.1.2 Quantities\nSince the work is quite tedious, I leave out the derivations for the full conditionals of the parameters. To summarize, given priors\n\\[\\begin{align}\n\\sigma^2 &\\sim \\text{inverse-gamma}(\\nu_0 / 2, \\sigma_0^2 \\nu_0 / 2) \\\\\n\\tau^2 &\\sim \\text{inverse-gamma}(\\eta_0 / 2, \\tau_0^2 \\eta_0 / 2) \\\\\n\\mu^2 &\\sim \\mathcal{N}(\\mu_0, \\gamma_0^2)\n\\end{align}\\]\nthe full conditionals are\n\\[\\begin{align}\n\\{\\mu \\mid \\theta_1, \\dots, \\theta_m, \\tau^2\\} &\\sim \\mathcal{N}\\left(\\frac{m\\bar{\\theta} / \\tau^2 + \\mu_0 / \\gamma_0^2}{m/\\tau^2 + 1 / \\gamma_0^2}, \\left[m / \\tau^2 + 1 / \\gamma_0^2 \\right]^{-1}\\right) \\\\\n\\{\\tau^2 \\mid \\theta_1, \\dots, \\theta_m, \\mu\\} &\\sim \\text{inverse-gamma}\\left(\\frac{\\eta_0 + m}{2}, \\frac{\\eta_0\\tau_0^2 + \\sum_{j = 1}^{m}(\\theta_j - \\mu)^2}{2} \\right) \\\\\n\\{\\theta_j \\mid y_{1, j}, \\dots, y_{n_{j}, j}, \\sigma^2\\} &\\sim \\mathcal{N}\\left(\\frac{n_j\\bar{y}_j / \\sigma^2 + 1 / \\tau^2}{n_j / \\sigma^2 + 1 / \\tau^2}, \\left[ n_j / \\sigma^2 + 1 / \\tau^2 \\right]^{-1} \\right) \\\\\n\\{\\sigma^2 \\mid \\boldsymbol{\\theta}, \\boldsymbol{y_1}, \\dots, \\boldsymbol{y_n}\\} &\\sim \\text{inverse-gamma}\\left(\\frac{1}{2}\\left[ \\nu_0 + \\sum_{j = 1}^m n_j\\right], \\frac{1}{2}\\left[\\nu_0\\sigma_0^2 + \\sum_{j = 1}^{m} \\left( \\sum_{i = 1}^{n_j} (y_{i, j} - \\theta)^2 \\right) \\right] \\right)\n\\end{align}\\]\nIt’s worth briefly discussing what these values represent. The full conditionals for \\(\\mu\\) and \\(\\tau^2\\) look like standard normal posteriors. Similarly, the full conditional for \\(\\theta_j\\) looks like a normal posterior dependent only on the specific subgroup \\(\\boldsymbol{y}_j\\) and the common variance \\(\\sigma^2\\). Lastly (and most interestingly), notice that the posterior for \\(\\sigma^2\\) looks like a standard inverse gamma posterior which depends on \\(\\sum \\sum (y_{i, j} -\n\\theta)^2\\) which is the pooled variance across all groups (see also \\(\\sum n_j\\))."
  },
  {
    "objectID": "8.html#prior-distributions-and-posterior-approximation",
    "href": "8.html#prior-distributions-and-posterior-approximation",
    "title": "Chapter 8: Group comparisons and hierarchical modeling",
    "section": "\n4.1 Prior distributions and posterior approximation",
    "text": "4.1 Prior distributions and posterior approximation\nWe need to specify the following priors:\n\\[\n\\sigma^2 \\sim \\text{inverse-gamma}(\\nu_0 / 2, \\sigma_0^2 \\nu_0 / 2)\n\\]\nIf we know the math exam was designed to give a nationwide variance of 100, we can set the within-school variance to 100. This is probably an overestimate since the within-school variance should be less than the nationwide estimate. Regardless, we set \\(\\sigma_0^2 = 100, \\nu_0 = 1\\) to weakly concentrate the prior around 100.\n\\[\n\\tau^2 \\sim \\text{inverse-gamma}(\\eta_0 / 2, \\tau_0^2 \\eta_0 / 2)\n\\]\nSimilarly, we set \\(\\tau_0^2 = 100, \\eta_0 = 1\\).\n\\[\n\\mu^2 \\sim \\mathcal{N}(\\mu_0, \\gamma_0^2)\n\\]\nSince the mean over all schools should be 50, we set \\(\\mu_0 = 50, \\gamma_0^2 = 25\\), so that 95% of the probability of our prior is in \\((40, 60)\\).\n\n4.1.1 Gibbs sampling\nNow that we’re sampling more and more parameters \\(\\{\\mu^{(s)}, \\tau^{2(s)},\n\\sigma^{2(s)}, \\theta_1^{(s)}, \\dots, \\theta_m^{(s)} \\}\\), there’s a key point about Gibbs sampling that must be emphasized: the order in which we sample the new parameters doesn’t matter, but each parameter must be updated according to the most current values of the other parameters. That is, if we have sampled \\(\\mu^{(s+1)}\\), the sample of \\(\\tau^{(s + 1)}\\) must be dependent on \\(\\mu^{(s+1)}\\), NOT \\(\\mu^{(s)}\\). This ensures the markov chain property.\n\nShow R codeY = Y.school.mathscore\n\n# Priors\nnu0 = eta0 = 1\ns20 = t20 = 100\nmu0 = 50\ng20 = 25\n\n# Number of schools. Y[, 1] are school ids\nm = length(unique(Y[, 1]))\n\n# Starting values - use sample mean and variance\nn = sv = ybar = rep(NA, m)\nfor (j in 1:m) {\n  Y_j = Y[Y[, 1] == j, 2]\n  ybar[j] = mean(Y_j)\n  sv[j] = var(Y_j)\n  n[j] = length(Y_j)\n}\n# Let initial theta estimates be the sample means\n# Similarly, let initial values of sigma2, mu, and tau2 be \"sample mean and\n# variance\"\ntheta = ybar\nsigma2 = mean(sv)\nmu = mean(theta)\ntau2 = var(theta)\n\n# MCMC\nset.seed(1)\nS = 1000\nTHETA = matrix(nrow = S, ncol = m)\n# Storing sigma, mu, theta together\nSMT = matrix(nrow = S, ncol = 3)\n\nfor (s in 1:S) {\n  # Sample thetas\n  for (j in 1:m) {\n    vtheta = 1 / (n[j] / sigma2 + 1 / tau2)\n    etheta = vtheta * (ybar[j] * n[j] / sigma2 + mu / tau2)\n    theta[j] = rnorm(1, etheta, sqrt(vtheta))\n  }\n  \n  # Sample sigma2\n  nun = nu0 + sum(n) # TODO: Could cache this\n  ss = nu0 * s20\n  # Pool variance\n  for (j in 1:m) {\n    ss = ss + sum((Y[Y[, 1] == j, 2] - theta[j])^2)\n  }\n  sigma2 = 1 / rgamma(1, nun / 2, ss / 2)\n  \n  # Sample mu\n  vmu = 1 / (m / tau2 + 1 /g20)\n  emu = vmu * (m * mean(theta) / tau2 + mu0 / g20)\n  mu = rnorm(1, emu, sqrt(vmu))\n  \n  # Sample tau2\n  etam = eta0 + m\n  ss = eta0 * t20 + sum((theta - mu)^2)\n  tau2 = 1 / rgamma(1, etam / 2, ss / 2)\n  \n  # Store params\n  THETA[s, ] = theta\n  SMT[s, ] = c(sigma2, mu, tau2)\n}\n\n\n\n4.1.2 MCMC diagnostics\nThe book mentions here that it’s important to check convergence of the Gibbs sampler; I won’t do that here, but dividing the samples into groups of e.g. 500 samples, and ensuring that the mean values of the parameters don’t change too much from group to group is a good way to check, at least for a manageable number of parameters."
  },
  {
    "objectID": "8.html#posterior-summaries-and-shrinkage",
    "href": "8.html#posterior-summaries-and-shrinkage",
    "title": "Chapter 8: Group comparisons and hierarchical modeling",
    "section": "\n4.2 Posterior summaries and shrinkage",
    "text": "4.2 Posterior summaries and shrinkage\nNotice from the full conditional of \\(\\theta_j\\) above that the expected value of \\(\\theta_j\\) is a weighted average of \\(\\bar{y}_j\\) and \\(\\mu\\):\n\\[\\begin{align}\n\\mathbb{E}(\\theta_j \\mid \\boldsymbol{y}_j, \\mu, \\tau^2, \\sigma^2) &= \\frac{\\bar{y}_j n_j / \\sigma^2 + \\mu/\\tau^2}{n_j / \\sigma^2 + 1 / \\tau^2} \\\\\n&= \\frac{n_j / \\sigma^2}{n_j / \\sigma^2 + 1 / \\tau^2} \\bar{y}_j + \\frac{1 / \\tau^2}{n_j / \\sigma^2 + 1 / \\tau^2} \\mu\n\\end{align}\\]\nwhich is specifically weighted by the sample size \\(n_j\\). Since we assume that there is some common mean \\(\\mu\\), our estimate of \\(\\theta_j\\) gets pulled slightly towards that common parameter \\(\\mu\\) - less so for high \\(n_j\\). This demonstrates the phonemonon of shrinkage, where information is shared across groups in this hierarchical model.\nAgain, for high \\(n_j\\), however, the effect of this shrinkage is neglegible.\nShrinkage results in some interesting phenomena. For example, look at schools 82 and 46 in our dataset.\n\nShow R codemean(THETA[, 82])\n#&gt; [1] 42.48336\nmean(THETA[, 46])\n#&gt; [1] 41.31501\nybar[82]\n#&gt; [1] 38.764\nybar[46]\n#&gt; [1] 40.17619\n\n\nEven though the sample mean of school 82 is lower than school 46, the posterior expectation of \\(\\theta_{82}\\) is higher than \\(\\theta_{46}\\), because school 82 has a very small sample and thus is affected more by a pull towards \\(\\mu\\). While this may seem counterintuitive, the explanation is that there is more evidence that \\(\\theta_{46}\\) is low than there is \\(\\theta_{82}\\) is low due to the wide discrepancy in sample sizes. The assumption that \\(\\theta_j\\) stem from one \\(\\mu\\), then, takes a “conservative” approach to estimating the \\(\\theta_{82}\\) with little data."
  },
  {
    "objectID": "8.html#analysis-of-math-score-data",
    "href": "8.html#analysis-of-math-score-data",
    "title": "Chapter 8: Group comparisons and hierarchical modeling",
    "section": "\n5.1 Analysis of math score data",
    "text": "5.1 Analysis of math score data\nFor time I haven’t reproduced the analysis here are there aren’t too many conclusions drawn - the point is just that you can let the variance vary across groups."
  },
  {
    "objectID": "8.html#section",
    "href": "8.html#section",
    "title": "Chapter 8: Group comparisons and hierarchical modeling",
    "section": "\n6.1 8.1",
    "text": "6.1 8.1\n\n6.1.1 a\nI expect \\(\\text{Var}(y_{i, j} \\mid \\mu, \\tau^2)\\) to be bigger since it includes both within- and between-group sampling variability.\n\n6.1.2 b\nI think \\(\\text{Cov}(y_{i_1, j}, y_{i_2, j} \\mid \\theta_j, \\sigma^2)\\) is zero because, according to exchangeability, our \\(y_{i, j}\\) are conditionally i.i.d. when \\(\\theta_j, \\sigma^2\\) is known.\nOn the other hand, given our model, it seems like knowing about another \\(y_{i_1,\nj}\\) does provide more information about \\(y_{i_2, j}\\), and I expect them to covary positively with each other. Specifically, \\(y_{i_1, j}\\) seems to give more information about what the mean \\(\\theta_j\\) is, and we expect values from the same \\(\\theta_j\\) to be closer together (due to decreased variability). I can’t come up with a more formal mathematical justification, though.\n\n6.1.3 c\n\\[\\begin{align}\n\\text{Var}(y_{i, j} \\mid \\theta_j, \\sigma^2) &= \\sigma^2 & \\text{By def.}\\\\\n\\text{Var}(\\bar{y}_{\\cdot, j} \\mid \\theta_j, \\sigma^2) &= \\sigma^2 / n_j & \\text{Samp. dist. mean} \\\\\n\\text{Cov}(y_{i_1, j}, y_{i_2, j} \\mid \\theta_j, \\sigma^2) &= \\mathbb{E}(y_{i_1, j}y_{i_2, j}) - \\mathbb{E}(y_{i_1, j})\\mathbb{E}(y_{i_2, j}) \\\\\n&= \\mathbb{E}(y_{i_1, j})\\mathbb{E}(y_{i_2, j}) - \\mathbb{E}(y_{i_1, j})\\mathbb{E}(y_{i_2, j}) & \\text{i.i.d.} \\\\\n&= 0 \\\\\n& \\\\\n\\text{Var}(y_{i, j} \\mid \\mu, \\tau^2) &= \\text{Var}(\\mathbb{E}(y_{i, j} \\mid \\theta_j, \\sigma^2) \\mid \\mu, \\tau^2) + \\mathbb{E}(\\text{Var}(y_{i, j} \\mid \\theta_j, \\sigma^2) \\mid \\mu, \\tau^2) & \\text{Law total var.} \\\\\n&= \\text{Var}(\\theta_j \\mid \\mu, \\tau^2) + \\mathbb{E}(\\sigma^2 \\mid \\mu, \\tau^2) \\\\\n&= \\tau^2 + \\sigma^2 \\\\\n\n\\text{Var}(\\bar{y}_{\\cdot, j} \\mid \\mu, \\tau^2) &= \\text{Var}(\\mathbb{E}(\\bar{y}_{\\cdot, j} \\mid \\theta_j, \\sigma^2) \\mid \\mu, \\tau^2) + \\mathbb{E}(\\text{Var}(\\bar{y}_{\\cdot, j} \\mid \\theta_j, \\sigma^2) \\mid \\mu, \\tau^2) & \\text{Law total var.} \\\\\n&= \\text{Var}(\\theta_j \\mid \\mu, \\tau^2) + \\mathbb{E}(\\sigma^2 / n_j \\mid \\mu, \\tau^2) \\\\\n&= \\tau^2 + (\\sigma^2 / n_j) \\\\\n\n\\text{Cov}(y_{i_1, j}, y_{i_2, j} \\mid \\mu, \\tau^2) &= \\text{E}(\\text{Cov}(y_{i_1, j}, y_{i_2, j} \\mid \\theta_j, \\sigma^2) \\mid \\mu, \\tau^2) + \\text{Cov}(\\mathbb{E}(y_{i_1, j} \\mid \\theta_j, \\sigma^2), \\mathbb{E}(y_{i_2, j} \\mid \\theta_j, \\sigma^2)) & \\text{Law total covar.} \\\\\n&= \\text{E}(0 \\mid \\mu, \\tau^2) + \\text{Cov}(\\mathbb{E}(y_{i_1, j} \\mid \\theta_j, \\sigma^2), \\mathbb{E}(y_{i_2, j} \\mid \\theta_j, \\sigma^2)) & \\text{i.i.d.} \\\\\n&= \\text{Cov}(\\theta_j, \\theta_j) \\\\\n&= \\text{Var}(\\theta_j) \\\\\n&= \\tau^2\n\\end{align}\\]\nThese values indeed align with the intuitions above. The values for the variances and covariances with \\(\\theta_j\\) unknown are simply those for \\(\\theta_j\\) known plus \\(\\tau^2\\), the between-group sampling variability.\n\n6.1.4 d\nFor convenience let \\(\\mathcal{D} = \\{\\boldsymbol{y}_1, \\dots,\n\\boldsymbol{y}_m\\}\\) and \\(\\boldsymbol{\\theta} = \\{ \\theta_1, \\dots, \\theta_m \\}\\).\nAlso, if we treat the model as a Bayes’ net, we can use factorization to quickly extract the conditional independencies: \\(P(X_1, \\dots, X_n) = \\prod_{i = 1}^n P(X_i \\mid \\text{Pa}(X_i))\\) where \\(\\text{Pa}(X)\\) are the parents of \\(X\\).\n\\[\\begin{align}\np(\\mu \\mid \\mathcal{D}, \\boldsymbol{\\theta}, \\sigma^2, \\tau^2) &= \\frac{p(\\mu, \\mathcal{D}, \\boldsymbol{\\theta}, \\sigma^2, \\tau^2)}{\\int p(\\mu, \\mathcal{D}, \\boldsymbol{\\theta}, \\sigma^2, \\tau^2) \\; d\\mu} \\\\\n&= \\frac{p(\\mu) p(\\tau^2) p(\\sigma^2) p(\\mathcal{D} \\mid \\boldsymbol{\\theta}, \\sigma^2) p(\\boldsymbol{\\theta} \\mid \\mu, \\tau^2) } {\\int p(\\mu) p(\\tau^2) p(\\sigma^2) p(\\mathcal{D} \\mid \\boldsymbol{\\theta}, \\sigma^2) p(\\boldsymbol{\\theta} \\mid \\mu, \\tau^2)\\; d\\mu } & \\text{Factorization} \\\\\n&= \\frac{p(\\mu) p(\\tau^2) p(\\sigma^2) p(\\mathcal{D} \\mid \\boldsymbol{\\theta}, \\sigma^2) p(\\boldsymbol{\\theta} \\mid \\mu, \\tau^2) } { p(\\tau^2) p(\\sigma^2) p(\\mathcal{D} \\mid \\boldsymbol{\\theta}, \\sigma^2) \\int p(\\mu) p(\\boldsymbol{\\theta} \\mid \\mu, \\tau^2)\\; d\\mu } & \\text{Constants outside} \\\\\n&= \\frac{p(\\mu) p(\\boldsymbol{\\theta} \\mid \\mu, \\tau^2) } { \\int p(\\mu) p(\\boldsymbol{\\theta} \\mid \\mu, \\tau^2)\\; d\\mu } & \\\\\n&= p(\\mu \\mid \\boldsymbol{\\theta}, \\tau^2) & \\text{Bayes' rule}\n\\end{align}\\]\nThis means that \\(\\mu\\) does not depend on the data (or \\(\\sigma^2\\)) once \\(\\theta_1, \\dots, \\theta_m\\) are known; another example of conditional independence induced by the Bayes network."
  },
  {
    "objectID": "8.html#section-1",
    "href": "8.html#section-1",
    "title": "Chapter 8: Group comparisons and hierarchical modeling",
    "section": "\n6.2 8.3",
    "text": "6.2 8.3\n\n6.2.1 a\n\nShow R code# Load data\nlibrary(dplyr)\nlibrary(tidyr)\nschools.list = lapply(1:8, function(i) {\n  s.tbl = paste0('Exercises/school', i, '.dat') %&gt;%\n    read.table\n  \n  data.frame(\n    school = i,\n    hours = s.tbl[, 1] %&gt;% as.numeric\n  )\n})\n\nschools.raw = do.call(rbind, schools.list)\n\nY = schools.raw\n\n\n# Prior\nmu0 = 7\ng20 = 5\nt20 = 10\neta0 = 2\ns20 = 15\nnu0 = 2\n\n# Number of schools. Y[, 1] are school ids\nm = length(unique(Y[, 1]))\n\n# Starting values - use sample mean and variance\nn = sv = ybar = rep(NA, m)\nfor (j in 1:m) {\n  Y_j = Y[Y[, 1] == j, 2]\n  ybar[j] = mean(Y_j)\n  sv[j] = var(Y_j)\n  n[j] = length(Y_j)\n}\n\n# Let initial theta estimates be the sample means\n# Similarly, let initial values of sigma2, mu, and tau2 be \"sample mean and\n# variance\"\ntheta = ybar\nsigma2 = mean(sv)\nmu = mean(theta)\ntau2 = var(theta)\n\n# MCMC\nS = 1500\nTHETA = matrix(nrow = S, ncol = m)\n# Storing sigma, mu, theta together\nSMT = matrix(nrow = S, ncol = 3)\ncolnames(SMT) = c('sigma2', 'mu', 'tau2')\n\nfor (s in 1:S) {\n  # Sample thetas\n  for (j in 1:m) {\n    vtheta = 1 / (n[j] / sigma2 + 1 / tau2)\n    etheta = vtheta * (ybar[j] * n[j] / sigma2 + mu / tau2)\n    theta[j] = rnorm(1, etheta, sqrt(vtheta))\n  }\n  \n  # Sample sigma2\n  nun = nu0 + sum(n) # TODO: Could cache this\n  ss = nu0 * s20\n  # Pool variance\n  for (j in 1:m) {\n    ss = ss + sum((Y[Y[, 1] == j, 2] - theta[j])^2)\n  }\n  sigma2 = 1 / rgamma(1, nun / 2, ss / 2)\n  \n  # Sample mu\n  vmu = 1 / (m / tau2 + 1 /g20)\n  emu = vmu * (m * mean(theta) / tau2 + mu0 / g20)\n  mu = rnorm(1, emu, sqrt(vmu))\n  \n  # Sample tau2\n  etam = eta0 + m\n  ss = eta0 * t20 + sum((theta - mu)^2)\n  tau2 = 1 / rgamma(1, etam / 2, ss / 2)\n  \n  # Store params\n  THETA[s, ] = theta\n  SMT[s, ] = c(sigma2, mu, tau2)\n}\n\n\nAssess convergence with diagnostic boxplots:\n\n\n\n\n\n\n\n\nEvaluate effective sample size:\n\nShow R code# Tweak number of samples until all of the below are above 1000\nlibrary(coda)\neffectiveSize(SMT[, 1])\n#&gt;     var1 \n#&gt; 1509.853\neffectiveSize(SMT[, 2])\n#&gt;     var1 \n#&gt; 1238.402\neffectiveSize(SMT[, 3])\n#&gt;     var1 \n#&gt; 1036.337\n\n\n\n6.2.2 b\nPosterior means and confidence intervals\n\nShow R codet(apply(SMT, MARGIN = 2, FUN = quantile, probs = c(0.025, 0.5, 0.975)))\n#&gt;             2.5%       50%     97.5%\n#&gt; sigma2 11.736878 14.376589 17.775544\n#&gt; mu      5.945417  7.546141  9.182105\n#&gt; tau2    1.836294  4.683608 14.643933\n\n\nComparing posterior to prior:\n\nShow R code# For dinvgamma\nlibrary(MCMCpack)\nsigma2_prior = data.frame(\n  value = seq(10, 22.5, by = 0.1),\n  density = dinvgamma(seq(10, 22.5, by = 0.1), nu0 / 2, nu0 * s20 / 2),\n  variable = 'sigma2'\n)\ntau2_prior = data.frame(\n  value = seq(0, 30, by = 0.1),\n  density = dinvgamma(seq(0, 30, by = 0.1), eta0 / 2, eta0 * t20 / 2),\n  variable = 'tau2'\n)\nmu_prior = data.frame(\n  value = seq(0, 12, by = 0.1),\n  density = dnorm(seq(0, 12, by = 0.1), mu0, sqrt(g20)),\n  variable = 'mu'\n)\npriors = rbind(sigma2_prior, tau2_prior, mu_prior)\npriors$dist = 'prior'\nsmt.df$dist = 'posterior'\n\nggplot(priors, aes(x = value, y = density, color = dist)) +\n  geom_line() +\n  geom_density(data = smt.df, mapping = aes(x = value, y = ..density..)) +\n  facet_wrap(~ variable, scales = 'free')\n\n\n\n\n\n\n\nOur prior estimates for \\(\\mu\\) and \\(\\tau^2\\) were fairly estimate, but our estimate for \\(\\sigma^2\\) was very far off. After this analysis, we have estimates for \\(\\mu\\), the average amount of hours of schoolwork spent at a typical school, \\(\\tau^2\\), the variability between schools in the average hours of schoolwork, and \\(\\sigma^2\\), the variability among students’ hours in each school.\n\n6.2.3 c\n\nShow R codet20_prior = (1 / rgamma(1e6, eta0 / 2, eta0 * t20 / 2))\ns20_prior = (1 / rgamma(1e6, nu0 / 2, nu0 * s20 / 2))\n\nR_prior = data.frame(\n  value = (t20_prior) / (t20_prior + s20_prior),\n  dist = 'prior'\n)\nR_post = data.frame(\n  value = SMT[, 'tau2'] / (SMT[, 'tau2'] + SMT[, 'sigma2']),\n  dist = 'posterior'\n)\n\nggplot(R_prior, aes(x = value, y = ..density.., color = dist)) +\n  geom_density(data = R_prior) +\n  geom_density(data = R_post)\n\n\n\n\n\n\nShow R code\nmean(R_post$value)\n#&gt; [1] 0.2616334\n\n\n\\(R\\) measures how much of the total variance in our data is between-group. Our prior didn’t contain much information about this quantity, but after inference, we expect that around 25% of our variance comes from between group variance (\\(\\tau^2\\)).\n\n6.2.4 d\n\nShow R codetheta7_lt_6 = THETA[, 7] &lt; THETA[, 6]\nmean(theta7_lt_6)\n#&gt; [1] 0.5473333\n\ntheta7_smallest = (THETA[, 7] &lt; THETA[, -7]) %&gt;%\n  apply(MARGIN = 1, FUN = all)\n\nmean(theta7_smallest)\n#&gt; [1] 0.336\n\n\n\n6.2.5 e\n\nShow R coderelationship = data.frame(\n  sample_average = ybar,\n  post_exp = colMeans(THETA),\n  school = 1:length(ybar)\n)\nggplot(relationship, aes(x = sample_average, y = post_exp, label = school)) +\n  geom_text() +\n  geom_abline(slope = 1, intercept = 0) +\n  geom_hline(yintercept = mean(schools.raw[, 'hours']), lty = 2) +\n  annotate('text', x = 10, y = 7.9, label = paste0(\"Pooled sample mean \", round(mean(schools.raw[, 'hours']), 2))) +\n  geom_hline(yintercept = mean(SMT[, 'mu']), color = 'red') +\n  annotate('text', x = 10, y = 7.4, label = paste0(\"Posterior exp. mu \", round(mean(SMT[, 'mu']), 2)), color = 'red')\n\n\n\n\n\n\n\nThere is a quite tight correspondence between the sample average and the posterior expectation, although mild shrinkage can be observed with schools with very high and low sample averages being pulled towards the mean."
  },
  {
    "objectID": "7.html",
    "href": "7.html",
    "title": "Chapter 7: The multivariate normal model",
    "section": "",
    "text": "We make the step to two variables by example. Consider a sample (\\(n = 22\\)) of children who are given reading comprehension tests before and after receiving a particular instructional method. So each student has a before and after test score. We can denote these two variables for student \\(i\\) as a vector \\(\\mathbf{Y}_i\\), where \\(Y_{i, 1}\\) is the before score, and \\(Y_{i, 2}\\) is the after score:\n\\[\\begin{align}\n\\mathbf{Y}_i = \\begin{pmatrix}\nY_{i, 1} \\\\\nY_{i, 2} \\\\\n\\end{pmatrix}\n\\end{align}\\]\nRecall \\[\\begin{align}\n\\text{Cor}(X, Y) &= \\frac{\\text{Cov}(X, Y)}{\\text{SD}(X)\\text{SD}(Y)} \\\\\n&= \\frac{\\sigma_{1, 2}}{\\sigma_1 \\sigma_2} \\\\\n&= \\frac{\\sigma_{1, 2}}{\\sqrt{\\sigma_1^2 \\sigma_2^2}}\n\\end{align}\\]\n\nIf \\[\\begin{align}\n\\mathbf{y} &= \\begin{pmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_p\n\\end{pmatrix} \\sim \\mathcal{N}(\\boldsymbol{\\theta}, \\Sigma)\n\\end{align}\\]\nwhere\n\\[\\begin{align}\n\\boldsymbol{\\theta} &= \\begin{pmatrix}\n\\theta_1 \\\\\n\\theta_2 \\\\\n\\vdots \\\\\n\\theta_p\n\\end{pmatrix}\n\\end{align}\\]\nand\n\\[\\begin{align}\n\\Sigma &= \\begin{pmatrix}\n\\sigma_1^2 & \\sigma_{1, 2} & \\cdots & \\sigma_{1, p} \\\\\n\\sigma_{1, 2} & \\sigma_2^2 & \\cdots & \\sigma_{2, p} \\\\\n\\vdots & \\vdots & & \\vdots \\\\\n\\sigma_{1, p} & \\cdots & \\cdots & \\sigma_p^2\n\\end{pmatrix}\n\\end{align}\\]\nthen\n\\[\\begin{align}\np(\\mathbf{y} \\mid \\boldsymbol{\\theta}, \\Sigma) = (2\\pi)^{-p / 2} | \\Sigma |^{-1/2} \\text{exp}\\left( \\frac{1}{2} -(\\mathbf{y} - \\boldsymbol{\\theta})^T \\Sigma^{-1} (\\mathbf{y} - \\boldsymbol{\\theta}) \\right)\n\\end{align}\\]\nIt’s useful to compare this to the single variable case. The first two terms represent \\(1/\\sqrt{2\\pi\\sigma^2}\\) in the univariate case, generalized to an arbitrary dimension: there is no longer the square root of the variance for a single variable, but rather a \\(p\\)-dimensional covariance matrix raised to the \\(1/2\\) power. Furthermore, the quadratic term in the exponential \\((y -\n\\theta)^2\\) can be seen in the exponential here, but also included is the matrix multiplication with the inverse of the covariance matrix."
  },
  {
    "objectID": "7.html#example-reading-comprehension",
    "href": "7.html#example-reading-comprehension",
    "title": "Chapter 7: The multivariate normal model",
    "section": "",
    "text": "We make the step to two variables by example. Consider a sample (\\(n = 22\\)) of children who are given reading comprehension tests before and after receiving a particular instructional method. So each student has a before and after test score. We can denote these two variables for student \\(i\\) as a vector \\(\\mathbf{Y}_i\\), where \\(Y_{i, 1}\\) is the before score, and \\(Y_{i, 2}\\) is the after score:\n\\[\\begin{align}\n\\mathbf{Y}_i = \\begin{pmatrix}\nY_{i, 1} \\\\\nY_{i, 2} \\\\\n\\end{pmatrix}\n\\end{align}\\]\nRecall \\[\\begin{align}\n\\text{Cor}(X, Y) &= \\frac{\\text{Cov}(X, Y)}{\\text{SD}(X)\\text{SD}(Y)} \\\\\n&= \\frac{\\sigma_{1, 2}}{\\sigma_1 \\sigma_2} \\\\\n&= \\frac{\\sigma_{1, 2}}{\\sqrt{\\sigma_1^2 \\sigma_2^2}}\n\\end{align}\\]"
  },
  {
    "objectID": "7.html#multivariate-normal-density",
    "href": "7.html#multivariate-normal-density",
    "title": "Chapter 7: The multivariate normal model",
    "section": "",
    "text": "If \\[\\begin{align}\n\\mathbf{y} &= \\begin{pmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_p\n\\end{pmatrix} \\sim \\mathcal{N}(\\boldsymbol{\\theta}, \\Sigma)\n\\end{align}\\]\nwhere\n\\[\\begin{align}\n\\boldsymbol{\\theta} &= \\begin{pmatrix}\n\\theta_1 \\\\\n\\theta_2 \\\\\n\\vdots \\\\\n\\theta_p\n\\end{pmatrix}\n\\end{align}\\]\nand\n\\[\\begin{align}\n\\Sigma &= \\begin{pmatrix}\n\\sigma_1^2 & \\sigma_{1, 2} & \\cdots & \\sigma_{1, p} \\\\\n\\sigma_{1, 2} & \\sigma_2^2 & \\cdots & \\sigma_{2, p} \\\\\n\\vdots & \\vdots & & \\vdots \\\\\n\\sigma_{1, p} & \\cdots & \\cdots & \\sigma_p^2\n\\end{pmatrix}\n\\end{align}\\]\nthen\n\\[\\begin{align}\np(\\mathbf{y} \\mid \\boldsymbol{\\theta}, \\Sigma) = (2\\pi)^{-p / 2} | \\Sigma |^{-1/2} \\text{exp}\\left( \\frac{1}{2} -(\\mathbf{y} - \\boldsymbol{\\theta})^T \\Sigma^{-1} (\\mathbf{y} - \\boldsymbol{\\theta}) \\right)\n\\end{align}\\]\nIt’s useful to compare this to the single variable case. The first two terms represent \\(1/\\sqrt{2\\pi\\sigma^2}\\) in the univariate case, generalized to an arbitrary dimension: there is no longer the square root of the variance for a single variable, but rather a \\(p\\)-dimensional covariance matrix raised to the \\(1/2\\) power. Furthermore, the quadratic term in the exponential \\((y -\n\\theta)^2\\) can be seen in the exponential here, but also included is the matrix multiplication with the inverse of the covariance matrix."
  },
  {
    "objectID": "7.html#specifying-parameters",
    "href": "7.html#specifying-parameters",
    "title": "Chapter 7: The multivariate normal model",
    "section": "\n3.1 Specifying parameters",
    "text": "3.1 Specifying parameters\nSpecifying parameters is somewhat interesting for the inverse-Wishart becase there are many of them - we need to specify the entire covariance matrix. If we have a prior expectation of a covariance matrix \\(\\Sigma_0\\), then we can center our prior around it in two suggested ways:\n\nSet \\(\\nu_0\\) large and set \\(\\mathbf{S}_0 = (\\nu_0 - p - 1) \\Sigma_0\\), such that \\(\\mathbb{E}(\\Sigma) = \\frac{\\nu_0 - p - 1}{\\nu_0 - p - 1}\\Sigma_0 = \\Sigma_0\\) and (due to large \\(\\nu_0\\)) the prior is fairly concentrated around \\(\\Sigma_0\\);\nSet \\(\\nu_0 = p + 2\\) and let \\(\\mathbf{S}_0 = \\Sigma_0\\), such that \\(\\mathbb{E}(\\Sigma) = \\frac{1}{p + 2 - p - 1}\\Sigma_0 = \\Sigma_0\\) but only loosely centered around \\(\\Sigma_0\\) (due to fairly small \\(\\nu_0\\))\n\nFor an “empirical Bayes” approach, we can center our prior around the empirical covariance matrix of our sample."
  },
  {
    "objectID": "7.html#full-conditional-distribution-of-sigma-mid-boldsymboly_1-dots-boldsymboly_n-boldsymboltheta",
    "href": "7.html#full-conditional-distribution-of-sigma-mid-boldsymboly_1-dots-boldsymboly_n-boldsymboltheta",
    "title": "Chapter 7: The multivariate normal model",
    "section": "\n3.2 Full conditional distribution of \\(\\Sigma \\mid \\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_n, \\boldsymbol{\\theta}\\)\n",
    "text": "3.2 Full conditional distribution of \\(\\Sigma \\mid \\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_n, \\boldsymbol{\\theta}\\)\n\nThere is an intimidating normalizing constant for the inverse-Wishart. All we need to know is if \\(\\Sigma \\sim \\text{inverse-Wishart}(\\nu_0, \\mathbf{S}_0^{-1})\\),\n\\[\\begin{align}\np(\\Sigma) \\propto | \\Sigma |^{-(\\nu_0 + p + 1) / 2} \\times \\exp\\left(-\\text{tr}(\\mathbf{S}_0 \\Sigma^{-1})  / 2\\right)\n\\end{align}\\]\nRecall the sampling model from earlier. We skipped some simplifications above (substituting \\(\\mathbf{A}_1\\) and \\(\\boldsymbol{b}_1\\)) so take it for granted that a less-simplified form is\n\\[\\begin{align}\np(\\mathbf{y}_1, \\dots, \\mathbf{y}_n \\mid \\boldsymbol{\\theta}, \\Sigma) &= (2\\pi)^{-np/2} | \\Sigma |^{-n/2} \\exp \\left( - \\sum_{i = 1}^n (\\boldsymbol{y}_i - \\boldsymbol{\\theta})^T \\Sigma^{-1} (\\boldsymbol{y}_i - \\boldsymbol{\\theta}) / 2 \\right)\n\\end{align}\\]\nUsing some linear algebra,\n\\[\\begin{align}\n\\sum_{i = 1}^n (\\boldsymbol{y}_i - \\boldsymbol{\\theta})^T \\Sigma^{-1} (\\boldsymbol{y}_i - \\boldsymbol{\\theta}) &= \\text{tr}\\left( \\left(\\sum_{i = 1}^n (\\boldsymbol{y}_i - \\boldsymbol{\\theta}) (\\boldsymbol{y}_i - \\boldsymbol{\\theta})^T \\right) \\Sigma^{-1} \\right)\n\\text{tr}\\left( \\mathbf{S}_{\\theta} \\Sigma^{-1} \\right)\n\\end{align}\\]\nwhere \\(\\mathbf{S}_{\\theta} = \\sum_{i = 1}^n (\\boldsymbol{y}_i -\n\\boldsymbol{\\theta}) (\\boldsymbol{y}_i - \\boldsymbol{\\theta})^T\\) is the residual sum of squares matrix for the vectors \\(\\boldsymbol{y}_1, \\dots,\n\\boldsymbol{y}_n\\). (To obtain the residual sum of squares matrix, you calculate the sum of squares for the residual vectors \\(\\boldsymbol{y}_i -\n\\boldsymbol{\\theta}\\))\nSo\n\\[\\begin{align}\np(\\mathbf{y}_1, \\dots, \\mathbf{y}_n \\mid \\boldsymbol{\\theta}, \\Sigma) &= (2\\pi)^{-np/2} | \\Sigma |^{-n/2} \\exp \\left( - \\text{tr}(\\mathbf{S}_{\\theta} \\Sigma^{-1})  / 2 \\right)\n\\end{align}\\]\nNow we can calculate the full conditional distribution of \\(\\Sigma\\):\n\\[\\begin{align}\np(\\Sigma \\mid \\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_n, \\boldsymbol{\\theta}) &\\propto p(\\Sigma) \\times p(\\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_n \\mid \\boldsymbol{\\theta}, \\Sigma) \\\\\n&\\propto \\left[ | \\Sigma |^{-(\\nu_0 + p + 1) / 2} \\times \\exp\\left(-\\text{tr}(\\mathbf{S}_0 \\Sigma^{-1})  / 2\\right) \\right] \\times\n\\left[ | \\Sigma |^{-n/2} \\exp \\left( - \\text{tr}(\\mathbf{S}_{\\theta} \\Sigma^{-1})  / 2 \\right) \\right] \\\\\n&=  | \\Sigma |^{-(\\nu_0 + n + p + 1) / 2} \\exp \\left( -\\text{tr}(\\left( \\mathbf{S}_0 + \\mathbf{S}_{\\theta} \\right) \\Sigma^{-1}) / 2 \\right) \\\\\n&\\propto \\text{dinverse-Wishart}\\left(\\nu_0 + n, \\left[\\mathbf{S}_0 + \\mathbf{S}_{\\theta} \\right]^{-1} \\right) \\\\\n&= \\text{dinverse-Wishart}\\left(\\nu_n, \\mathbf{S}_n^{-1} \\right)\n\\end{align}\\]\nwhere \\(\\nu_n = \\nu_0 + n\\) and \\(\\mathbf{S}_n = \\mathbf{S}_0 + \\mathbf{S}_{\\theta}\\).\nLike the univariate case, the conditional distribution on \\(\\Sigma\\) is dependent on \\(\\nu_0 + n\\), a sum of the prior sample size and the data sample size, \\(\\textbf{S}_0 + \\textbf{S}_\\theta\\), the sum of the “prior” residual sum of squares and the empirical sum of squares.\nRecall that, since inverse-Wishart matrices involve sampling from a normal distribution with mean \\(\\mathbf{0}\\), indeed \\(\\mathbf{S}_0\\) can be treated as a residual covariance matrix, given that \\(\\mathbb{E}(\\boldsymbol{y}_i -\n\\boldsymbol{\\theta}) = \\mathbf{0}\\).\nFinally, notice that the conditional expectation of the covariance matrix is is a weighted average of the prior expectation \\(\\frac{1}{\\nu_0 - p -\n1}\\mathbf{S}_0\\) and the unbiased estimator \\(\\frac{1}{n} \\mathbf{S}_{\\theta}\\):\n\\[\\begin{align}\n\\mathbb{E}(\\Sigma \\mid \\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_n, \\boldsymbol{\\theta}) &= \\frac{1}{\\nu_0 + n - p - 1} (\\mathbf{S}_0 + \\mathbf{S}_{\\theta}) \\\\\n&= \\frac{\\nu_0 - p - 1}{\\nu_0 + n - p - 1} \\frac{1}{\\nu_0 - p - 1} \\mathbf{S}_0 + \\frac{n}{\\nu_0 + n - p - 1}\\frac{1}{n} \\mathbf{S}_{\\theta}.\n\\end{align}\\]\nSo the Bayesian estimator is a biased estimator, but is still demonstrably consistent as \\(n \\to \\infty\\). As mentioned in Chapter 5, we hope that the estimator is biased more towards the true mean, as long as the prior is mildly informative."
  },
  {
    "objectID": "7.html#semiconjugate-prior",
    "href": "7.html#semiconjugate-prior",
    "title": "Chapter 7: The multivariate normal model",
    "section": "\n4.1 (Semiconjugate) prior",
    "text": "4.1 (Semiconjugate) prior\n\n\n\\(\\mathbf{S}_0\\) for the inverse-Wishart\n\n\nrelated to the prior estimate of the covariance between the variables\nOnly related to because as mentioned above, there are some guidelines for what to use for \\(\\nu_0\\) and \\(\\mathbf{S}_0\\) such that the prior distribution is centered around \\(\\Sigma_0\\), the true prior estimate of the covariance matrix you are looking for.\n\n\n\n\\(\\nu_0\\) for the inverse-Wishart\n\na “prior sample size” from which the initial estimate of the variance is observed\n\n\n\n\\(\\boldsymbol{mu}_0\\) for the multivariate normal\n\nan initial estimate for the population mean\n\n\n\n\\(\\Lambda_0\\) for the multivariate normal\n\nthe covariance (i.e. uncertainty) of the initial estimate for the population mean\n\n\n\nSomewhat similar to the univariate case, the estimate of the covariance matrix for the inverse-Wishart prior is decoupled from the estimate of the covariance of the mean vector in the multivariate normal prior, although it’s common to set these the same (but again, see rules for determining \\(\\nu_0\\)).\nNote that this is somewhat different than the univariate case; since there were no covariances to worry about, what was decoupled was “prior sample sizes” from which the prior variance and prior mean are observed. Like here, it was also common to set these the same."
  },
  {
    "objectID": "7.html#posterior",
    "href": "7.html#posterior",
    "title": "Chapter 7: The multivariate normal model",
    "section": "\n4.2 Posterior",
    "text": "4.2 Posterior\nThe updated parameters are\n\n\n\\(\\mathbf{S}_n = \\mathbf{S}_0 + \\mathbf{S}_{\\theta}\\), where \\(\\mathbf{S}_{\\theta}\\) is the residual sum of squares matrix\n\\(\\nu_n = \\nu_0 + n\\)\n\\(\\mu_n = (\\Lambda_0^{-1} + n\\Sigma^{-1})^{-1} (\\Lambda_0 \\boldsymbol{\\mu}_0 + n\\Sigma^{-1}\\bar{\\boldsymbol{y}}) = \\Lambda_n (\\Lambda_0^{-1}\\boldsymbol{\\mu}_0 + n\\Sigma^{-1}\\bar{\\boldsymbol{y}})\\)\n\\(\\Lambda_n = (\\Lambda_0^{-1} + n\\Sigma^{-1})^{-1}\\)"
  },
  {
    "objectID": "7.html#example-reading-comprehension-1",
    "href": "7.html#example-reading-comprehension-1",
    "title": "Chapter 7: The multivariate normal model",
    "section": "\n5.1 Example: reading comprehension",
    "text": "5.1 Example: reading comprehension\nWe return to the example of two reading comprehension exams, given pre- and post-training.\n\n5.1.1 Specifying prior\nMean\nAssume the tests are designed such that people generally score 50 out of 100. Thus, our prior mean is \\(\\boldsymbol{\\mu}_0 = (50, 50)^T\\). Note that this implicitly assumes there is no effect of the training - the prior expectation of the post-training score is the same as the pre-training score.\nNext, we need to specify the covariance of the prior expectation of the mean. Specifically, since the scores are bounded between 0 and 100, we should put little probability outside the \\([0, 100]\\) range (so a bell curve centered on 50 with 2 standard deviations \\(\\in [0, 100]\\)). Then 1 standard deviation is 25 and the variance is thus 625.\nSince the scores are both testing reading ability the scores are probably correlated. So if we want a prior correlation between \\(\\theta_1\\) and \\(\\theta_2\\) of 0.5, we need to solve the correlation equation\n\\[\\begin{align}\n& 0.5 = \\frac{\\sigma_{1, 2}}{\\sqrt{\\sigma_1^2 \\sigma_2^2}} \\\\\n\\implies& \\sigma_{1, 2} = 0.5 \\sqrt{625^2} = 312.5 \\\\\n\\end{align}\\]\nTherefore,\n\\[\n\\Lambda_0 = \\begin{bmatrix} 625 & 312.5 \\\\ 312.5 & 625 \\end{bmatrix}\n\\]\nVariance\nWe will use the guideline mentioned earlier for loosely centering our covariance matrix prior on \\(\\Lambda_0\\). We’ll set \\(\\mathbf{S}_0^{-1} = \\Lambda_0\\) and \\(\\nu_0 = p + 2 = 4\\).\n\n5.1.2 Code\n\nShow R code# Prior specification\nMu_0 = c(50, 50)  # If coerced, will be treated as column\nLambda_0 = rbind(c(625, 312.5), c(312.5, 625))\n\nnu_0 = 4\nS_0 = matrix(rep(Lambda_0), nrow = 2)\n\n\n\nShow R code# Note that this defines rmvnorm and rwish, but I am goint to use default\n# implementations or packages to see what I would be using in the real world.\n# Specifically we need MASS::mvrnorm (Modern Applied Statistics with S), and\n# wishart comes default in newer R distributions with rWishart\nsource(\"Inline/chapter7.R\")\n# Try plotting\nY = Y.reading\nggplot(data.frame(Y.reading)) +\n  geom_point(aes(x = pretest, y = posttest))\n\n\n\n\n\n\n\n\nShow R code# Gibbs sampling\nlibrary(MASS)\nn = nrow(Y) # Number of observations\nSigma_0 = cov(Y) # Calculate covariance matrix; initial Sigma sample\n# NOTE: This initial Sigma sample doesn't end up in the gibbs sample - we throw\n# it away and start from scratch where sample 1 is the Theta based on Sigma_0, and\n# the Sigma based on that new Theta\nSigma = Sigma_0\nybar = colMeans(Y) # Faster way of calculating column means\n\n# TODO: Preallocate space for these instead of setting as NULL\nTHETA = NULL\nSIGMA = NULL\n\n# Also, inv = solve to make it more readable\ninv = solve\n\nset.seed(1)\nfor (s in 1:5000) {\n  # Update theta\n  # 1a. Compute params: Mu_n and Lambda_n from y_1, \\dots, y_n and \\Sigma^{(s)}\n  # &gt; Compute Lambda_n according to equation 7.4\n  # Note: could cache inverse of priors\n  Lambda_n = inv(inv(Lambda_0) + n * inv(Sigma))\n  # &gt; Compute Mu_n according to 7.5. Use Matrix mult\n  # Note that he first term in 7.5 is Lambda_n\n  Mu_n = Lambda_n %*% (inv(Lambda_0) %*% Mu_0 + n * inv(Sigma) %*% ybar)\n  \n  # 1b. Sample \\theta^{(s + 1)} \\sim multivariate normal mu_n, lambda_n\n  # Now we know Lambda_n, Mu_n as implied by the known Sigma and data (p. 108).\n  # Sample theta from multivariate normal (7.6, implied by 7.3)\n  Theta = mvrnorm(n = 1, Mu_n, Lambda_n)\n  \n  # Known Theta. Now sample a new Sigma. NOTE: Old sigma gets thrown away!\n  # 2a) Compute params for Sigma: Compute S_n from data and \\theta^{(s + 1)}\n  # i.e. Given the data and this Theta, we need to calculate the parameters that\n  # define the full conditional distribution of \\Sigma^{(s + 1)}\n  # S_n according to p.112 first paragraph - not defined, but could be in 7.9\n  # S_\\theta is the residual sum of squares, defined in unlabeled equation after\n  # 7.8\n  # Use vectorized to avoid summation\n  # Calculate residuals, then do sum of squares\n  # Q: why t(Y)? just how elementwise works I guess\n  resid = t(Y) - c(Theta)\n  S_theta = resid %*% t(resid)\n  S_n = S_0 + S_theta\n  # 2b) Knowing the parameters for the full conditional distribution on Sigma\n  # (inverse wishart with nu_0 and S_n known), sample\n  # df = number of samples (degrees of freedom)\n  # Don't forget to invert it afterwards (inverse wishart)\n  # Weird thing is rWishart returns a weird list of arrays\n  Sigma = inv(rWishart(1, nu_0 + n, inv(S_n))[, , 1])\n  \n  THETA = rbind(THETA, Theta)\n  # Flatten sigma??\n  SIGMA = rbind(SIGMA, c(Sigma))\n}\n\n\nHere are some associated calculations with this sample\n\nShow R code# Confidence interval for difference between post and pre test\nquantile(THETA[, 2] - THETA[, 1], prob = c(0.025, 0.5, 0.975))\n#&gt;      2.5%       50%     97.5% \n#&gt;  1.454197  6.614914 11.663732\n\n# Likelihood that the mean for the second test is greater than the mean for the\n# 1st test\nmean(THETA[, 2] &gt; THETA[, 1])\n#&gt; [1] 0.9924\n\n# Confidence interval for the correlation\nCORR = apply(SIGMA, MARGIN = 1, FUN = function(row) {\n  # indices 1 and 4 are correlation of dims 1 and 2\n  # indices 2 is equal to index 3 is equal to covariance\n  row[2] / sqrt(row[1] * row[4])\n})\n# Obviously there is a correlation\nquantile(CORR, prob = c(0.025, 0.5, 0.975))\n#&gt;      2.5%       50%     97.5% \n#&gt; 0.4180072 0.6871101 0.8476477\n\n\nWe can also work with the posterior predictive distribution by sampling new pairs \\((y_1, y_2)^{T(s)}\\) from our samples of \\(\\boldsymbol{\\theta}^{(s)}\\) and \\(\\Sigma^{(s)}\\):\n\nShow R codeY = matrix(0, nrow = 5000, ncol = 2)\nfor (s in 1:5000) {\n  Y[s, ] = mvrnorm(1, THETA[s, ], matrix(SIGMA[s, ], nrow = 2))\n}\n\n# Probability that the post-test score of a randomly selected person is greater\n# than the pre-test score\nmean(Y[, 2] &gt; Y[, 1])\n#&gt; [1] 0.7032\n\n\nImportantly, the probability of an individual having a higher post-test score than pre-test is much lower than the near-1 probability of the difference in mean test scores. It’s important to have clarified the difference between population means and individuals when drawing conclusions about your data."
  },
  {
    "objectID": "7.html#gibbs-sampling-with-missing-data",
    "href": "7.html#gibbs-sampling-with-missing-data",
    "title": "Chapter 7: The multivariate normal model",
    "section": "\n6.1 Gibbs sampling with missing data",
    "text": "6.1 Gibbs sampling with missing data\nNormally we use Gibbs sampling to estimate the posterior \\(p(\\boldsymbol{\\theta},\n\\Sigma \\mid \\mathbf{Y})\\) Here, however, we don’t have a full dataset \\(\\mathbf{Y}\\); rather, we have an observed dataset \\(\\mathbf{Y}_{\\text{obs}}\\) and missing values \\(\\mathbf{Y}_{\\text{miss}}\\). The key idea is to also estimate the posterior distribution on \\(\\mathbf{Y}_{\\text{miss}}\\), which will also help us make more accurate estimates on \\(\\boldsymbol{\\theta}\\) and \\(\\Sigma\\). Using Gibbs sampling, when we have sample values \\(\\boldsymbol{\\theta}^{(s)}\\) and \\(\\Sigma^{(s)}\\), we can sample from\n\\[\n\\mathbf{Y}_{\\text{miss}}^{(s)} \\sim p(\\mathbf{Y}_{\\text{miss}} \\mid \\mathbf{Y}_{\\text{obs}}, \\boldsymbol{\\theta}^{(s)}, \\Sigma^{(s)})\n\\]\nSpecifically, to sample from the above, we simply sample the missing values of each data point independently. For a data point \\(\\boldsymbol{y}\\) with missing values, let \\(a\\) be the indices of the observed values and \\(b\\) be the indices of the missing values. Then it is shown that sampling \\(\\boldsymbol{y}_{[b]}\\) given known observed variables and the parameters \\(\\boldsymbol{\\theta}\\) and \\(\\Sigma\\) also follows a multivariate normal distribution, but with mean and covariance matrices with dimension \\(| b |\\) that take into account the existing variables:\n\\[\\begin{align}\n\\boldsymbol{y}_{[b]} \\mid \\boldsymbol{y}_{[a]}, \\boldsymbol{\\theta}, \\Sigma \\sim \\mathcal{N}(\\boldsymbol{\\theta}_{b \\mid a}, \\Sigma_{b \\mid a})\n\\end{align}\\]\nwhere\n\n\n\\(\\boldsymbol{\\theta}_{b \\mid a} = \\boldsymbol{\\theta}_b + \\Sigma_{[b, a]}(\\Sigma_{[a, a]})^{-1} (\\boldsymbol{y}_{[a]} - \\boldsymbol{\\theta}_{[a]})\\);\n\nIntuitively, the mean of the multivariate normal distribution on the missing values given some observed values starts with the unconditional mean of the observed values, plus or minus some offset that depends on the observed values and the correlations between the observed and missing values. For example, if it is known that a datapoint’s observed values are quite high relative to the mean \\((\\boldsymbol{y}_a - \\boldsymbol{\\theta}_a)\\), and that there is a positive correlation between observed values and missing values, we would expect the missing values to generally be higher as well.\n\n\n\n\\(\\Sigma_{b \\mid a} = \\Sigma_{[b, b]} - \\Sigma_{[b, a]} (\\Sigma_{[a, a]})^{-1} \\Sigma_{[a, b]}\\)\n\nIntuitively, the covariance matrix of the conditional distribution on the missing values starts with the unconditional covariance, but notice the minus sign; since the covariance matrix is positive definite, knowing about some observed variables will decrease our uncertainty about the missing values.\n\n\n\nOnce we’ve sampled a set of missing values, notice that we now have a full “dataset” if we combine our observed values with the newly sampled missing values. This means that we can sample from the full conditional distributions of \\(\\boldsymbol{\\theta}\\) and \\(\\Sigma\\) normally, and from there, once again sample a new set of \\(\\mathbf{Y}_{\\text{miss}}\\).\nTo summarize Gibbs sampling with missing data: assume starting values \\(\\Sigma^{(0)}\\) and \\(\\mathbf{Y}_{\\text{miss}}^{(0)}\\) - perhaps the empirical covariance matrix and the unconditional means of the observed sample. Then the algorithm has just one more step:\n\nSample \\(\\boldsymbol{\\theta}^{(s + 1)}\\) from \\(p(\\boldsymbol{\\theta} \\mid \\mathbf{Y}_{\\text{obs}}, \\mathbf{Y}_{\\text{miss}}^{(s)}, \\Sigma^{(s)})\\)\n\nSample \\(\\Sigma^{(s + 1)}\\) from \\(p(\\Sigma \\mid \\mathbf{Y}_{\\text{obs}}, \\mathbf{Y}_{\\text{miss}}^{(s)}, \\boldsymbol{\\theta}^{(s)})\\)\n\nSample \\(\\mathbf{Y}_{\\text{miss}}^{(s + 1)}\\) from \\(p(\\mathbf{Y}_{\\text{miss}} \\mid \\mathbf{Y}_{\\text{obs}}, \\boldsymbol{\\theta}^{(s)}, \\Sigma^{(s)})\\)\n\n\nFor steps 1 and 2, you simply combine the sampled missing data and the observed data for a full dataset \\(\\mathbf{Y}\\) and sample from the full conditional distributions like normal."
  },
  {
    "objectID": "7.html#example",
    "href": "7.html#example",
    "title": "Chapter 7: The multivariate normal model",
    "section": "\n6.2 Example",
    "text": "6.2 Example\nLet’s take a look at an example using a dataset with four health-related measurements on 200 women near Phoenix, Arizona. Notice that this dataset has missing values. We’ll assume that the data is missing at random, which is necessary for this analysis.\n\nShow R codeY = Y.pima.miss\nhead(Y) # Notice missing data\n\n\n  \n\n\nShow R codelibrary(GGally)\nsuppressWarnings(ggpairs(Y))\n\n\n\n\n\n\n\nGibbs sampling according to the 3-step scheme described above is implemented below. For priors, we set \\(\\boldsymbol{\\mu}_0 = (120, 64, 26, 26)\\) assuming we know these are the national averages of the health measurements. We then (waving our hands a little) select prior variances that keep these measurements mostly around zero and only lightly centered around our estimates.\n\nShow R code# Gibbs sampling\nn = nrow(Y)\np = ncol(Y)\nmu0 = c(120, 64, 26, 26)\nsd0 = mu0 / 2\n# Setting prior on covariance\nL0 = matrix(.1, p, p)\ndiag(L0) = 1\nL0 = L0 * outer(sd0, sd0)\nprint(L0)\n#&gt;      [,1]   [,2]  [,3]  [,4]\n#&gt; [1,] 3600  192.0  78.0  78.0\n#&gt; [2,]  192 1024.0  41.6  41.6\n#&gt; [3,]   78   41.6 169.0  16.9\n#&gt; [4,]   78   41.6  16.9 169.0\n\n# Variance prior lightly concentrated, where nu0 &gt; p is nu0 = p + 2\nnu0 = p + 2\n# Scale matrix - set to be the same as L0\nS0 = L0\n\n# Set starting values\nSigma = S0\nY.full = Y\nO = 1 * (!is.na(Y))  # Get NOT NAs, coerce to int via * 1\nfor (j in 1:p) { # Looping through columns\n  # For missing values in column, set to mean of the observed values\n  mean.wo.na = mean(Y.full[, j], na.rm = TRUE)\n  # Rows: all of those that are NA, and the jth column, set it to this mean\n  Y.full[is.na(Y.full[, j]), j] = mean.wo.na\n}\n\n# Gibbs\nTHETA = SIGMA = Y.MISS = NULL\nset.seed(1)\nfor (s in 1:1000) {\n  # Update theta: step 1 of p.117 which is the same as previous\n  ybar = colMeans(Y.full)\n  Ln = inv(inv(L0) + n * inv(Sigma))\n  mun = Ln %*% (inv(L0) %*% mu0 + n * inv(Sigma) %*% ybar)\n  theta = mvrnorm(1, mun, Ln)\n  \n  # Update sigma: step 2 of p.117, same as previous\n  resid = t(Y.full) - c(theta)\n  Stheta = resid %*% t(resid)\n  Sn = S0 + Stheta\n  Sigma = inv(rWishart(1, nu0 + n, inv(Sn))[, , 1])\n  \n  # Update ymiss: step 3 of p.117, requires eqs 7.10, 7.11\n  # Loop through rows of data (takes longer!!), need to sample rows individually\n  # (independent) top of p.118\n  for (i in 1:n) {\n    # Skip if we already have it\n    if (all(O[i, ] == 1)) {\n      next\n    }\n    # Partition b = NA rows, a = present rows\n    # Still works of a, b are empty, I presume\n    oi = O[i, ]\n    a = oi == 1\n    b = oi == 0\n    \n    # Now we want to sample yb | ya, Sigma, Theta\n    \n    # \\Sigma_{[a, a]}^{-1}, used in eqs 7.10 AND 7.11 (so calc once)\n    iSa = inv(Sigma[a, a])\n    # Calcualte \\Sigma_{[b, a]}(\\Sigma_{[a, a]})^{-1} used in 7.10 AND 7.11\n    beta.j = Sigma[b, a] %*% iSa\n    # Calculate Sigma.j (7.11). Start with covariacne matrix for the missing\n    # vars, then influence by beta (decrease variance)\n    Sigma.j = Sigma[b, b] - beta.j %*% Sigma[a, b]\n    # Calculate theta.j (7.10). Start with standard theta, then change based on\n    # residuals of other vals and what we wknow about covariances\n    yi = Y.full[i, ]\n    theta.j = theta[b] + beta.j %*% t(yi[a] - theta[a])\n    \n    # Now we have samples for subset of b. Preserver order, now sample\n    Y.full[i, b] = mvrnorm(1, theta.j, Sigma.j)\n  }\n  \n  # Concat\n  THETA = rbind(THETA, theta)\n  SIGMA = rbind(SIGMA, c(Sigma))\n  Y.MISS = rbind(Y.MISS, Y.full[O == 0])\n}\n\n# Means and confidence intervals for posterior means\ncolnames(Y)\n#&gt; [1] \"glu\"  \"bp\"   \"skin\" \"bmi\"\ncolMeans(THETA)\n#&gt; [1] 123.51682  71.04978  29.38495  32.18491\napply(THETA, MARGIN = 2, FUN = function(d) quantile(d, prob = c(0.025, 0.5, 0.975)))\n#&gt;           [,1]     [,2]     [,3]     [,4]\n#&gt; 2.5%  118.7039 69.41573 27.62746 31.33561\n#&gt; 50%   123.5534 71.05000 29.39057 32.18047\n#&gt; 97.5% 127.8140 72.63692 31.05039 33.04161\n\n# Sample correlation matrices\nCOR = array(dim = c(p, p, 1000))\nfor (s in 1:nrow(SIGMA)) {\n  # It's in rows right now, refold into matrix\n  Sig = matrix(SIGMA[s, ], nrow = p, ncol = p)\n  # Calculate correlation matrix: (TODO: figure out how this works)\n  COR[, , s] = Sig / sqrt(diag(Sig) %o% diag(Sig))\n}\n\n# Mean correlations from the correlation matrix samples. Can also calculate\n# confidence intervals with quantile\napply(COR, MARGIN = c(1, 2), FUN = mean)\n#&gt;           [,1]      [,2]      [,3]      [,4]\n#&gt; [1,] 1.0000000 0.2236531 0.2475843 0.1888097\n#&gt; [2,] 0.2236531 1.0000000 0.2478914 0.2349531\n#&gt; [3,] 0.2475843 0.2478914 1.0000000 0.6510103\n#&gt; [4,] 0.1888097 0.2349531 0.6510103 1.0000000"
  },
  {
    "objectID": "7.html#section",
    "href": "7.html#section",
    "title": "Chapter 7: The multivariate normal model",
    "section": "\n7.1 7.1",
    "text": "7.1 7.1\n\n7.1.1 a\nSince the density is uniform with respect to \\(\\boldsymbol{\\theta}\\), the integral over the support of this function is infinite and cannot be 1.\n\n7.1.2 b\n\\[\\begin{align}\np_J(\\boldsymbol{\\theta}, \\Sigma \\mid \\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_n) &\\propto p(\\boldsymbol{\\theta}, \\Sigma) \\times p(\\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_n \\mid \\boldsymbol{\\theta}, \\Sigma) \\\\\n&\\propto \\left[ | \\Sigma |^{-(p + 2) / 2} \\right] \\times \\left[ | \\Sigma |^{-n / 2} \\exp\\left( -\\text{tr}(\\mathbf{S}_\\theta \\Sigma^{-1}) \\right) \\right] \\\\\n&\\propto | \\Sigma |^{-(p + n + 2) / 2} \\exp \\left( -\\text{tr}(\\mathbf{S}_\\theta \\Sigma^{-1}) / 2 \\right)\n\\end{align}\\]\nTo obtain the full conditionals of a parameter, we treat the other parameters as constant, so\n\\[\\begin{align}\np_J(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_n, \\Sigma) &\\propto \\exp(- \\text{tr}(\\mathbf{S}_\\theta \\Sigma^{-1}) / 2) \\\\\n&= \\exp(-\\sum_{i = 1}^n (\\boldsymbol{y}_i - \\theta)^T \\Sigma^{-1} (\\boldsymbol{y}_i - \\theta) / 2 ) & \\text{Expand back} \\\\\n&= \\exp(- n (\\bar{\\boldsymbol{y}} - \\theta)^T \\Sigma^{-1} (\\bar{\\boldsymbol{y}} - \\theta) / 2 ) \\\\\n&= \\text{dnormal}(\\bar{\\boldsymbol{y}}, \\Sigma / n)\n\\end{align}\\]\nand\n\\[\\begin{align}\np_J(\\Sigma \\mid \\boldsymbol{y}_1, \\dots, \\boldsymbol{y}_n, \\boldsymbol{\\theta}) &\\propto | \\Sigma | ^{-(p + n + 2) / 2 } \\exp(- \\text{tr}(\\mathbf{S}_\\theta \\Sigma^{-1}) / 2) \\\\\n&\\propto \\text{dinverse-wishart}\\left(n + 1, \\mathbf{S}_\\theta^{-1} \\right)\n\\end{align}\\]"
  },
  {
    "objectID": "7.html#section-1",
    "href": "7.html#section-1",
    "title": "Chapter 7: The multivariate normal model",
    "section": "\n7.2 7.3",
    "text": "7.2 7.3\n\nShow R codebluecrab = as.matrix(read.table('Exercises/bluecrab.dat'))\norangecrab = as.matrix(read.table('Exercises/orangecrab.dat'))\n\n\n\n7.2.1 a\n\nShow R codecrab.mcmc = lapply(list('bluecrab' = bluecrab, 'orangecrab' = orangecrab), function(crab) {\n  p = ncol(crab)\n  n = nrow(crab)\n  ybar = colMeans(crab)\n  \n  # Prior parameters\n  \n  mu0 = ybar\n  lambda0 = s0 = cov(crab)\n  nu0 = 4\n  \n  S = 10000\n  THETA = matrix(nrow = S, ncol = p)\n  SIGMA = array(dim = c(p, p, S))\n  \n  # Start with sigma sample\n  sigma = s0\n  \n  # Gibbs sampling\n  library(MASS)\n  \n  # Also, inv = solve to make it more readable\n  inv = solve\n  \n  for (s in 1:S) {\n    # Update theta\n    lambdan = inv(inv(lambda0) + n * inv(sigma))\n    mun = lambdan %*% (inv(lambda0) %*% mu0 + n * inv(sigma) %*% ybar)\n    theta = mvrnorm(n = 1, mun, lambdan)\n    \n    # Update sigma\n    resid = t(crab) - c(theta)\n    stheta = resid %*% t(resid)\n    sn = s0 + stheta\n    sigma = inv(rWishart(1, nu0 + n, inv(sn))[, , 1])\n    \n    THETA[s, ] = theta\n    SIGMA[, , s] = sigma\n  }\n  \n  list(theta = THETA, sigma = SIGMA)\n})\n\n\n\n7.2.2 b\n\n\n\n\n\n\n\n\nThere is strong evidence that orange crabs tend to be larger in both measurements than blue crabs:\n\nShow R codemean(orangecrab.df$theta1 &gt; bluecrab.df$theta1)\n#&gt; [1] 0.9013\nmean(orangecrab.df$theta2 &gt; bluecrab.df$theta2)\n#&gt; [1] 0.9979\n\n\n\n7.2.3 c\n\nShow R codebluecrab.cor = apply(crab.mcmc$bluecrab$sigma, MARGIN = 3, FUN = function(covmat) {\n  covmat[1, 2] / (sqrt(covmat[1, 1] * covmat[2, 2]))\n})\norangecrab.cor = apply(crab.mcmc$orangecrab$sigma, MARGIN = 3, FUN = function(covmat) {\n  covmat[1, 2] / (sqrt(covmat[1, 1] * covmat[2, 2]))\n})\ncor.df = data.frame(species = c(rep('blue', length(bluecrab.cor)), rep('orange', length(orangecrab.cor))),\n                    cor = c(bluecrab.cor, orangecrab.cor))\nggplot(cor.df, aes(x = cor, fill = species)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c('blue', 'orange'))\n\n\n\n\n\n\nShow R code\nmean(bluecrab.cor &lt; orangecrab.cor)\n#&gt; [1] 0.9899\n\n\nThe orange crab species appears to have a much higher correlation between its two measurements than the blue crab species."
  },
  {
    "objectID": "7.html#section-2",
    "href": "7.html#section-2",
    "title": "Chapter 7: The multivariate normal model",
    "section": "\n7.3 7.4",
    "text": "7.3 7.4\n\nShow R codeagehw = as.matrix(read.table('Exercises/agehw.dat'))\ncolnames(agehw) = agehw[1, ]\nagehw = agehw[-1, ]\nagehw = matrix(as.numeric(agehw), nrow = 100)\n\n\n\n7.3.1 a\nWith typical intuitions about life expectancy and age of marriage, I suspect that the ages of most of the married couples will fall between 25 and 80. There may be slight age differences among men and women, but nothing that I’m confident enough to to encode in my prior. Thus I will set \\(\\boldsymbol{\\mu}_0 = ((25 + 80) / 2, (25 + 80) / 2) = (52.5, 52.5)^T\\)\nI have no choice but to pick a semiconjugate prior distribution in this case, but it does seem intuitive that there are less married couples at ages 25 and 80 than there are married couples around age 50, thus justifying a bell curve centered around \\(52.5\\) with variance \\(13.75^2 \\approx 189\\) such that approximately 95% of my prior falls within the range \\((25, 80)\\).\nI also have reason to believe the ages of the couples are quite tightly correlated, so knowing the above variance, I will aim for a prior correlation of \\(0.75\\) Solving the correlation equation gives\n\\[\\begin{align}\n& 0.75 = \\frac{\\sigma_{1, 2}}{189} \\\\\n\\implies& \\sigma_{1, 2} = 141.75\n\\end{align}\\]\nSo I will set \\[\\Lambda_0 = \\begin{bmatrix} 189 & 141.75 \\\\ 141.75 & 189 \\end{bmatrix} \\]\nLike previous problems, for the variance, I will set \\(\\mathbf{S}_0^{-1} =\n\\Lambda_0\\) and \\(\\nu_0 = p + 2 = 4\\). Note that this only loosely centers our covariance matrix prior on \\(\\Lambda_0\\), so I am being a bit conservative in terms of my belief in the variance and the correlation between the ages.\n\nShow R codeY = agehw\np = ncol(agehw)\nn = nrow(agehw)\nybar = colMeans(agehw)\n\nmu0 = rep(52.5, p)\nlambda0 = s0 = rbind(c(189, 141.75), c(141.75, 189))\n# nu0 = p + 2\nnu0 = p + 2 + 10\n\n\n\n7.3.2 b\nThe wording of the question is interesting - I assume I’m supposed to sample a fixed \\(\\boldsymbol{\\theta}, \\Sigma\\) and from there sample \\(100\\) points all with the same parameters. If I were to do this myself, I feel like I would sample a new data point for each sample of \\(\\boldsymbol{\\theta}, \\Sigma\\)…\nIn fact, because of that wording, I originally set \\(\\nu_0 = p + 2 = 4\\) to loosely center my prior. But given that this variance will often produce uncorrelated prior predictive datasets, I’m increasing \\(\\nu_0\\) a bit…\nAfter increasing \\(\\nu_0\\), I’m fairly comfortable with what these posterior predictive datasets look like.\n\nShow R codeN = 100\nS = 12\n\nY_preds = lapply(1:S, function(s) {\n  # Sample THETA according to prior\n  theta = mvrnorm(n = 1, mu0, lambda0)\n  sigma = inv(rWishart(1, nu0, inv(s0))[, , 1])\n  Y_s = mvrnorm(n = 100, theta, sigma)\n  data.frame(Y1 = Y_s[, 1], Y2 = Y_s[, 2], dataset = s)\n})\n\nY_comb = do.call(rbind, Y_preds)\n\nggplot(Y_comb, aes(x = Y1, y = Y2)) +\n  geom_point() +\n  facet_wrap(~ dataset)\n\n\n\n\n\n\n\n\n7.3.3 c\n\nShow R codeS = 10000\n\n# Reuse this since we'll need to specify different priors\ndo_mcmc = function(Y, mu0, lambda0, s0, nu0) {\n  ybar = colMeans(Y)\n  p = ncol(Y)\n  n = nrow(Y)\n\n  THETA = matrix(nrow = S, ncol = p)\n  SIGMA = array(dim = c(p, p, S))\n  \n  # Start with sigma sample\n  sigma = cov(Y)\n  \n  # Gibbs sampling\n  \n  # Also, inv = solve to make it more readable\n  inv = solve\n  \n  for (s in 1:S) {\n    # Update theta\n    lambdan = inv(inv(lambda0) + n * inv(sigma))\n    mun = lambdan %*% (inv(lambda0) %*% mu0 + n * inv(sigma) %*% ybar)\n    theta = mvrnorm(n = 1, mun, lambdan)\n    \n    # Update sigma\n    resid = t(Y) - c(theta)\n    stheta = resid %*% t(resid)\n    sn = s0 + stheta\n    sigma = inv(rWishart(1, nu0 + n, inv(sn))[, , 1])\n    \n    THETA[s, ] = theta\n    SIGMA[, , s] = sigma\n  }\n  \n  list(theta = THETA, sigma = SIGMA)\n}\n\nmy_prior_mcmc = do_mcmc(agehw, mu0, lambda0, s0, nu0)\nTHETA = my_prior_mcmc$theta\nSIGMA = my_prior_mcmc$sigma\n\n# For reuse later\nprint_quantiles = function(THETA, SIGMA) {\n  print(\"Husband\")\n  print(quantile(THETA[, 1], probs = c(0.025, 0.5, 0.975))) # Husband\n  print(\"Wife\")\n  print(quantile(THETA[, 2], probs = c(0.025, 0.5, 0.975))) # Wife\n  cors = apply(SIGMA, MARGIN = 3, FUN = function(covmat) {\n    covmat[1, 2] / (sqrt(covmat[1, 1] * covmat[2, 2]))\n  })\n  print(\"Correlation\")\n  print(quantile(cors, probs = c(0.025, 0.5, 0.975)))\n}\n\nprint_quantiles(THETA, SIGMA)\n#&gt; [1] \"Husband\"\n#&gt;     2.5%      50%    97.5% \n#&gt; 42.01685 44.52494 47.03880 \n#&gt; [1] \"Wife\"\n#&gt;     2.5%      50%    97.5% \n#&gt; 38.60299 40.99994 43.42255 \n#&gt; [1] \"Correlation\"\n#&gt;      2.5%       50%     97.5% \n#&gt; 0.8615416 0.9028502 0.9321153\n\n\n\n7.3.4 d\nI haven’t done 7.2, but doing Jeffreys’ prior and a “diffuse prior” below will still be helpful to see what effect prior information has.\ni\n\nShow R codeTHETA = matrix(nrow = S, ncol = p)\nSIGMA = array(dim = c(p, p, S))\n\n# Start with sigma sample\nsigma = cov(Y)\n\n# Gibbs sampling\n\n# Also, inv = solve to make it more readable\ninv = solve\n\nfor (s in 1:S) {\n  # Update theta\n  theta = mvrnorm(n = 1, ybar, sigma / n)\n  \n  # Update sigma\n  resid = t(Y) - c(theta)\n  stheta = resid %*% t(resid)\n  sigma = inv(rWishart(1, n + 1, inv(stheta))[, , 1])\n  \n  THETA[s, ] = theta\n  SIGMA[, , s] = sigma\n}\n\nprint_quantiles(THETA, SIGMA)\n#&gt; [1] \"Husband\"\n#&gt;     2.5%      50%    97.5% \n#&gt; 41.73803 44.42889 47.15085 \n#&gt; [1] \"Wife\"\n#&gt;     2.5%      50%    97.5% \n#&gt; 38.37376 40.91439 43.48397 \n#&gt; [1] \"Correlation\"\n#&gt;      2.5%       50%     97.5% \n#&gt; 0.8608382 0.9038100 0.9347940\n\n\nii\nUnit information prior (skipping)\niii\n\nShow R codemu0 = rep(0, p)\nlambda0 = 10^5 * diag(p)\ns0 = 1000 * diag(p)\nnu0 = 3\ndiffuse_mcmc = do_mcmc(agehw, mu0, lambda0, s0, nu0)\nprint_quantiles(diffuse_mcmc$theta, diffuse_mcmc$sigma)\n#&gt; [1] \"Husband\"\n#&gt;     2.5%      50%    97.5% \n#&gt; 41.67960 44.41405 47.18645 \n#&gt; [1] \"Wife\"\n#&gt;     2.5%      50%    97.5% \n#&gt; 38.32275 40.88109 43.51451 \n#&gt; [1] \"Correlation\"\n#&gt;      2.5%       50%     97.5% \n#&gt; 0.7931776 0.8552845 0.8996432\n\n\n\n7.3.5 e\nIt doesn’t really seem like the prior information matters because the sample size is so large. Regardless of whether the prior is informative, the quantiles and correlations end up quite similar. Maybe the diffuse prior is slightly different, but it’s not a big difference.\nIf we have a smaller sample size, this may be different. Let’s see what happens if I truncate the dataset to the first 25 variables and rerun with my informative prior and the diffuse prior:\nMy prior\n\nShow R codemu0 = rep(52.5, p)\nlambda0 = s0 = rbind(c(189, 141.75), c(141.75, 189))\n# nu0 = p + 2\nnu0 = p + 2 + 10\nmy_prior_mcmc_short = do_mcmc(agehw[1:25, ], mu0, lambda0, s0, nu0)\nprint_quantiles(my_prior_mcmc_short$theta, my_prior_mcmc_short$sigma)\n#&gt; [1] \"Husband\"\n#&gt;     2.5%      50%    97.5% \n#&gt; 40.96477 45.37803 49.83724 \n#&gt; [1] \"Wife\"\n#&gt;     2.5%      50%    97.5% \n#&gt; 38.41850 43.04898 47.77481 \n#&gt; [1] \"Correlation\"\n#&gt;      2.5%       50%     97.5% \n#&gt; 0.8418117 0.9136244 0.9540250\n\n\nDiffuse prior\n\nShow R codemu0 = rep(0, p)\nlambda0 = 10^5 * diag(p)\ns0 = 1000 * diag(p)\nnu0 = 3\ndiffuse_mcmc_short = do_mcmc(agehw[1:25, ], mu0, lambda0, s0, nu0)\nprint_quantiles(diffuse_mcmc_short$theta, diffuse_mcmc_short$sigma)\n#&gt; [1] \"Husband\"\n#&gt;     2.5%      50%    97.5% \n#&gt; 39.07635 45.12302 51.00340 \n#&gt; [1] \"Wife\"\n#&gt;     2.5%      50%    97.5% \n#&gt; 36.53189 42.74457 48.81278 \n#&gt; [1] \"Correlation\"\n#&gt;      2.5%       50%     97.5% \n#&gt; 0.5427696 0.7613713 0.8823101\n\n\nIn this case, the effect of the prior on correlation especially is easily observed. The correlation for the diffuse prior is quite low, as it is being dragged towards nothing."
  },
  {
    "objectID": "1.html",
    "href": "1.html",
    "title": "Chapter 1: Introduction and examples",
    "section": "",
    "text": "Bayesian inference: the process of learning by updating prior probabilistic beliefs in light of new information. Data analysis tools built on these foundations are known as Bayesian methods.\n\nWe want to estimate a parameter \\(\\theta \\in \\Theta\\) from a dataset \\(y \\in\n\\mathcal{Y}\\).\n\n\n\\(p(\\theta)\\), defined for all \\(\\theta \\in \\Theta\\), is our prior distribution about the space of possible parameters\nBayesian methods require a sampling model: \\(P(y \\mid\n\\theta)\\) describes the probability that of a specific dataset given a parameter.\n\nNote that later, this will be useful for prediction!\n\n\n\nThen we wish to update our belief distribution about \\(\\theta\\) given. The posterior distribution is defined as\n\\[\\begin{align}\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int_{\\Theta}p(y \\mid \\tilde{\\theta}) p(\\tilde{\\theta}) \\; d\\tilde{\\theta}}.\n\\end{align}\\]\nNote that the denominator is constant and doesn’t need to be computed, since we can just normalize our posterior distribution such that \\(P(\\theta \\mid y)\\) for all \\(\\Theta\\) sums up to 1. Thus we commonly write\n\\[\\begin{align}\np(\\theta \\mid y) \\propto p(y \\mid \\theta) p(\\theta).\n\\end{align}\\]\n\n(from Resnik & Hardisty, “Gibbs Sampling for the Uninitiated”)\nThe difference between Bayesian learning and frequentist learning is the consideration of prior beliefs about parameters. In standard Maximum Likelihood Estimation (MLE), we select the parameter that is most likely to have generated the observed data:\n\\[\n\\theta_{ML} = \\underset{\\theta}{\\text{argmax}} \\; p(y \\mid \\theta).\n\\]\nUsing Bayesian Maximum A Posteriori Estimation, however, we select \\(\\theta\\) that is most likely given the observed data. The difference is that our measure of “likelihood given the data” is influenced by our prior beliefs about \\(\\theta\\), as in Equation 2:\n\\[\\begin{align}\n\\theta_{MAP} &= \\underset{\\theta}{\\text{argmax}} \\; p(\\theta \\mid y) \\\\\n  &= \\underset{\\theta}{\\text{argmax}} p(y \\mid \\theta) p(\\theta).\n\\end{align}\\]\nNote that with an uninformative prior \\(\\theta \\sim \\text{Uniform}\\), the MAP estimate is the same as the ML estimate."
  },
  {
    "objectID": "1.html#the-bayesian-learning-framework",
    "href": "1.html#the-bayesian-learning-framework",
    "title": "Chapter 1: Introduction and examples",
    "section": "",
    "text": "We want to estimate a parameter \\(\\theta \\in \\Theta\\) from a dataset \\(y \\in\n\\mathcal{Y}\\).\n\n\n\\(p(\\theta)\\), defined for all \\(\\theta \\in \\Theta\\), is our prior distribution about the space of possible parameters\nBayesian methods require a sampling model: \\(P(y \\mid\n\\theta)\\) describes the probability that of a specific dataset given a parameter.\n\nNote that later, this will be useful for prediction!\n\n\n\nThen we wish to update our belief distribution about \\(\\theta\\) given. The posterior distribution is defined as\n\\[\\begin{align}\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int_{\\Theta}p(y \\mid \\tilde{\\theta}) p(\\tilde{\\theta}) \\; d\\tilde{\\theta}}.\n\\end{align}\\]\nNote that the denominator is constant and doesn’t need to be computed, since we can just normalize our posterior distribution such that \\(P(\\theta \\mid y)\\) for all \\(\\Theta\\) sums up to 1. Thus we commonly write\n\\[\\begin{align}\np(\\theta \\mid y) \\propto p(y \\mid \\theta) p(\\theta).\n\\end{align}\\]\n\n(from Resnik & Hardisty, “Gibbs Sampling for the Uninitiated”)\nThe difference between Bayesian learning and frequentist learning is the consideration of prior beliefs about parameters. In standard Maximum Likelihood Estimation (MLE), we select the parameter that is most likely to have generated the observed data:\n\\[\n\\theta_{ML} = \\underset{\\theta}{\\text{argmax}} \\; p(y \\mid \\theta).\n\\]\nUsing Bayesian Maximum A Posteriori Estimation, however, we select \\(\\theta\\) that is most likely given the observed data. The difference is that our measure of “likelihood given the data” is influenced by our prior beliefs about \\(\\theta\\), as in Equation 2:\n\\[\\begin{align}\n\\theta_{MAP} &= \\underset{\\theta}{\\text{argmax}} \\; p(\\theta \\mid y) \\\\\n  &= \\underset{\\theta}{\\text{argmax}} p(y \\mid \\theta) p(\\theta).\n\\end{align}\\]\nNote that with an uninformative prior \\(\\theta \\sim \\text{Uniform}\\), the MAP estimate is the same as the ML estimate."
  },
  {
    "objectID": "1.html#as-an-approach-to-probability-and-statistics",
    "href": "1.html#as-an-approach-to-probability-and-statistics",
    "title": "Chapter 1: Introduction and examples",
    "section": "\n2.1 As an approach to probability and statistics",
    "text": "2.1 As an approach to probability and statistics\nThe debate between Bayesians and frequentists dives into some very philosophical issues. Cox’s theorem (1946, 1961) gives a formal proof for thinking about probabilities using a Bayesian approach. I will likely want to look at an explanation of these proofs later: http://ksvanhorn.com/bayes/Papers/rcox.pdf\nOutside of formal mathematical grounding, Bayesian methods have excellent practical benefits as data analysis tools:\n\nEven if prior probabilities are not exactly quantifiable, approximations of \\(p(\\theta)\\) and \\(p(\\theta \\mid y)\\) are still useful for analyzing how rational learners would change beliefs\nBayesian methods can represent principled ways of doing analysis when there are no alternative methods"
  },
  {
    "objectID": "1.html#as-models-of-cognition",
    "href": "1.html#as-models-of-cognition",
    "title": "Chapter 1: Introduction and examples",
    "section": "\n2.2 As models of cognition",
    "text": "2.2 As models of cognition\nAn appeal of Bayesian learning is that it is also cognitively intuitive. Humans have beliefs about the world, whose uncertainty can be expressed probabilistically. Then, given data, these beliefs are rationally updated. There is a rich tradition in modeling human cognition using Bayesian methods to great success, with plenty of work done in showing how people’s beliefs and knowledge about the world can be expressed probabilistically (e.g. Griffiths & Tenenbaum, 2006)\nBayesianism is not without its detractors, however. Some critics argue that the evidence that Bayesian analysis is weak, and that sufficiently sophisticated models are unfalsifiable. See Bowers & Davis (2012), comment by Griffiths, Chater, Norris, Pouget (2012), reply by Bowers & Davis (2012)."
  },
  {
    "objectID": "1.html#sensitivity-analysis",
    "href": "1.html#sensitivity-analysis",
    "title": "Chapter 1: Introduction and examples",
    "section": "\n3.1 Sensitivity analysis",
    "text": "3.1 Sensitivity analysis\nIf we change the confidence in our prior, we get different posterior distributions. The more “peaked” our prior is, the less peaked the posterior will be given a \\(Y = 0\\) result (and the less the Bayesian solution will approximate the ML estimate).\nTo quantify how changes in the prior beliefs affect our posterior estimates, we’ll do some calculations. Recall the expectation and variance of Beta distributions. If \\(X \\sim \\text{Beta}(\\alpha, \\beta)\\), then\n\\[\\begin{align}\n\\mathbb{E}(X) &= \\frac{\\alpha}{\\alpha + \\beta} \\\\\n\\text{Var}(X) &= \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}.\n\\end{align}\\]\nDue to the properties of these functions we can parameterize the Beta distribution alternatively with\n\nExpectation: \\(\\theta_0 = \\frac{\\alpha}{\\alpha + \\beta}\\)\n\nPrecision: \\(w = a + b\\)\n\n\nSince \\((\\theta \\mid Y = y) \\sim \\text{Beta}(a + y, b + n - y)\\),\n\\[\\begin{align}\n\\mathbb{E}(\\theta \\mid Y = y) &= \\frac{a + y}{a + b + n} \\\\\n&= \\frac{n}{w + n}\\frac{y}{n} + \\frac{w}{w + n}\\theta_0.\n\\end{align}\\]\n\nShow R code# What is the expected value of theta after observing result y, given a Beta\n# prior parameterized by theta0 and w?\nN = 20\nexp.posterior = function(w, theta0, y) {\n  (N / (w + N)) * (y / N) + (w / (w + N)) * theta0\n}\nTheta0 = rev(seq(0.0, 0.5, by = 0.01))\nW = seq(0, 25, by = 0.5)\nd = outer(Theta0, W, FUN = function(w, theta0) exp.posterior(w, theta0, 0))\nrownames(d) = Theta0\ncolnames(d) = W\n\ndf = melt(d)\ncolnames(df) = c('theta0', 'w', 'theta')\n\np = ggplot(df, aes(x = w, y = theta0, z = theta)) +\n  geom_contour(aes(colour = ..level..))\nlibrary(directlabels)\ndirect.label(p, method = 'bottom.pieces')\n\n\nExpected value of the posterior for theta, for combinations of theta0 and w"
  },
  {
    "objectID": "1.html#comparison-to-non-bayesian-methods",
    "href": "1.html#comparison-to-non-bayesian-methods",
    "title": "Chapter 1: Introduction and examples",
    "section": "\n3.2 Comparison to non-Bayesian methods",
    "text": "3.2 Comparison to non-Bayesian methods\nWhen we use the frequentist maximum likelihood estimator, we get an estimated \\(\\theta_{ML} = 0\\). Since our estimate is subject to sampling error, we commonly construct confidence intervals for these estimates.\nThe Wald interval is a commonly used confidene interval for a population proportion. However, it is not meant to be used for small sample sizes or situations in which the observed proportion is close to (or equals) 0 or 1, since in these cases the error of a binomially-distributed observation is not at all like the normal distribution For an observation \\(Y = 20\\), for example, the Wald CI is, regardless of level of confidence, just \\(0\\). We wouldn’t want to say with 99.999% confidence that the population mean is 0, given our small sample size.\nThe previous Bayesian estimate, however, works well for both small and large n.  With small \\(n\\), the estimator allows us to encode prior beliefs about the true proportion. With \\(w\\) and \\(\\theta_0\\) as before:\n\\[\n\\hat{\\theta} = \\mathbb{E}(\\theta \\mid Y = y) = \\frac{n}{n + w}\\frac{y}{n} + \\frac{w}{n + w}\\theta_0.\n\\]\nNotice that this is kind of an average between the prior expectation \\(\\theta_0\\) and the observed proportion of the data \\(\\frac{y}{n}\\), weighted by the amount of data \\(n\\). For large \\(n\\), \\(\\hat{\\theta}\\) becomes dominated by the data, regardless of prior estimate and confidence.\nTheoretical details on the properties of Bayesian estimators are covered later in Section 5.4."
  },
  {
    "objectID": "1.html#bayesian-regression-does-better-than-standard-linear-regression",
    "href": "1.html#bayesian-regression-does-better-than-standard-linear-regression",
    "title": "Chapter 1: Introduction and examples",
    "section": "\n4.1 Bayesian regression does better than standard linear regression",
    "text": "4.1 Bayesian regression does better than standard linear regression\nThe standard ordinary least squares (OLS) estimate of \\(\\mathbf{\\beta}\\) does worse than the Bayesian method on the test set. This is due to overfitting, and OLS’s “inability to recognize when the sample size is too small to accurately estimate the regression coefficients.” Sparse linear regression models are key here, and the Bayesian sparsity prior performs well; the common lasso technique introduced by Tibshirani (1996) is also popular, but this in fact corresponds to Bayesian methods for a special case."
  },
  {
    "objectID": "2.html",
    "href": "2.html",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "",
    "text": "This section will be brief, as it is just a review of probability. However, as exchangeability and de Finetti’s theorem are important especially in Bayesian statistics, I’ll go into more depth there."
  },
  {
    "objectID": "2.html#descriptions-of-distributions",
    "href": "2.html#descriptions-of-distributions",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n4.1 Descriptions of distributions",
    "text": "4.1 Descriptions of distributions\nIn the same way that we use the mean, mode, and median to describe samples, we can use them to describe distributions. Notice that for many distributions, these quantities are not the same.\nWe also use variance and quantiles to measure the spread of distributions."
  },
  {
    "objectID": "2.html#joint-distributions",
    "href": "2.html#joint-distributions",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n4.2 Joint distributions",
    "text": "4.2 Joint distributions\n\n4.2.1 Discrete\nLet \\(Y_1\\) and \\(Y_2\\) be random variables with sample spaces \\(\\mathcal{Y}_1\\) and \\(\\mathcal{Y}_2\\). Then the joint pdf/density of \\(Y_1\\) and \\(Y_2\\) is defined as:\n\\[\np(y_1, y_2) = P(\\{Y_1 = y_1\\} \\cap \\{Y_2 = y_2 \\})\n\\]\nand the marginal density of \\(Y_1\\) is obtained by summing over all possible values of \\(Y_2\\):\n\\[\\begin{align}\np(y_1) &= \\sum_{y_2 \\in \\mathcal{Y}_2} p(y_1, y_2) \\\\\n       &= \\sum_{y_2 \\in \\mathcal{Y}_2} p(y_1 \\mid y_2) p(y_2).\n\\end{align}\\]\nThe conditional density is\n\\[\\begin{align}\np(y_2 \\mid y_1) = \\frac{p(y_1, y_2)}{p(y_1)}\n\\end{align}\\]\nNotice that given the joint density \\(p(y_1, y_2)\\), we can calculate marginal and conditional densities \\(\\{ p(y_1), p(y_2), p(y_1 \\mid y_2), p(y_2 \\mid y_1) \\}\\) by simply summing up the relevant variables. Additionally, given \\(p(y_1)\\) and \\(p(y_2 \\mid y_1)\\), (or the reverse), we can reconstruct the joint distribution. However, given only marginal densities \\(p(y_1)\\) and \\(p(y_2)\\), we can’t reconstruct the joint distribution, since we don’t know whether the events are independent.\n\n4.2.2 Continuous\nIn the continuous case, the probability density function is a function of \\(y_1\\) and \\(y_2\\) such that the CDF is\n\\[\nF(y_1, y_2) = \\int_{-\\infty}^{y_1} \\int_{-\\infty}^{y_2} p(y_1, y_2) \\; dy_2 \\; dy_1.\n\\]\nObtaining the marginal densities can be done by integrating out the irrelevant variable:\n\\[\\begin{align}\np(y_1) &= \\int_{-\\infty}^{\\infty} p(y_1, y_2) \\; dy_2 \\\\\np(y_2) &= \\int_{-\\infty}^{\\infty} p(y_1, y_2) \\; dy_1 \\\\\n\\end{align}\\]\nWith the marginal densities, you can compute the conditional densities \\(p(y_2\n\\mid y_1) = p(y_1, y_2) / p(y_1)\\), etc."
  },
  {
    "objectID": "2.html#independent-random-variables",
    "href": "2.html#independent-random-variables",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n4.3 Independent random variables",
    "text": "4.3 Independent random variables\nLet \\(Y_1, \\dots, Y_n\\) be random variables dependent on a common parameter \\(\\theta\\). Then \\(Y_1 \\dots, Y_n\\) are conditionally independent given \\(\\theta\\) if\n\\[\\begin{align}\np(y_1, \\dots, y_n \\mid \\theta) = p(y_1 \\mid \\theta) \\times \\dots \\times p(y_n \\mid \\theta).\n\\end{align}\\]\nNote this extends naturally from the definition of independent of two random variables, \\(P(A \\cap B) = P(A) P(B)\\). Thus, knowing about any \\(Y_i\\) does not give any information about the other \\(Y_j\\). Lastly, the joint density of these variables can be defined as\n\\[\np(y_1, \\dots, y_n \\mid \\theta) = \\prod_i p(y_i \\mid \\theta).\n\\]\nWe say that \\(Y_1, \\dots, Y_n\\) are conditionallly independent and identically distributed (i.i.d.):\n\\[\nY_1, \\dots, Y_n \\mid \\theta \\sim \\text{i.i.d.} \\; p(y \\mid \\theta).\n\\]"
  },
  {
    "objectID": "2.html#proof-for-0-1-random-variables",
    "href": "2.html#proof-for-0-1-random-variables",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n6.1 Proof for {0, 1} random variables",
    "text": "6.1 Proof for {0, 1} random variables\nFrom Heath & Sudderth (1976). De Finetti’s Theorem on Exchangeable Variables. Also see this neat StackExchange answer.\n\n6.1.1 Alternative statement of theorem\nFor every infinite sequence of exchangeable random variables \\((X_n)\\) having values in \\(\\{0, 1\\}\\) and a finite subsequence \\(X_1, \\dots, X_n\\), there is a probability distribution \\(F\\) such that\n\\[\\begin{align}\nP(X_1 = 1, \\dots, X_k = 1, X_{k+1} = 0, \\dots, X_n = 0) &=  \\\\\nP\\left(\\underbrace{1, \\dots, 1}_{\\text{$k$ times}}, \\underbrace{0, \\dots, 0}_{\\text{$n - k$ times}}\\right) &= \\int_{0, 1} \\theta^k (1 - \\theta)^{n-k} F(d \\theta)\n\\end{align}\\]\nWhere \\(F\\) is the prior over \\(\\Theta\\), i.e. the values that \\(\\theta\\) can take.\n\n6.1.2 Proof\nLemma. Let \\(p_{k, n} = P(X_1 = 1, \\dots, X_k = 1, X_{k + 1} = 0, \\dots, X_n =\n0)\\), the quantity on the left side of the above equation, and suppose \\(X_1,\n\\dots, X_m\\) are exchangable Boolean random variables as before.\nLet \\(q_r = P\\left( \\sum_{j\n= 1}^m X_j = r \\right)\\), that is, \\(q_i\\) is the probability that exactly \\(i\\) of the \\(m\\) variables are 1.\nAlso denote \\((x)_k = \\prod_{j = 0}^{k - 1} (x - j) = \\frac{x!}{(x - k)!}\\).\nThen,\n\\[\\begin{align}\np_{k, n} = \\sum_{r = 0}^{m} \\frac{(r)_k (m - r)_{n - k}}{(m)_n} q_r \\text{ for } 0 \\leq k \\leq n \\leq m\n\\end{align}\\]\nwhere \\(\\frac{(r)_k (m - r)_{n - k}}{(m)_n}\\) is some complicated combinatorics term for the number of ways to that \\(r\\) ones and \\(m - r\\) zeros can be placed in a sequence of length \\(m\\).\nWith the sustitution \\(\\frac{r}{m} = \\theta\\), we can re-package the summation of discrete \\(r\\) as an integral over a stepwise function \\(F_m\\) with domain \\([0, 1]\\) that jumps \\(q_r\\) at every interval \\(0 \\leq r / m \\leq 1\\):\n\\[\np_{k, n} = \\int_{0}^{1} \\frac{(\\theta m)_k ((1 - \\theta)m)_{n - k}}{(m)_n} F_m(d\\theta).\n\\]\nAs \\(m\\) goes to infinity, the steps of the stepwise function grow infinitely small, such that the function converges to the continuous probability distribution \\(F\\). By Helly’s theorem and some hand-waving in this explanation, the components of the integrand converge to the exponential terms in the theorem: \\(\\theta^k (1 - \\theta)^{n - k}\\)."
  },
  {
    "objectID": "2.html#section",
    "href": "2.html#section",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n7.1 2.1",
    "text": "7.1 2.1\n\n7.1.1 a\nThe marginal probability distribution of a father’s occupation is found by summing over the rows of the son’s occupation. Formally, let \\(F\\) be the father’s occupation and \\(S\\) be the son’s. Then \\(P(F = f) = \\sum P(F = f, S = s)\\).\n\nFarm: 0.11\nOperatives: 0.279\netc…\n\n7.1.2 b\nThis time sum over columns.\n\n7.1.3 c\nIn the row of the table where the father’s occupation is “farm”, normalize the values of the son’s occupation such that they sum to one. This can be done by dividing each value by the sum of the row. Formally, this is calculating\n\\[\\begin{align}\nP(S = s \\mid F = \\text{farm}) &= \\frac{P(S = s, F = \\text{farm})}{P(F = \\text{farm})} \\\\\n&= \\frac{P(S = s, F = \\text{farm})}{\\sum_{s' \\in S} P(S = s', F = \\text{farm})}.\n\\end{align}\\]\n\n7.1.4 d\nNormalize the column where the son’s occupation is “farm” like above."
  },
  {
    "objectID": "2.html#section-1",
    "href": "2.html#section-1",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n7.2 2.2",
    "text": "7.2 2.2\n\n7.2.1 a\nSince expectation is linear, \\[\\begin{align}\n\\mathbb{E}(a_1 Y_1 + a_2 Y_2) &= a_1\\mathbb{E}(Y_1) + a_2\\mathbb{E}(Y_2) \\\\\n&= a_1 \\mu_1 + a_2 \\mu_2\n\\end{align}\\]\nSince \\(Y_1\\) and \\(Y_2\\) are independent, \\(\\text{Cov}(Y_1, Y_2) = 0\\). When adding variances, it’s necessary to combine terms like below: \\[\\begin{align}\n\\text{Var}(a_1 Y_1 + a_2 Y_2) &= a^2\\text{Var}(Y_1) + b^2\\text{Var}(Y_2) + 2ab\\text{Cov}(Y_1, Y_2) \\\\\n&= a^2\\sigma_1^2 + b^2\\sigma_2^2\n\\end{align}\\]\n\n7.2.2 b\n\\[\\begin{align}\n\\mathbb{E}(a_1 Y_1 - a_2 Y_2) &= a_1\\mathbb{E}(Y_1) - a_2\\mathbb{E}(Y_2) \\\\\n&= a_1 \\mu_1 - a_2 \\mu_2\n\\end{align}\\]\n\\[\\begin{align}\n\\text{Var}(a_1 Y_1 - a_2 Y_2) &= a^2\\text{Var}(Y_1) + b^2\\text{Var}(Y_2) - 2ab\\text{Cov}(Y_1, Y_2) \\\\\n&= a^2\\sigma_1^2 + b^2\\sigma_2^2 \\\\\n&= \\text{Var}(a_1 Y_1 + a_2 Y_2)\n\\end{align}\\]"
  },
  {
    "objectID": "2.html#section-2",
    "href": "2.html#section-2",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n7.3 2.3",
    "text": "7.3 2.3\nLet \\(X, Y, Z\\) be random variables with joint density \\(p(x, y, z) \\propto f(x, z) g(y, z) h(z)\\).\n\n7.3.1 a\n\\[\\begin{align}\np(x \\mid y, z) &= \\frac{p(x, y, z)}{p(y, z)} \\\\\n&= \\frac{p(x, y, z)}{\\int p(x, y, z) \\; dx} \\\\\n&\\propto \\frac{f(x, z) g(y, z) h(z)}{\\int f(x, z) g(y, z) h(z) \\; dx} \\\\\n&\\propto \\frac{f(x, z) g(y, z) h(z)}{g(y, z) h(z) \\int f(x, z) \\; dx} \\\\\n&\\propto \\frac{f(x, z)}{\\int f(x, z) \\; dx}\n\\end{align}\\]\n\n7.3.2 b\n\\[\\begin{align}\np(y \\mid x, z) &= \\frac{p(x, y, z)}{p(x, z)} \\\\\n&\\propto \\frac{f(x, z) g(y, z) h(z)}{\\int p(x, y, z) \\; dy} \\\\\n&\\propto \\frac{f(x, z) g(y, z) h(z)}{\\int f(x, z) g(y, z) h(z) \\; dy} \\\\\n&\\propto \\frac{f(x, z) g(y, z) h(z)}{f(x, z) h(z) \\int g(y, z) \\; dy}\n&\\propto \\frac{g(y, z)}{\\int g(y, z) \\; dy}\n\\end{align}\\]\n\n7.3.3 c\nIt is sufficient to show that \\(p(x \\mid y, z) = p(x \\mid z)\\):\nFrom (a), \\(p(x \\mid y, z) \\propto \\frac{f(x, z)}{\\int f(x, z) \\; dx}\\). Now\n\\[\\begin{align}\np(x \\mid z) &= \\frac{p(x, z)}{p(z)} \\\\\n&\\propto \\frac{\\int p(x, y, z) \\; dy}{\\int \\int p(x, y, z) \\; dy \\; dx} \\\\\n&\\propto \\frac{\\int f(x, z) g(y, z) h(z) \\; dy}{\\int \\int f(x, z) g(y, z) h(z) \\; dy \\; dx} \\\\\n&\\propto \\frac{f(x, z) h(z) \\int g(y, z) \\; dy}{h(z) \\left( \\int g(y, z) \\; dy \\right) \\left( \\int f(x, z) \\; dx \\right)} \\\\\n&\\propto \\frac{f(x, z)}{\\int f(x, z) \\; dx} \\\\\n&\\propto p(x \\mid y, z)\n\\end{align}\\]\nNow, since \\(p(x \\mid z) \\propto p(x \\mid y, z)\\) but additionally \\(\\int p(x \\mid\nz) = \\int p(x \\mid y, z) = 1\\), \\(p(x \\mid z) = p(x \\mid y, z)\\), so \\(x\\) and \\(y\\) are conditionally independent given \\(z\\)."
  },
  {
    "objectID": "2.html#section-3",
    "href": "2.html#section-3",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n7.4 2.4",
    "text": "7.4 2.4\n\n7.4.1 a\nUse P3 and condition on an always true event:\n\\[\\begin{align}\nP(H_j \\cap E \\mid 1 = 1) &= P(H_j \\mid 1 = 1) P(E \\mid H_j \\cap 1 = 1) = P(H_j)P(E \\mid H_j) \\\\\nP(H_j \\cap E \\mid 1 = 1) &= P(E \\mid 1 = 1) P(H_j \\mid E \\cap 1 = 1) = p(E)p(H_j \\mid E) \\\\\n&= P(H_j) P(E \\mid H_j)\n\\end{align}\\]\n\n7.4.2 b\nIf we can assume that \\(p(\\mathcal{H}) = 1\\), then\n\\[\\begin{align}\nP(E) &= P(E \\cap H) \\\\\n&= P(E \\cap (H_1 \\cup H_2 \\cup \\dots \\cup H_k)) \\\\\n&= P((E \\cap (H_1)) \\cup (E \\cap (H_2 \\cup \\dots \\cup H_k))) & \\text{Distributing} \\\\\n&= P(E \\cap H_1) + P(E \\cap (H_2 \\cup \\dots \\cup H_k)) & \\text{P2; Implied condition on a true event}\n\\end{align}\\]\n\n7.4.3 c\nProceed inductively from b.\n\n7.4.4 d\n\\[\\begin{align}\n& P(H_j)P(E \\mid H_j) = P(E)P(H_j \\mid E) \\\\\n\\implies& P(H_j \\mid E) = \\frac{P(H_j)P(E \\mid H_j)}{P(E)} \\\\\n\\implies& P(H_j \\mid E) = \\frac{P(H_j)P(E \\mid H_j)}{\\sum_k P(E \\cap H_k)} & \\text{From c} \\\\\n\\implies& P(H_j \\mid E) = \\frac{P(H_j)P(E \\mid H_j)}{\\sum_k P(E \\mid H_k) P(H_k)} & \\text{P3} \\\\\n\\end{align}\\]"
  },
  {
    "objectID": "2.html#section-4",
    "href": "2.html#section-4",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n7.5 2.5",
    "text": "7.5 2.5\n\n7.5.1 a\n\nShow R codex = rbind(\n  # Y = 0 Y = 1\n  c(.5 * .4, .5 * .6), # X = 0\n  c(.5 * .6, .5 * .4) # X = 1\n)\nrownames(x) = c(\"X = 0\", \"X = 1\")\nkable(x, col.names = c(\"Y = 0\", \"Y = 1\"))\n\n\n\n\nY = 0\nY = 1\n\n\n\nX = 0\n0.2\n0.3\n\n\nX = 1\n0.3\n0.2\n\n\n\n\n\n\n7.5.2 b\n\\[\\mathbb{E}(Y) = 0.5\\]. Probability the ball is green is \\(0.5\\).\n\n7.5.3 c\n\\[\\begin{align}\n\\text{Var}(Y \\mid X = 0) &= \\mathbb{E}((Y \\mid X = 0)^2) - \\mathbb{E}(Y \\mid X = 0)^2 \\\\\n&= 1^2 p(Y = 1 \\mid X = 0) + 0^2 p(Y = 0 \\mid X = 0) - \\\\ & \\quad (1 p(Y = 1 \\mid X = 0) + 0 p(Y = 0 \\mid X = 0))^2 \\\\\n&= .6 - (.6)^2 \\\\\n&= 0.24 \\\\\n&= \\text{Var}(Y \\mid X = 1) & \\text{Not going to do this one}\n\\end{align}\\]\n\\[\\begin{align}\n\\text{Var}(Y) &= \\mathbb{E}(Y^2) - \\mathbb{E}(Y)^2 \\\\\n&= 1^2 p(Y = 1) + 0^2 p(Y = 0) - (0.5)^2 \\\\\n&= 0.5 - (0.5)^2 = 0.25\n\\end{align}\\]\n\\(\\text{Var}(Y)\\) is slightly larger since we are more uncertain about the value of \\(Y\\) when we have not yet flipped the coin. Knowing which urn we will draw from clarifies our probabilites of obtaining a green or red ball.\n\n7.5.4 d\n\\[\\begin{align}\nP(X = 0 \\mid Y = 1) &= .6\n\\end{align}\\]"
  },
  {
    "objectID": "2.html#section-5",
    "href": "2.html#section-5",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n7.6 2.6",
    "text": "7.6 2.6\nIf \\(A \\perp B \\mid C\\) then\n\\[\\begin{align}\nP(A, B \\mid C) &= P(A \\mid C) P(B \\mid C) \\\\\n  &= (1 - P(A^c \\mid C))P(B \\mid C) \\\\\n  &= P(B \\mid C) - P(B \\mid C)P(A^c \\mid C)\n\\end{align}\\]\nso \\[P(B \\mid C)P(A^c \\mid C) = P(B \\mid C) - P(A, B \\mid C)\\].\nAlso notice \\[\\begin{align}\n& P(B \\mid C) = P(A, B \\mid C) + P(A^c, B \\mid C) & \\text{LTP} \\\\\n\\implies & P(A^c, B \\mid C) = P(B \\mid C) - P(A, B \\mid C)\n\\end{align}\\]\nEquating the two equations above, we have \\[\nP(A^c, B \\mid C) = P(B \\mid C) P(A^c \\mid C)\n\\]\nWe do this similarly for the other events.\nFor a case where \\(A \\perp B \\mid C\\) holds but \\(A \\perp B \\mid C^c\\) does not, consider a Bayesian network where knowing \\(C\\) results in 100% belief in the values of \\(A\\) and \\(B\\) (e.g. \\(P(A, B \\mid C) = 1\\)), but absent of \\(C\\), values \\(A\\) and \\(B\\) have some probability of manifesting that affect each other."
  },
  {
    "objectID": "2.html#section-6",
    "href": "2.html#section-6",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n7.7 2.7",
    "text": "7.7 2.7\n\n7.7.1 a\nNo matter how likely the event, the maximum money you will obtain is $1. Thus no rational person would give more than $1 for the possibility of obtaining $1, as such an action would always result in lost money.\n\n7.7.2 b\nSince either \\(E\\) or \\(E^c\\) will definitively happen, we would want someone who is betting on the occurrences of either \\(E\\) or \\(E^c\\) to even out."
  },
  {
    "objectID": "2.html#section-7",
    "href": "2.html#section-7",
    "title": "Chapter 2: Belief, probability, and exchangeability",
    "section": "\n7.8 2.8",
    "text": "7.8 2.8\n\n7.8.1 a\ni\nA frequentist idea: if I were to pick at random many, many \\(x\\) sampled from the census roll, how many of them would be Hindu?\nA subjectivist interpretation: how strongly do I believe that a random person from this census roll is Hindu?\n(Should be \\(0.15\\))\nii\nIf I were to pick at random many, many \\(x\\) from the census roll, in the long run average, what proportion of them would be \\(6452859\\)?\nHow strongly do I believe that this \\(x\\) I am going to sample is \\(6452859\\)?\niii\nAn interesting one\nAssume person \\(6452589\\) is a random person sampled from Sri Lanka that is either Hindu or not. In the long run, if I observed many persons \\(6452589\\), how many of them would be Hindu?\nPerson \\(6452589\\) is one person who may or may not be Hindu. How strongly do I believe that he/she is Hindu?\n\n7.8.2 b\ni\nii\niii\nSkipping\n\n7.8.3 c"
  },
  {
    "objectID": "4.html",
    "href": "4.html",
    "title": "Chapter 4: Monte Carlo approximation",
    "section": "",
    "text": "Why Monte Carlo? Often we want to calculate either arbitrary properties of posterior distributions or complex posterior distributions themselves. Often, clean analytical solutions for posterior distributions are difficult to obtain. By using computational methods, we can approximate arbitrarily complex posterior probability calculations by repeatedly sampling posteriors. Such techniques are known as Monte Carlo methods."
  },
  {
    "objectID": "4.html#numerical-evaluation",
    "href": "4.html#numerical-evaluation",
    "title": "Chapter 4: Monte Carlo approximation",
    "section": "\n1.1 Numerical evaluation",
    "text": "1.1 Numerical evaluation\nThe actual posterior mean of \\(\\theta_2 \\mid y\\) is \\(68/45 = 1.51\\). Notice we can approximate this mean with the mean of the above\n\nShow R codemeans = c('10 samples' = mean(mc10$theta),\n          '100 samples' = mean(mc100$theta),\n          '1000 samples' = mean(mc1000$theta))\nkable(means, col.names = 'Estimate of E(theta)')\n\n\n\n\nEstimate of E(theta)\n\n\n\n10 samples\n1.442985\n\n\n100 samples\n1.524203\n\n\n1000 samples\n1.519111\n\n\n\n\n\nWe can calculate probabilities of events concerning theta by counting the number of times in our sample the randomly sampled value satisfies the event. For example, to calculate \\(P(\\theta &lt; 1.75 \\mid y)\\), we observe the number of times a sampled \\(\\theta^{i} &lt; 1.75\\). In R, comparison operators like &gt; or == operate element-wise, so mc1000$theta &lt; 1.75 returns a boolean vector of Ts and Fs depending on whether the specific \\(\\theta^i\\) is indeed less than 1.75:\nThus, we can calculate\n\nShow R codemeans = c('10 samples' = mean(mc10$theta &lt; 1.75),\n          '100 samples' = mean(mc100$theta &lt; 1.75),\n          '1000 samples' = mean(mc1000$theta &lt; 1.75))\nkable(means, col.names = 'Estimate of P(theta &lt; 1.75)')\n\n\n\n\nEstimate of P(theta &lt; 1.75)\n\n\n\n10 samples\n1.00\n\n\n100 samples\n0.85\n\n\n1000 samples\n0.89\n\n\n\n\n\nNotice the true probability can be calculated with via pgamma(1.75, 68, 45) and is 0.9."
  },
  {
    "objectID": "4.html#convergence",
    "href": "4.html#convergence",
    "title": "Chapter 4: Monte Carlo approximation",
    "section": "\n1.2 Convergence",
    "text": "1.2 Convergence\nWe can measure how quickly our estimates converge to the true mean (for this example, when the true mean is known) by plotting the estimate thus far as the number of samples in our estimation increase, as below:\n\nShow R codecstats = melt(data.frame(\n  n = seq_along(mc1000$theta),\n  'Expectation' = cumsum(mc1000$theta) / seq_along(mc1000$theta),\n  'Probability' = cumsum(mc1000$theta &lt; 1.75) / seq_along(mc1000$theta &lt; 1.75)\n), id.vars = 'n')\nrealstats = data.frame(\n  stat = c(68 / 45, pgamma(1.75, 68, 45)),\n  variable = c('Expectation', 'Probability')\n)\nggplot(cstats, aes(x = n, y = value)) +\n  facet_wrap(~ variable, scales = 'free') +\n  geom_line() +\n  ylab('Estimate') + xlab('Number of samples') +\n  geom_hline(data = realstats, mapping = aes(yintercept = stat), lty = 2)\n\n\n\n\n\n\n\nSince, due to the central limit theorem, estimates of the mean of \\(\\theta^1, \\dots,\n\\theta^S\\) (and other quantities??) are approximately normally distributed for large \\(S\\), we can construct confidence intervals for our estimates based on the sample size.\nSpecifically, an approximate 95% confidence interval for \\(\\theta\\) is\n\\[\n\\hat{\\theta} \\pm 1.96 \\sqrt{\\hat{\\sigma}^2 / S}\n\\]\nwhere \\(\\hat{\\sigma}^2\\) is the unbiased estimator of the population variance (hence the approximate confidence interval; divide by \\(S - 1\\), not \\(S\\)). Using this, we can estimate the number of samples we ought to take to report our estimate to a certain degree of precision. We ought to take enough samples such that the standard error \\(\\sqrt{\\hat{\\sigma}^2/S} &lt; \\alpha\\) where \\(\\alpha\\) is the desired level of precision. Of course, since we don’t know how variable our samples are, we don’t know how big \\(\\hat{\\sigma}^2\\) is, so we cannot a priori determine the number of samples to run. It is possible, however, to run a smaller number of samples first to determine an estimate of \\(\\hat{\\sigma}^2\\) and thus the standard error, then conservatively use that estimate to identify the size of \\(S\\) required for the desired precision."
  },
  {
    "objectID": "4.html#example-log-odds",
    "href": "4.html#example-log-odds",
    "title": "Chapter 4: Monte Carlo approximation",
    "section": "\n2.1 Example: Log-odds",
    "text": "2.1 Example: Log-odds\nLog-odds is the relative likelihood that an event with probability \\(\\theta\\) will occur versus not occur. Specifially,\n\\[\\begin{align}\n\\text{log odds}(\\theta) = \\log \\left( \\frac{\\theta}{1 - \\theta} \\right) = \\gamma.\n\\end{align}\\]\nIf \\(\\theta = 0.5 = 1 - \\theta\\) then \\(\\text{log odds}(\\theta) = 0\\). If \\(\\theta\\) is more likely to happen than not, then \\(\\text{log odds}(\\theta) &gt; 0\\). If \\(\\theta\\) is less likely to happen than not, then \\(\\text{log odds}(\\theta) &lt; 0\\).\nWe return to surveys. Imagine we survey 860 individuals about agreement with a recent Supreme Court ruling and \\(y = 441\\) say they agreed with the ruling. Say we have a uniform prior on \\(\\theta\\) before observing any data, so \\(\\theta \\sim \\text{Beta}(1, 1)\\).\nNotice that, even when given a concrete prior distribution, calculating the prior distribution on \\(\\gamma\\) requires actual calculations. They may be managable in this case, but the point is that as functions become far more complicated than the log-odds calculation in this example, even computing a closed form for our prior may be intractable.\nSo we can do Monte Carlo estimation of prior and posterior distributions of \\(\\gamma\\) based on our knowledge about how \\(\\theta\\) updates after observing data. Recall that, in our beta-binomial model, if \\(\\theta \\sim \\text{Beta}(a, b) =\n\\text{Beta}(1, 1)\\), then \\(\\theta \\mid y_1, \\dots, y_n \\sim \\text{Beta}(a + n, b\n+ n - y) = \\text{Beta}(442, 420)\\).\nNotice that our log odds ratio is quite close to 0. Moreover, by leveraging Monte Carlo estimation, we are very (approximately) precise about the precise shape of our prior and posterior distributions, with little mathematical derivation required.\n\nShow R codea = 1\nb = 1\ny = 441\nn = 860\nn.samp = 10000\n\nlog.odds = function(x) log(x / (1 - x))\n\ntheta.prior.mc = rbeta(n.samp, a, b)\n# Now compute gammas as a function of theta!\nprior = log.odds(theta.prior.mc)\n\ntheta.post.mc = rbeta(n.samp, a + y, b + n - y)\nposterior = log.odds(theta.post.mc)\n\ncombined = melt(cbind(prior, posterior))\ncolnames(combined) = c('n', 'type', 'value')\n\nggplot(combined, aes(x = value, group = type, color = type)) +\n  geom_density(fill = NA) +\n  scale_x_continuous(limits = c(-5, 5)) +\n  xlab('gamma')"
  },
  {
    "objectID": "4.html#example-2-functions-of-two-parameters",
    "href": "4.html#example-2-functions-of-two-parameters",
    "title": "Chapter 4: Monte Carlo approximation",
    "section": "\n2.2 Example 2: Functions of two parameters",
    "text": "2.2 Example 2: Functions of two parameters\nWe can now return back to the earlier example with two separate Poisson models of the number of children of women’s without and with bachelor’s degrees. Since \\(\\theta_1\\) and \\(\\theta_2\\) are independent, we can sample a pair \\((\\theta^{(i)}_1,\n\\theta^{(i)}_2)\\) from separate samples from \\(p(\\theta_1 \\mid y)\\) and \\(p(\\theta_2\n\\mid y)\\), such that many such pairs \\((\\theta^{(i)}_1, \\theta^{(i)}_2)\\) will (by Monte Carlo estimation) approximate the joint density of \\(p(\\theta_1, \\theta_2)\\) without needing to calculate or integrate over the joint density by hand. Again,\n\\[\\begin{align}\n\\left(\\theta_1 \\;\\middle|\\; \\sum_i Y_{i, 1} = 217\\right) &\\sim \\text{Gamma}(219, 112) \\\\\n\\left(\\theta_2 \\;\\middle|\\; \\sum_i Y_{i, 2} = 217\\right) &\\sim \\text{Gamma}(68, 45)\n\\end{align}\\]\nthe corresponding derivation is thus\n\nShow R codeN = 10000\ntheta1.mc = rgamma(N, 219, 112)\ntheta2.mc = rgamma(N, 68, 45)\nmean(theta1.mc &gt; theta2.mc)\n#&gt; [1] 0.9714\n\n\nAlso, like the gamma example above, we can calculate some arbitrary function. Say we are interested in the ratio \\(f(\\theta_1, \\theta_2) = \\theta_1/\\theta_2\\) of the means. On average, how many times more children do women without bachelor’s degrees have compared to those with bachelor’s degrees. Then we sample multiple pairs \\((\\theta^{(i)}_1, \\theta^{(i)}_2)\\), and multiple pairs \\(\\gamma^i =\nf(\\theta^{(i)}_1, \\theta^{(i)}_2)\\).\n\nShow R code# Common prior\na = 2\nb = 1\n# Without bachelor's\nn1 = 111\ny1 = 217\n# With\nn2 = 44\ny2 = 66\n\nn.samp = 10000\n\nratio = function(a, b) a / b # Not necessary, but good for foramlization\n\n# Approximate prior distribution for good measure\nprior = ratio(rgamma(n.samp, a, b), rgamma(n.samp, a, b))\nposterior = ratio(rgamma(n.samp, a + y1, b + n1), rgamma(n.samp, a + y2, b + n2))\n\ncombined = melt(cbind(prior, posterior))\ncolnames(combined) = c('n', 'type', 'value')\ncombined$type = factor(combined$type, levels = c('prior', 'posterior'))\n\nggplot(combined, aes(x = value, group = type, color = type)) +\n  facet_wrap(~ type, scales = 'free_y') +\n  scale_x_continuous(limits = c(0, 10)) +\n  geom_density(fill = NA) +\n  xlab(expression(theta[1] / theta[2]))"
  },
  {
    "objectID": "4.html#section",
    "href": "4.html#section",
    "title": "Chapter 4: Monte Carlo approximation",
    "section": "\n5.1 4.1",
    "text": "5.1 4.1\nFor the county in exercise 3.1, \\(\\theta_3 \\mid \\sum Y_i = y \\sim \\text{Beta}(58,\n44)\\).\nFor this county, assuming a uniform prior, \\(\\theta_4 \\mid \\sum Y_i = y \\sim\n\\text{Beta}(31, 21)\\).\nSo,\n\nShow R codetheta1.mc = rbeta(5000, 58, 44)\ntheta2.mc = rbeta(5000, 31, 21)\nmean(theta1.mc &lt; theta2.mc)\n#&gt; [1] 0.635"
  },
  {
    "objectID": "4.html#section-1",
    "href": "4.html#section-1",
    "title": "Chapter 4: Monte Carlo approximation",
    "section": "\n5.2 4.2",
    "text": "5.2 4.2\n\n5.2.1 a\n\nShow R codetheta.a = rgamma(5000, 237, 20)\ntheta.b = rgamma(5000, 125, 14)\nmean(theta.b &lt; theta.a)\n#&gt; [1] 0.9948\n\n\n\n5.2.2 b\n\nShow R coden0 = 1:50\nexps = sapply(n0, function(n) { \n  mean(rgamma(5000, (12 * n) + 113, n + 13) &lt; rgamma(5000, 237, 20))\n})\nqplot(1:50, exps, geom = c('point', 'smooth'))\n\n\n\n\n\n\n\nEven a strong factor of \\(n_0\\) has a relatively minimal effect on the posterior distribution.\n\n5.2.3 c\nRecall for a Poisson model, the posterior predictive distribution after a \\(\\text{Gamma}(a, b)\\) prior is a negative binomial distribution \\(\\text{NB}(a +\n\\sum y_i, b, n)\\). (The posterior predictive parameters are the same as those of the posterior distribution itself). However, we can also simulate it by sampling from the Poisson distribution implied by the sampled theta.\n\nShow R coden0 = 1:50\nN = 10000\nys = sapply(n0, function(n) {\n  theta.a = rgamma(N, 237, 20)\n  theta.b = rgamma(N, (12 * n) + 113, n + 13)\n  y.a = rpois(N, theta.a)\n  y.b = rpois(N, theta.b)\n  mean(y.b &lt; y.a)\n})\nqplot(1:50, ys, geom = c('point', 'smooth'))\n\n\n\n\n\n\n\nWhich appears to be a different relationship - exactly what it is could be calculated by integrating the quantity using the posterior distribution, then figuring out what the shape is as a function of \\(n_0\\)."
  },
  {
    "objectID": "4.html#section-2",
    "href": "4.html#section-2",
    "title": "Chapter 4: Monte Carlo approximation",
    "section": "\n5.3 4.3",
    "text": "5.3 4.3\n\nShow R codeya = c(12, 9, 12, 14, 13, 13, 15, 8, 15, 6)\nyb = c(11, 11, 10, 9, 9, 8, 7, 10, 6, 8, 8, 9, 7)\n\n\n\n5.3.1 a\nUsing ya:\n\nShow R codetheta1 = rgamma(1000, 2 + sum(ya), 1 + length(ya))\nts = sapply(theta1, function(theta) {\n  ys = rpois(10, theta)\n  t = mean(ys) / sd(ys)\n  t\n})\n\nggplot(data.frame(ts = ts), aes(x = ts)) +\n  geom_histogram() +\n  geom_vline(xintercept = mean(ya) / sd(ya))\n\n\n\n\n\n\n\nSince the observed statistic (vertical line) is centered well within the standard spread of the observed \\(t(s)\\), we have no reason to believe the fit of the Poisson model is bad. Also, since \\(t(s)\\) depends on the only parameter of the data \\(\\theta\\), it can thus be inferred that the Poisson model seems to fit reasonably in this case.\n\n5.3.2 b\nUsing yb:\n\nShow R codetheta2 = rgamma(1000, 2 + sum(yb), 1 + length(yb))\nts = sapply(theta2, function(theta) {\n  ys = rpois(10, theta)\n  t = mean(ys) / sd(ys)\n  t\n})\n\nggplot(data.frame(ts = ts), aes(x = ts)) +\n  geom_histogram() +\n  geom_vline(xintercept = mean(yb) / sd(yb))\n\n\n\n\n\n\n\nSince the observed statistic (vertical line) seems to be an outlier for the range of statistics normally seen in this dataset, we can infer that the Poisson model does not seem to fit this dataset well."
  },
  {
    "objectID": "4.html#section-3",
    "href": "4.html#section-3",
    "title": "Chapter 4: Monte Carlo approximation",
    "section": "\n5.4 4.6",
    "text": "5.4 4.6\n\n5.4.1 via Monte-Carlo sampling\n\nShow R codetheta.mc = runif(10000)\ngamma.mc = sapply(theta.mc, function(theta) log(theta / (1 - theta)))\nggplot(data.frame(gamma = gamma.mc), aes(x = gamma, y = ..density..)) +\n  geom_histogram()\n\n\n\n\n\n\n\nYes, the prior for \\(\\gamma\\) is centered around 0 and appears to be normally distributed. Naturally, \\(p(\\gamma)\\) must be centered around something, since you cannot have a uniform distribution on an infinite interval.\n\n5.4.2 analytically\nThis is computed in Exercise 3.10 (a)."
  },
  {
    "objectID": "4.html#section-4",
    "href": "4.html#section-4",
    "title": "Chapter 4: Monte Carlo approximation",
    "section": "\n5.5 4.7",
    "text": "5.5 4.7\n\n5.5.1 a\nWe first sample \\((\\theta, \\sigma^2)\\) via sampling from \\(p(\\sigma^2)\\) and then \\(p(\\theta \\mid \\sigma^2)\\):\n\nShow R codeN = 10000\nsigma2.mc = 1 / rgamma(N, 10, 2.5)\ntheta.mc = rnorm(N, 4.1, sigma2.mc / 20)\n\n\nNow we can sample according to the mixture posterior distribution:\n\nShow R code# Don't forget about sqrt!\nsigma.mc = sqrt(sigma2.mc)\nynew.mc = .31 * rnorm(N, theta.mc, sigma.mc) +\n  .46 * rnorm(N, 2 * theta.mc, 2 * sigma.mc) +\n  .23 * rnorm(N, 3 * theta.mc, 3 * sigma.mc)\nggplot(mapping = aes(x = ynew.mc)) + geom_histogram()\n\n\n\n\n\n\n\n\n5.5.2 b\n\nShow R codequantile(ynew.mc, c(.125, .875))\n#&gt;    12.5%    87.5% \n#&gt; 7.154727 8.561602\n\n\n\n5.5.3 c\n\nShow R code# i. Compute and normalize density\ndens = density(ynew.mc)\ndens.ynorm = dens$y / sum(dens$y)\n# ii. Sort in decreasing order\ndens.ynorm.desc = dens.ynorm[order(dens.ynorm, decreasing = TRUE)]\n# iii. Find first probability value st cumsum of sorted values &gt; 0.75\ncutoff = dens.ynorm.desc[min(which(cumsum(dens.ynorm.desc) &gt; 0.75))]\nin.hdp = dens.ynorm &gt; cutoff\nggplot(data.frame(y = dens$x, density = dens.ynorm, hdp = in.hdp)) +\n  geom_point(aes(x = y, y = density, color = hdp))\n\n\n\n\n\n\nShow R code\ndens$x[c(min(which(in.hdp)), max(which(in.hdp)))]\n#&gt; [1] 7.170384 8.575215\n\n\nSince the distribution of weights is relatively symmetric and normally distributed, the HDP and quantile confidence intervals are quite similar.\n\n5.5.4 d\nPerhaps a combination of multiple parts of a vegetable which have known distributions (e.g. stem, fruit, leaves, etc)"
  },
  {
    "objectID": "4.html#section-5",
    "href": "4.html#section-5",
    "title": "Chapter 4: Monte Carlo approximation",
    "section": "\n5.6 4.8",
    "text": "5.6 4.8\n\nShow R codemenchild30bach = scan('Exercises/menchild30bach.dat')\nmenchild30nobach = scan('Exercises/menchild30nobach.dat')\n\n\n\n5.6.1 a\n\nShow R codea = 2\nb = 1\nN = 5000\n\nthetaA = rgamma(N, a + sum(menchild30bach), b + length(menchild30bach))\nthetaB = rgamma(N, a + sum(menchild30nobach), b + length(menchild30nobach))\n\nynewA = rpois(N, thetaA)\nynewB = rpois(N, thetaB)\n\npos.predict = data.frame(\n  ynew = c(ynewA, ynewB),\n  dist = factor(rep(c('bach', 'nobach'), each = N), levels = c('bach', 'nobach')),\n  type = 'posterior'\n)\nggplot(pos.predict, aes(x = ynew, group = dist)) +\n  geom_histogram() +\n  facet_grid(. ~ dist)\n\n\n\n\n\n\n\n\n5.6.2 b\n\nShow R codetheta.diff = thetaB - thetaA\nprint(\"Theta difference:\")\n#&gt; [1] \"Theta difference:\"\nprint(quantile(theta.diff, c(0.025, 0.975)))\n#&gt;      2.5%     97.5% \n#&gt; 0.1395081 0.7397640\n\nynew.diff = ynewB - ynewA\nprint(\"Ynew difference:\")\n#&gt; [1] \"Ynew difference:\"\nprint(quantile(ynew.diff, c(0.025, 0.975)))\n#&gt;  2.5% 97.5% \n#&gt;    -2     4\n\n\nSince the confidence interval for \\(\\theta_B - \\theta_A\\) does not contain zero, we believe with at least approximately 95% probability that the true posterior mean \\(\\theta_B\\) is greater than \\(\\theta_A\\). However, the same does not hold true for the means of the difference between two individuals sampled from this distribution, due to the increased uncertainty in the posterior predictive distribution.\n\n5.6.3 c\n\nShow R codeemp.df = data.frame(\n  ynew = c(menchild30bach, menchild30nobach),\n  dist = factor(c(rep('bach', length(menchild30bach)), rep('nobach', length(menchild30nobach))), levels = c('bach', 'nobach')),\n  type = 'empirical'\n)\n\ntotal.df = rbind(pos.predict, emp.df)\n\nggplot(total.df, aes(x = ynew, y = ..density.., group = type, fill = type)) +\n  geom_histogram(position = 'dodge') +\n  facet_grid(. ~ dist)\n\n\n\n\n\n\n\nThe posterior distribution for \\(\\tilde{Y}_B\\) seems to peak around 1, while the empirical distribution peaks strongly around 0. Thus I think this is an error in the model fit.\n(Observe that the mean of the nobach population is around 1.4)\n\nShow R codemean(ynewB)\n#&gt; [1] 1.4154\n\n\n\n5.6.4 d\nModel checking, by computing a statistic that may be of interest:\n\nShow R codezeroandone = lapply(thetaB, function(theta) {\n  nB = rpois(218, theta)\n  n0s = sum(nB == 0)\n  n1s = sum(nB == 1)\n  c(n0s, n1s)\n})\nzeros = sapply(zeroandone, function(t) t[1])\nones = sapply(zeroandone, function(t) t[2])\nggplot(data.frame(zeros = zeros, ones = ones)) +\n  geom_point(aes(x = zeros, y = ones), alpha = 0.1) +\n  annotate('point', x = sum(menchild30nobach == 0), y = sum(menchild30nobach == 1), color = 'red')\n\n\n\n\n\n\n\nThe observed statistic is in red. Notice how it seems somewhat abnormal for sample datasets from our poisson model with \\(\\theta = 1.4\\) especially in the case of the number of ones observed. This is a clear indicator that the fit of our Poisson model is suboptimal."
  },
  {
    "objectID": "9.html",
    "href": "9.html",
    "title": "Chapter 9: Linear regression",
    "section": "",
    "text": "Show R codeswim = read.table('Exercises/swim.dat')\n\n\nTo specify our prior, we let the prior expectation of our \\(y\\)-intercept to be 23, and we let the prior expectation of the effect of training week by week to be 0, so \\(\\boldsymbol{\\beta} = (23, 0)^T\\).\nWe expect no covariance with the \\(\\beta\\) coefficients, but we do have uncertainty about our initial \\(\\beta\\) estimates. Specifically, to let 95% of our uncertainty of the \\(y\\)-intercept to fall in \\([22, 24]\\), we let \\(\\Sigma_{0(1, 1)} = 1/4\\) (so that \\(\\pm\\) 2 standard deviations is \\(\\pm\\) 1). We also expect that training has a relatively mild effect on time, so we let \\(\\Sigma_{0(2, 2)} = 0.1\\) which is just an arbitrarily chosen small variance.\nFor our expectation of the variability of measurements, let’s similarly set \\(\\sigma^2_0 = 1/4\\) and only lightly center this prior with \\(\\nu_0 = 1\\).\n\nShow R codelibrary(MASS) # mvrnorm\nlibrary(dplyr)\nS = 5000\nX = cbind(rep(1, 6), seq(1, 11, by = 2))\nn = dim(X)[1]\np = dim(X)[2]\n\n# Prior\nbeta0 = c(23, 0)\nsigma0 = rbind(c(0.25, 0), c(0, 0.1))\nnu0 = 1\ns20 = 0.25\n\nset.seed(1)\n\ninv = solve\n\n# For each swimmer, run linear regression gibbs sampling and obtain a posterior\n# predictive distribution\nswim_pred = apply(swim, MARGIN = 1, function(y) {\n  \n  # Store samples\n  BETA = matrix(nrow = S, ncol = length(beta0))\n  SIGMA = numeric(S)\n  \n  # Starting values - just use prior values?\n  beta = c(23, 0)\n  s2 = 0.7^2\n  \n  # Gibbs sampling algorithm from 9.2.1\n  for (s in 1:S) {\n    # 1a) Compute V and m\n    V = inv(inv(sigma0) + (t(X) %*% X) / s2)\n    m = V %*% (inv(sigma0) %*% beta0 + (t(X) %*% y) / s2)\n    \n    # 1b) sample beta\n    beta = mvrnorm(1, m, V)\n    \n    # 2a) Compute SSR(beta) (specific formula from 9.1)\n    ssr = (t(y) %*% y) - (2 * t(beta) %*% t(X) %*% y) + (t(beta) %*% t(X) %*% X %*% beta)\n    \n    # 2b) sample s2\n    s2 = 1 / rgamma(1, (nu0 + n) / 2, (nu0 * s20 + ssr) / 2)\n\n    BETA[s, ] = beta\n    SIGMA[s] = s2\n  }\n  \n  # Now sample posterior predictive - two weeks later\n  xpred = c(1, 13)\n  YPRED = rnorm(S, BETA %*% xpred, sqrt(SIGMA))\n  \n  YPRED\n})\n\n\n\n\nShow R codefastest_times = apply(swim_pred, MARGIN = 1, FUN = which.min)\ntable(fastest_times) / length(fastest_times)\n#&gt; fastest_times\n#&gt;      1      2      3      4 \n#&gt; 0.6524 0.0134 0.3060 0.0282\n\n\nWe notice that with our posterior predictive dataset, swimmer 1 is the fastest about 65% of the time by week 13, so we recommend that swimmer 1 race.\n\n\nShow R codecrime = read.table('Exercises/crime.dat', header = TRUE)\n\n\n\n\nShow R codey = crime$y\nX = crime %&gt;% select(-y) %&gt;% as.matrix\n\nn = dim(X)[1]\np = dim(X)[2]\n\ng = n\nnu0 = 2\ns20 = 1\n\nS = 1000\n\nHg = (g / (g + 1)) * X %*% inv(t(X) %*% X) %*% t(X)\nSSRg = t(y) %*% (diag(1, nrow = n) - Hg) %*% y\n\ns2 = 1 / rgamma(S, (nu0 + n) / 2, (nu0 * s20 + SSRg) / 2)\nVb = g * inv(t(X) %*% X) / (g + 1)\nEb = Vb %*% t(X) %*% y\n\nE = matrix(rnorm(S * p, 0, sqrt(s2)), S, p)\nbeta = t(t(E %*% chol(Vb)) + c(Eb))\n\n\n\nShow R codelibrary(tidyr)\n\nsignif = apply(beta, MARGIN = 2, FUN = quantile, probs = c(0.025, 0.5, 0.975)) %&gt;%\n  apply(MARGIN = 2, FUN = function(y) !(y[1] &lt; 0 && 0 &lt; y[3]))\n\nbeta_df = as.data.frame(beta) %&gt;%\n  gather(key = 'variable', val = 'coefficient') %&gt;%\n  mutate(signif = signif[variable])\n\nggplot(beta_df, aes(x = variable, y = coefficient, color = signif)) +\n  stat_summary(fun.y = mean, fun.ymin = function(y) quantile(y, probs = c(0.025)), fun.ymax = function(y) quantile(y, probs = c(0.975))) +\n  geom_hline(yintercept = 0, lty = 2)\n\n\n\n\n\n\n\nLooks like Ed (mean years of schooling), Ineq (Income inequality), M (percentage of males aged 14-24), Prob (probability of imprisonment), and U2 (unemployment rate of urban males 35-39).\n\n\nShow R codey = crime$y\nX = crime %&gt;% select(-y) %&gt;% as.matrix\nset.seed(1) # Reproducible!\ntrain_i = sample.int(length(y), size = round(length(y) / 2), replace = FALSE)\nytr = y[train_i]\nXtr = X[train_i, ]\nyte = y[-train_i]\nXte = X[-train_i, ]\n\n\n\n\nShow R code# From 9.1\nbeta_ols = inv(t(Xtr) %*% Xtr) %*% t(Xtr) %*% ytr\nbeta_ols\n#&gt;             [,1]\n#&gt; M     0.19419790\n#&gt; So    0.20624856\n#&gt; Ed    0.64334998\n#&gt; Po1   0.30590821\n#&gt; Po2   0.44725441\n#&gt; LF   -0.09198965\n#&gt; M.F   0.03537926\n#&gt; Pop   0.08440462\n#&gt; NW   -0.01227990\n#&gt; U1   -0.03278782\n#&gt; U2    0.15494093\n#&gt; GDP   0.10455812\n#&gt; Ineq  0.76691166\n#&gt; Prob -0.25823362\n#&gt; Time  0.05938070\n\ny_ols = Xte %*% beta_ols\n\nols_df = data.frame(\n  observed = yte,\n  predicted = y_ols\n)\n\nggplot(ols_df, aes(x = observed, y = predicted)) +\n  geom_point() +\n  geom_smooth(method = 'lm')\n\n\n\n\n\n\nShow R code\npred_error = sum((yte - y_ols)^2) / length(yte)\npred_error\n#&gt; [1] 0.4880959\n\n\n\n\nShow R codey = ytr\nX = Xtr\n\nn = dim(X)[1]\np = dim(X)[2]\n\ng = n\nnu0 = 2\ns20 = 1\n\nS = 1000\n\nHg = (g / (g + 1)) * X %*% inv(t(X) %*% X) %*% t(X)\nSSRg = t(y) %*% (diag(1, nrow = n) - Hg) %*% y\n\ns2 = 1 / rgamma(S, (nu0 + n) / 2, (nu0 * s20 + SSRg) / 2)\nVb = g * inv(t(X) %*% X) / (g + 1)\nEb = Vb %*% t(X) %*% y\n\nE = matrix(rnorm(S * p, 0, sqrt(s2)), S, p)\nbeta = t(t(E %*% chol(Vb)) + c(Eb))\n\nbeta_bayes = as.matrix(colMeans(beta))\n\ny_bayes = Xte %*% beta_bayes\n\nbayes_df = data.frame(\n  observed = yte,\n  predicted = y_bayes\n)\n\nggplot(ols_df, aes(x = observed, y = predicted)) +\n  geom_point() +\n  geom_smooth(method = 'lm')\n\n\n\n\n\n\nShow R code\npred_error = sum((yte - y_bayes)^2) / length(yte)\npred_error\n#&gt; [1] 0.4910634\n\n\nAt least when the seed is 1, there doesn’t appear to be a major difference between the prediction errors.\n\n\nShow R code# Unnecessary code repeating here. Clean this up later w/ functions\nN = 100\nset.seed(1)\npred_errors = t(sapply(1:N, function(i) {\n  y = crime$y\n  X = crime %&gt;% select(-y) %&gt;% as.matrix\n  train_i = sample.int(length(y), size = round(length(y) / 2), replace = FALSE)\n  ytr = y[train_i]\n  Xtr = X[train_i, ]\n  yte = y[-train_i]\n  Xte = X[-train_i, ]\n  \n  # OLS\n  beta_ols = inv(t(Xtr) %*% Xtr) %*% t(Xtr) %*% ytr\n  beta_ols\n  \n  y_ols = Xte %*% beta_ols\n  \n  pred_error_ols = sum((yte - y_ols)^2) / length(yte)\n  \n  # Bayes\n  y = ytr\n  X = Xtr\n  \n  n = dim(X)[1]\n  p = dim(X)[2]\n  \n  g = n\n  nu0 = 2\n  s20 = 1\n  \n  S = 1000\n  \n  Hg = (g / (g + 1)) * X %*% inv(t(X) %*% X) %*% t(X)\n  SSRg = t(y) %*% (diag(1, nrow = n) - Hg) %*% y\n  \n  s2 = 1 / rgamma(S, (nu0 + n) / 2, (nu0 * s20 + SSRg) / 2)\n  Vb = g * inv(t(X) %*% X) / (g + 1)\n  Eb = Vb %*% t(X) %*% y\n  \n  E = matrix(rnorm(S * p, 0, sqrt(s2)), S, p)\n  beta = t(t(E %*% chol(Vb)) + c(Eb))\n  \n  beta_bayes = as.matrix(colMeans(beta))\n  \n  y_bayes = Xte %*% beta_bayes\n  \n  pred_error_bayes = sum((yte - y_bayes)^2) / length(yte)\n\n  c(pred_error_ols, pred_error_bayes)\n})) %&gt;% as.data.frame\ncolnames(pred_errors) = c('ols', 'bayes')\n\n\nHere’s a plot of the density of \\(\\text{err}_{\\text{Bayes}} -\n\\text{err}_{\\text{ols}}\\). If this is less than 0, then the Bayes estimator did better than the OLS estimator:\n\nShow R codepred_diff = pred_errors %&gt;% transmute(`bayes - ols` = bayes - ols)\n\nggplot(pred_diff, aes(x = `bayes - ols`)) +\n  geom_density() +\n  geom_vline(xintercept = 0, lty = 2)\n\n\n\n\n\n\n\nLastly,\n\nShow R codemean(pred_errors$bayes &lt; pred_errors$ols)\n#&gt; [1] 0.96\n\n\nFor N samples, 96% of the time, the predictive error using the Bayes estimators is less than the predictive error using the OLS estimators. Nice!"
  },
  {
    "objectID": "9.html#section",
    "href": "9.html#section",
    "title": "Chapter 9: Linear regression",
    "section": "",
    "text": "Show R codeswim = read.table('Exercises/swim.dat')\n\n\nTo specify our prior, we let the prior expectation of our \\(y\\)-intercept to be 23, and we let the prior expectation of the effect of training week by week to be 0, so \\(\\boldsymbol{\\beta} = (23, 0)^T\\).\nWe expect no covariance with the \\(\\beta\\) coefficients, but we do have uncertainty about our initial \\(\\beta\\) estimates. Specifically, to let 95% of our uncertainty of the \\(y\\)-intercept to fall in \\([22, 24]\\), we let \\(\\Sigma_{0(1, 1)} = 1/4\\) (so that \\(\\pm\\) 2 standard deviations is \\(\\pm\\) 1). We also expect that training has a relatively mild effect on time, so we let \\(\\Sigma_{0(2, 2)} = 0.1\\) which is just an arbitrarily chosen small variance.\nFor our expectation of the variability of measurements, let’s similarly set \\(\\sigma^2_0 = 1/4\\) and only lightly center this prior with \\(\\nu_0 = 1\\).\n\nShow R codelibrary(MASS) # mvrnorm\nlibrary(dplyr)\nS = 5000\nX = cbind(rep(1, 6), seq(1, 11, by = 2))\nn = dim(X)[1]\np = dim(X)[2]\n\n# Prior\nbeta0 = c(23, 0)\nsigma0 = rbind(c(0.25, 0), c(0, 0.1))\nnu0 = 1\ns20 = 0.25\n\nset.seed(1)\n\ninv = solve\n\n# For each swimmer, run linear regression gibbs sampling and obtain a posterior\n# predictive distribution\nswim_pred = apply(swim, MARGIN = 1, function(y) {\n  \n  # Store samples\n  BETA = matrix(nrow = S, ncol = length(beta0))\n  SIGMA = numeric(S)\n  \n  # Starting values - just use prior values?\n  beta = c(23, 0)\n  s2 = 0.7^2\n  \n  # Gibbs sampling algorithm from 9.2.1\n  for (s in 1:S) {\n    # 1a) Compute V and m\n    V = inv(inv(sigma0) + (t(X) %*% X) / s2)\n    m = V %*% (inv(sigma0) %*% beta0 + (t(X) %*% y) / s2)\n    \n    # 1b) sample beta\n    beta = mvrnorm(1, m, V)\n    \n    # 2a) Compute SSR(beta) (specific formula from 9.1)\n    ssr = (t(y) %*% y) - (2 * t(beta) %*% t(X) %*% y) + (t(beta) %*% t(X) %*% X %*% beta)\n    \n    # 2b) sample s2\n    s2 = 1 / rgamma(1, (nu0 + n) / 2, (nu0 * s20 + ssr) / 2)\n\n    BETA[s, ] = beta\n    SIGMA[s] = s2\n  }\n  \n  # Now sample posterior predictive - two weeks later\n  xpred = c(1, 13)\n  YPRED = rnorm(S, BETA %*% xpred, sqrt(SIGMA))\n  \n  YPRED\n})\n\n\n\n\nShow R codefastest_times = apply(swim_pred, MARGIN = 1, FUN = which.min)\ntable(fastest_times) / length(fastest_times)\n#&gt; fastest_times\n#&gt;      1      2      3      4 \n#&gt; 0.6524 0.0134 0.3060 0.0282\n\n\nWe notice that with our posterior predictive dataset, swimmer 1 is the fastest about 65% of the time by week 13, so we recommend that swimmer 1 race."
  },
  {
    "objectID": "9.html#section-1",
    "href": "9.html#section-1",
    "title": "Chapter 9: Linear regression",
    "section": "",
    "text": "Show R codecrime = read.table('Exercises/crime.dat', header = TRUE)\n\n\n\n\nShow R codey = crime$y\nX = crime %&gt;% select(-y) %&gt;% as.matrix\n\nn = dim(X)[1]\np = dim(X)[2]\n\ng = n\nnu0 = 2\ns20 = 1\n\nS = 1000\n\nHg = (g / (g + 1)) * X %*% inv(t(X) %*% X) %*% t(X)\nSSRg = t(y) %*% (diag(1, nrow = n) - Hg) %*% y\n\ns2 = 1 / rgamma(S, (nu0 + n) / 2, (nu0 * s20 + SSRg) / 2)\nVb = g * inv(t(X) %*% X) / (g + 1)\nEb = Vb %*% t(X) %*% y\n\nE = matrix(rnorm(S * p, 0, sqrt(s2)), S, p)\nbeta = t(t(E %*% chol(Vb)) + c(Eb))\n\n\n\nShow R codelibrary(tidyr)\n\nsignif = apply(beta, MARGIN = 2, FUN = quantile, probs = c(0.025, 0.5, 0.975)) %&gt;%\n  apply(MARGIN = 2, FUN = function(y) !(y[1] &lt; 0 && 0 &lt; y[3]))\n\nbeta_df = as.data.frame(beta) %&gt;%\n  gather(key = 'variable', val = 'coefficient') %&gt;%\n  mutate(signif = signif[variable])\n\nggplot(beta_df, aes(x = variable, y = coefficient, color = signif)) +\n  stat_summary(fun.y = mean, fun.ymin = function(y) quantile(y, probs = c(0.025)), fun.ymax = function(y) quantile(y, probs = c(0.975))) +\n  geom_hline(yintercept = 0, lty = 2)\n\n\n\n\n\n\n\nLooks like Ed (mean years of schooling), Ineq (Income inequality), M (percentage of males aged 14-24), Prob (probability of imprisonment), and U2 (unemployment rate of urban males 35-39).\n\n\nShow R codey = crime$y\nX = crime %&gt;% select(-y) %&gt;% as.matrix\nset.seed(1) # Reproducible!\ntrain_i = sample.int(length(y), size = round(length(y) / 2), replace = FALSE)\nytr = y[train_i]\nXtr = X[train_i, ]\nyte = y[-train_i]\nXte = X[-train_i, ]\n\n\n\n\nShow R code# From 9.1\nbeta_ols = inv(t(Xtr) %*% Xtr) %*% t(Xtr) %*% ytr\nbeta_ols\n#&gt;             [,1]\n#&gt; M     0.19419790\n#&gt; So    0.20624856\n#&gt; Ed    0.64334998\n#&gt; Po1   0.30590821\n#&gt; Po2   0.44725441\n#&gt; LF   -0.09198965\n#&gt; M.F   0.03537926\n#&gt; Pop   0.08440462\n#&gt; NW   -0.01227990\n#&gt; U1   -0.03278782\n#&gt; U2    0.15494093\n#&gt; GDP   0.10455812\n#&gt; Ineq  0.76691166\n#&gt; Prob -0.25823362\n#&gt; Time  0.05938070\n\ny_ols = Xte %*% beta_ols\n\nols_df = data.frame(\n  observed = yte,\n  predicted = y_ols\n)\n\nggplot(ols_df, aes(x = observed, y = predicted)) +\n  geom_point() +\n  geom_smooth(method = 'lm')\n\n\n\n\n\n\nShow R code\npred_error = sum((yte - y_ols)^2) / length(yte)\npred_error\n#&gt; [1] 0.4880959\n\n\n\n\nShow R codey = ytr\nX = Xtr\n\nn = dim(X)[1]\np = dim(X)[2]\n\ng = n\nnu0 = 2\ns20 = 1\n\nS = 1000\n\nHg = (g / (g + 1)) * X %*% inv(t(X) %*% X) %*% t(X)\nSSRg = t(y) %*% (diag(1, nrow = n) - Hg) %*% y\n\ns2 = 1 / rgamma(S, (nu0 + n) / 2, (nu0 * s20 + SSRg) / 2)\nVb = g * inv(t(X) %*% X) / (g + 1)\nEb = Vb %*% t(X) %*% y\n\nE = matrix(rnorm(S * p, 0, sqrt(s2)), S, p)\nbeta = t(t(E %*% chol(Vb)) + c(Eb))\n\nbeta_bayes = as.matrix(colMeans(beta))\n\ny_bayes = Xte %*% beta_bayes\n\nbayes_df = data.frame(\n  observed = yte,\n  predicted = y_bayes\n)\n\nggplot(ols_df, aes(x = observed, y = predicted)) +\n  geom_point() +\n  geom_smooth(method = 'lm')\n\n\n\n\n\n\nShow R code\npred_error = sum((yte - y_bayes)^2) / length(yte)\npred_error\n#&gt; [1] 0.4910634\n\n\nAt least when the seed is 1, there doesn’t appear to be a major difference between the prediction errors.\n\n\nShow R code# Unnecessary code repeating here. Clean this up later w/ functions\nN = 100\nset.seed(1)\npred_errors = t(sapply(1:N, function(i) {\n  y = crime$y\n  X = crime %&gt;% select(-y) %&gt;% as.matrix\n  train_i = sample.int(length(y), size = round(length(y) / 2), replace = FALSE)\n  ytr = y[train_i]\n  Xtr = X[train_i, ]\n  yte = y[-train_i]\n  Xte = X[-train_i, ]\n  \n  # OLS\n  beta_ols = inv(t(Xtr) %*% Xtr) %*% t(Xtr) %*% ytr\n  beta_ols\n  \n  y_ols = Xte %*% beta_ols\n  \n  pred_error_ols = sum((yte - y_ols)^2) / length(yte)\n  \n  # Bayes\n  y = ytr\n  X = Xtr\n  \n  n = dim(X)[1]\n  p = dim(X)[2]\n  \n  g = n\n  nu0 = 2\n  s20 = 1\n  \n  S = 1000\n  \n  Hg = (g / (g + 1)) * X %*% inv(t(X) %*% X) %*% t(X)\n  SSRg = t(y) %*% (diag(1, nrow = n) - Hg) %*% y\n  \n  s2 = 1 / rgamma(S, (nu0 + n) / 2, (nu0 * s20 + SSRg) / 2)\n  Vb = g * inv(t(X) %*% X) / (g + 1)\n  Eb = Vb %*% t(X) %*% y\n  \n  E = matrix(rnorm(S * p, 0, sqrt(s2)), S, p)\n  beta = t(t(E %*% chol(Vb)) + c(Eb))\n  \n  beta_bayes = as.matrix(colMeans(beta))\n  \n  y_bayes = Xte %*% beta_bayes\n  \n  pred_error_bayes = sum((yte - y_bayes)^2) / length(yte)\n\n  c(pred_error_ols, pred_error_bayes)\n})) %&gt;% as.data.frame\ncolnames(pred_errors) = c('ols', 'bayes')\n\n\nHere’s a plot of the density of \\(\\text{err}_{\\text{Bayes}} -\n\\text{err}_{\\text{ols}}\\). If this is less than 0, then the Bayes estimator did better than the OLS estimator:\n\nShow R codepred_diff = pred_errors %&gt;% transmute(`bayes - ols` = bayes - ols)\n\nggplot(pred_diff, aes(x = `bayes - ols`)) +\n  geom_density() +\n  geom_vline(xintercept = 0, lty = 2)\n\n\n\n\n\n\n\nLastly,\n\nShow R codemean(pred_errors$bayes &lt; pred_errors$ols)\n#&gt; [1] 0.96\n\n\nFor N samples, 96% of the time, the predictive error using the Bayes estimators is less than the predictive error using the OLS estimators. Nice!"
  }
]